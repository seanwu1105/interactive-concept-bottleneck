{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from src.concept_bottleneck.dataset import (\n",
    "    CUB200ImageToAttributes,\n",
    "    NUM_ATTRIBUTES,\n",
    ")\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 2\n",
    "\n",
    "\n",
    "training_preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomResizedCrop(299),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "training_data = CUB200ImageToAttributes(train=True, transform=training_preprocess)\n",
    "training_dataloader = DataLoader(\n",
    "    training_data, batch_size=batch_size, num_workers=num_workers, shuffle=True\n",
    ")\n",
    "\n",
    "test_data = CUB200ImageToAttributes(train=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/shuangwu/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.concept_bottleneck.networks import get_inception\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "model: torch.nn.Module = get_inception().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.typing as npt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: DataLoader[tuple[torch.Tensor, npt.NDArray[np.float32]]],\n",
    "    loss_fn: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: str,\n",
    "):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)  # type: ignore\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        logits, aux_logits = model(x)\n",
    "        loss = loss_fn(logits, y) + 0.4 * loss_fn(aux_logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f\"loss: {loss.item():>7f} [{batch * len(x):>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: DataLoader[tuple[torch.Tensor, npt.NDArray[np.float32]]],\n",
    "    loss_fn: torch.nn.Module,\n",
    "    device: str,\n",
    "):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            test_loss += loss_fn(logits, y).item()\n",
    "\n",
    "            correct_attributes = (\n",
    "                ((torch.sigmoid(logits) >= 0.5) == (y >= 0.5)).sum().item()\n",
    "            )\n",
    "            correct += correct_attributes / NUM_ATTRIBUTES\n",
    "\n",
    "            total_correct += ( # Count the number of images with all attributes correct\n",
    "                torch.all((torch.sigmoid(logits) >= 0.5) == (y >= 0.5), dim=1)\n",
    "                .sum()\n",
    "                .item()\n",
    "            )\n",
    "\n",
    "    test_loss /= len(dataloader)\n",
    "    accuracy = correct / len(dataloader.dataset)  # type: ignore\n",
    "    total_accuracy = total_correct / len(dataloader.dataset)  # type: ignore\n",
    "    print(f\"Total accuracy: {total_accuracy:>0.10f}%\")\n",
    "\n",
    "    return test_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000-------------------\n",
      "loss: 0.990696 [    0/ 5994]\n",
      "loss: 0.310962 [ 1600/ 5994]\n",
      "loss: 0.338918 [ 3200/ 5994]\n",
      "loss: 0.324636 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.2262, Training Accuracy: 91.1702%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2262, Test Accuracy: 91.1572%\n",
      "Saving model to independent-image-to-attributes.pth with accuracy 91.1572%\n",
      "Epoch 2/1000-------------------\n",
      "loss: 0.298379 [    0/ 5994]\n",
      "loss: 0.308300 [ 1600/ 5994]\n",
      "loss: 0.339199 [ 3200/ 5994]\n",
      "loss: 0.347442 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.2135, Training Accuracy: 91.5791%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2138, Test Accuracy: 91.5685%\n",
      "Saving model to independent-image-to-attributes.pth with accuracy 91.5685%\n",
      "Epoch 3/1000-------------------\n",
      "loss: 0.315007 [    0/ 5994]\n",
      "loss: 0.300422 [ 1600/ 5994]\n",
      "loss: 0.296928 [ 3200/ 5994]\n",
      "loss: 0.308102 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.2075, Training Accuracy: 91.7547%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2098, Test Accuracy: 91.6959%\n",
      "Saving model to independent-image-to-attributes.pth with accuracy 91.6959%\n",
      "Epoch 4/1000-------------------\n",
      "loss: 0.274172 [    0/ 5994]\n",
      "loss: 0.285826 [ 1600/ 5994]\n",
      "loss: 0.304314 [ 3200/ 5994]\n",
      "loss: 0.300692 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.2041, Training Accuracy: 91.8967%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2083, Test Accuracy: 91.7462%\n",
      "Saving model to independent-image-to-attributes.pth with accuracy 91.7462%\n",
      "Epoch 5/1000-------------------\n",
      "loss: 0.294444 [    0/ 5994]\n",
      "loss: 0.293986 [ 1600/ 5994]\n",
      "loss: 0.262002 [ 3200/ 5994]\n",
      "loss: 0.271708 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1998, Training Accuracy: 92.0156%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2051, Test Accuracy: 91.8035%\n",
      "Saving model to independent-image-to-attributes.pth with accuracy 91.8035%\n",
      "Epoch 6/1000-------------------\n",
      "loss: 0.267483 [    0/ 5994]\n",
      "loss: 0.320431 [ 1600/ 5994]\n",
      "loss: 0.368498 [ 3200/ 5994]\n",
      "loss: 0.288250 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1976, Training Accuracy: 92.0886%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2055, Test Accuracy: 91.8683%\n",
      "Saving model to independent-image-to-attributes.pth with accuracy 91.8683%\n",
      "Epoch 7/1000-------------------\n",
      "loss: 0.291674 [    0/ 5994]\n",
      "loss: 0.323985 [ 1600/ 5994]\n",
      "loss: 0.278765 [ 3200/ 5994]\n",
      "loss: 0.277649 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1956, Training Accuracy: 92.1467%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2039, Test Accuracy: 91.9118%\n",
      "Saving model to independent-image-to-attributes.pth with accuracy 91.9118%\n",
      "Epoch 8/1000-------------------\n",
      "loss: 0.297577 [    0/ 5994]\n",
      "loss: 0.313083 [ 1600/ 5994]\n",
      "loss: 0.288399 [ 3200/ 5994]\n",
      "loss: 0.258885 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1932, Training Accuracy: 92.2562%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2047, Test Accuracy: 91.8650%\n",
      "Epoch 9/1000-------------------\n",
      "loss: 0.294017 [    0/ 5994]\n",
      "loss: 0.307312 [ 1600/ 5994]\n",
      "loss: 0.270406 [ 3200/ 5994]\n",
      "loss: 0.275364 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1912, Training Accuracy: 92.3195%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2041, Test Accuracy: 91.9415%\n",
      "Saving model to independent-image-to-attributes.pth with accuracy 91.9415%\n",
      "Epoch 10/1000-------------------\n",
      "loss: 0.259200 [    0/ 5994]\n",
      "loss: 0.298734 [ 1600/ 5994]\n",
      "loss: 0.298574 [ 3200/ 5994]\n",
      "loss: 0.282903 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1893, Training Accuracy: 92.3958%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2046, Test Accuracy: 91.8463%\n",
      "Epoch 11/1000-------------------\n",
      "loss: 0.285669 [    0/ 5994]\n",
      "loss: 0.292657 [ 1600/ 5994]\n",
      "loss: 0.271878 [ 3200/ 5994]\n",
      "loss: 0.282053 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1873, Training Accuracy: 92.4470%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2041, Test Accuracy: 91.8883%\n",
      "Epoch 12/1000-------------------\n",
      "loss: 0.270381 [    0/ 5994]\n",
      "loss: 0.256931 [ 1600/ 5994]\n",
      "loss: 0.301359 [ 3200/ 5994]\n",
      "loss: 0.245978 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1846, Training Accuracy: 92.5682%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2039, Test Accuracy: 91.9351%\n",
      "Epoch 13/1000-------------------\n",
      "loss: 0.264500 [    0/ 5994]\n",
      "loss: 0.237568 [ 1600/ 5994]\n",
      "loss: 0.257874 [ 3200/ 5994]\n",
      "loss: 0.265075 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1833, Training Accuracy: 92.6346%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2030, Test Accuracy: 91.8583%\n",
      "Epoch 14/1000-------------------\n",
      "loss: 0.248779 [    0/ 5994]\n",
      "loss: 0.237368 [ 1600/ 5994]\n",
      "loss: 0.297926 [ 3200/ 5994]\n",
      "loss: 0.240084 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1799, Training Accuracy: 92.7718%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2052, Test Accuracy: 91.8898%\n",
      "Epoch 15/1000-------------------\n",
      "loss: 0.294965 [    0/ 5994]\n",
      "loss: 0.261691 [ 1600/ 5994]\n",
      "loss: 0.253754 [ 3200/ 5994]\n",
      "loss: 0.291076 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1799, Training Accuracy: 92.7426%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2059, Test Accuracy: 91.8474%\n",
      "Epoch 16/1000-------------------\n",
      "loss: 0.253854 [    0/ 5994]\n",
      "loss: 0.276060 [ 1600/ 5994]\n",
      "loss: 0.246149 [ 3200/ 5994]\n",
      "loss: 0.289232 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1786, Training Accuracy: 92.8090%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2081, Test Accuracy: 91.8803%\n",
      "Epoch 17/1000-------------------\n",
      "loss: 0.260932 [    0/ 5994]\n",
      "loss: 0.275577 [ 1600/ 5994]\n",
      "loss: 0.250757 [ 3200/ 5994]\n",
      "loss: 0.316399 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1759, Training Accuracy: 92.9409%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2064, Test Accuracy: 91.8434%\n",
      "Epoch 18/1000-------------------\n",
      "loss: 0.279188 [    0/ 5994]\n",
      "loss: 0.223155 [ 1600/ 5994]\n",
      "loss: 0.309069 [ 3200/ 5994]\n",
      "loss: 0.292140 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1751, Training Accuracy: 92.9314%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2071, Test Accuracy: 91.8608%\n",
      "Epoch 19/1000-------------------\n",
      "loss: 0.256487 [    0/ 5994]\n",
      "loss: 0.241303 [ 1600/ 5994]\n",
      "loss: 0.241342 [ 3200/ 5994]\n",
      "loss: 0.242840 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1749, Training Accuracy: 92.9633%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2066, Test Accuracy: 91.8731%\n",
      "Epoch 20/1000-------------------\n",
      "loss: 0.226501 [    0/ 5994]\n",
      "loss: 0.254148 [ 1600/ 5994]\n",
      "loss: 0.285182 [ 3200/ 5994]\n",
      "loss: 0.259079 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1728, Training Accuracy: 93.0245%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2086, Test Accuracy: 91.7641%\n",
      "Epoch 21/1000-------------------\n",
      "loss: 0.256151 [    0/ 5994]\n",
      "loss: 0.203636 [ 1600/ 5994]\n",
      "loss: 0.301204 [ 3200/ 5994]\n",
      "loss: 0.228222 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1705, Training Accuracy: 93.1211%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2076, Test Accuracy: 91.8255%\n",
      "Epoch 22/1000-------------------\n",
      "loss: 0.268831 [    0/ 5994]\n",
      "loss: 0.267092 [ 1600/ 5994]\n",
      "loss: 0.310778 [ 3200/ 5994]\n",
      "loss: 0.278910 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1690, Training Accuracy: 93.1753%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2082, Test Accuracy: 91.7806%\n",
      "Epoch 23/1000-------------------\n",
      "loss: 0.222788 [    0/ 5994]\n",
      "loss: 0.273207 [ 1600/ 5994]\n",
      "loss: 0.260653 [ 3200/ 5994]\n",
      "loss: 0.260786 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1682, Training Accuracy: 93.2170%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2113, Test Accuracy: 91.7545%\n",
      "Epoch 24/1000-------------------\n",
      "loss: 0.241934 [    0/ 5994]\n",
      "loss: 0.241305 [ 1600/ 5994]\n",
      "loss: 0.303957 [ 3200/ 5994]\n",
      "loss: 0.265622 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1661, Training Accuracy: 93.3202%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2098, Test Accuracy: 91.7857%\n",
      "Epoch 25/1000-------------------\n",
      "loss: 0.256180 [    0/ 5994]\n",
      "loss: 0.230457 [ 1600/ 5994]\n",
      "loss: 0.245600 [ 3200/ 5994]\n",
      "loss: 0.261176 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1636, Training Accuracy: 93.4228%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2123, Test Accuracy: 91.7300%\n",
      "Epoch 26/1000-------------------\n",
      "loss: 0.242636 [    0/ 5994]\n",
      "loss: 0.247434 [ 1600/ 5994]\n",
      "loss: 0.248714 [ 3200/ 5994]\n",
      "loss: 0.262726 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1636, Training Accuracy: 93.4410%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2095, Test Accuracy: 91.7925%\n",
      "Epoch 27/1000-------------------\n",
      "loss: 0.234295 [    0/ 5994]\n",
      "loss: 0.256138 [ 1600/ 5994]\n",
      "loss: 0.246446 [ 3200/ 5994]\n",
      "loss: 0.219130 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1638, Training Accuracy: 93.4198%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2134, Test Accuracy: 91.6092%\n",
      "Epoch 28/1000-------------------\n",
      "loss: 0.197613 [    0/ 5994]\n",
      "loss: 0.219653 [ 1600/ 5994]\n",
      "loss: 0.231633 [ 3200/ 5994]\n",
      "loss: 0.252870 [ 4800/ 5994]\n",
      "Total accuracy: 0.0001668335%\n",
      "Training Loss: 0.1611, Training Accuracy: 93.5198%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2161, Test Accuracy: 91.6193%\n",
      "Epoch 29/1000-------------------\n",
      "loss: 0.241067 [    0/ 5994]\n",
      "loss: 0.249512 [ 1600/ 5994]\n",
      "loss: 0.283228 [ 3200/ 5994]\n",
      "loss: 0.232579 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1593, Training Accuracy: 93.5841%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2143, Test Accuracy: 91.7287%\n",
      "Epoch 30/1000-------------------\n",
      "loss: 0.240994 [    0/ 5994]\n",
      "loss: 0.251944 [ 1600/ 5994]\n",
      "loss: 0.256873 [ 3200/ 5994]\n",
      "loss: 0.227928 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1602, Training Accuracy: 93.5463%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2167, Test Accuracy: 91.5202%\n",
      "Epoch 31/1000-------------------\n",
      "loss: 0.225282 [    0/ 5994]\n",
      "loss: 0.195885 [ 1600/ 5994]\n",
      "loss: 0.221091 [ 3200/ 5994]\n",
      "loss: 0.230746 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1573, Training Accuracy: 93.6958%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2158, Test Accuracy: 91.5940%\n",
      "Epoch 32/1000-------------------\n",
      "loss: 0.221028 [    0/ 5994]\n",
      "loss: 0.271832 [ 1600/ 5994]\n",
      "loss: 0.208708 [ 3200/ 5994]\n",
      "loss: 0.277200 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1562, Training Accuracy: 93.7458%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2140, Test Accuracy: 91.7119%\n",
      "Epoch 33/1000-------------------\n",
      "loss: 0.254909 [    0/ 5994]\n",
      "loss: 0.266531 [ 1600/ 5994]\n",
      "loss: 0.238143 [ 3200/ 5994]\n",
      "loss: 0.246356 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1544, Training Accuracy: 93.8184%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2160, Test Accuracy: 91.6921%\n",
      "Epoch 34/1000-------------------\n",
      "loss: 0.235009 [    0/ 5994]\n",
      "loss: 0.279970 [ 1600/ 5994]\n",
      "loss: 0.228712 [ 3200/ 5994]\n",
      "loss: 0.273221 [ 4800/ 5994]\n",
      "Total accuracy: 0.0001668335%\n",
      "Training Loss: 0.1524, Training Accuracy: 93.9090%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2156, Test Accuracy: 91.5922%\n",
      "Epoch 35/1000-------------------\n",
      "loss: 0.253849 [    0/ 5994]\n",
      "loss: 0.286154 [ 1600/ 5994]\n",
      "loss: 0.227293 [ 3200/ 5994]\n",
      "loss: 0.254673 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1527, Training Accuracy: 93.8834%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2168, Test Accuracy: 91.6038%\n",
      "Epoch 36/1000-------------------\n",
      "loss: 0.255154 [    0/ 5994]\n",
      "loss: 0.210139 [ 1600/ 5994]\n",
      "loss: 0.261182 [ 3200/ 5994]\n",
      "loss: 0.244862 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1516, Training Accuracy: 93.9185%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2191, Test Accuracy: 91.6677%\n",
      "Epoch 37/1000-------------------\n",
      "loss: 0.222761 [    0/ 5994]\n",
      "loss: 0.215519 [ 1600/ 5994]\n",
      "loss: 0.207879 [ 3200/ 5994]\n",
      "loss: 0.207969 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1493, Training Accuracy: 93.9878%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2223, Test Accuracy: 91.5511%\n",
      "Epoch 38/1000-------------------\n",
      "loss: 0.215037 [    0/ 5994]\n",
      "loss: 0.243524 [ 1600/ 5994]\n",
      "loss: 0.224172 [ 3200/ 5994]\n",
      "loss: 0.226391 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1477, Training Accuracy: 94.1112%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2172, Test Accuracy: 91.5653%\n",
      "Epoch 39/1000-------------------\n",
      "loss: 0.254036 [    0/ 5994]\n",
      "loss: 0.227987 [ 1600/ 5994]\n",
      "loss: 0.232570 [ 3200/ 5994]\n",
      "loss: 0.207321 [ 4800/ 5994]\n",
      "Total accuracy: 0.0001668335%\n",
      "Training Loss: 0.1474, Training Accuracy: 94.0821%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2217, Test Accuracy: 91.5763%\n",
      "Epoch 40/1000-------------------\n",
      "loss: 0.170468 [    0/ 5994]\n",
      "loss: 0.237299 [ 1600/ 5994]\n",
      "loss: 0.246191 [ 3200/ 5994]\n",
      "loss: 0.229397 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1461, Training Accuracy: 94.1453%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2194, Test Accuracy: 91.6775%\n",
      "Epoch 41/1000-------------------\n",
      "loss: 0.219188 [    0/ 5994]\n",
      "loss: 0.242037 [ 1600/ 5994]\n",
      "loss: 0.218218 [ 3200/ 5994]\n",
      "loss: 0.210379 [ 4800/ 5994]\n",
      "Total accuracy: 0.0003336670%\n",
      "Training Loss: 0.1464, Training Accuracy: 94.1094%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2202, Test Accuracy: 91.5980%\n",
      "Epoch 42/1000-------------------\n",
      "loss: 0.230196 [    0/ 5994]\n",
      "loss: 0.234542 [ 1600/ 5994]\n",
      "loss: 0.199378 [ 3200/ 5994]\n",
      "loss: 0.186549 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1457, Training Accuracy: 94.1640%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2223, Test Accuracy: 91.6274%\n",
      "Epoch 43/1000-------------------\n",
      "loss: 0.273486 [    0/ 5994]\n",
      "loss: 0.225817 [ 1600/ 5994]\n",
      "loss: 0.246871 [ 3200/ 5994]\n",
      "loss: 0.218997 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1440, Training Accuracy: 94.2585%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2245, Test Accuracy: 91.5891%\n",
      "Epoch 44/1000-------------------\n",
      "loss: 0.259110 [    0/ 5994]\n",
      "loss: 0.242675 [ 1600/ 5994]\n",
      "loss: 0.247623 [ 3200/ 5994]\n",
      "loss: 0.194097 [ 4800/ 5994]\n",
      "Total accuracy: 0.0001668335%\n",
      "Training Loss: 0.1435, Training Accuracy: 94.2641%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2232, Test Accuracy: 91.5823%\n",
      "Epoch 45/1000-------------------\n",
      "loss: 0.226809 [    0/ 5994]\n",
      "loss: 0.214890 [ 1600/ 5994]\n",
      "loss: 0.194197 [ 3200/ 5994]\n",
      "loss: 0.240684 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1419, Training Accuracy: 94.3315%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2222, Test Accuracy: 91.4964%\n",
      "Epoch 46/1000-------------------\n",
      "loss: 0.204641 [    0/ 5994]\n",
      "loss: 0.215581 [ 1600/ 5994]\n",
      "loss: 0.220969 [ 3200/ 5994]\n",
      "loss: 0.211085 [ 4800/ 5994]\n",
      "Total accuracy: 0.0001668335%\n",
      "Training Loss: 0.1403, Training Accuracy: 94.3839%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2260, Test Accuracy: 91.5667%\n",
      "Epoch 47/1000-------------------\n",
      "loss: 0.187276 [    0/ 5994]\n",
      "loss: 0.209531 [ 1600/ 5994]\n",
      "loss: 0.233331 [ 3200/ 5994]\n",
      "loss: 0.205939 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1415, Training Accuracy: 94.3410%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2292, Test Accuracy: 91.5964%\n",
      "Epoch 48/1000-------------------\n",
      "loss: 0.241901 [    0/ 5994]\n",
      "loss: 0.232221 [ 1600/ 5994]\n",
      "loss: 0.222124 [ 3200/ 5994]\n",
      "loss: 0.219606 [ 4800/ 5994]\n",
      "Total accuracy: 0.0001668335%\n",
      "Training Loss: 0.1375, Training Accuracy: 94.5006%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2254, Test Accuracy: 91.4609%\n",
      "Epoch 49/1000-------------------\n",
      "loss: 0.224163 [    0/ 5994]\n",
      "loss: 0.183823 [ 1600/ 5994]\n",
      "loss: 0.214358 [ 3200/ 5994]\n",
      "loss: 0.249960 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1385, Training Accuracy: 94.4740%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2286, Test Accuracy: 91.4731%\n",
      "Epoch 50/1000-------------------\n",
      "loss: 0.193798 [    0/ 5994]\n",
      "loss: 0.212053 [ 1600/ 5994]\n",
      "loss: 0.231996 [ 3200/ 5994]\n",
      "loss: 0.234364 [ 4800/ 5994]\n",
      "Total accuracy: 0.0003336670%\n",
      "Training Loss: 0.1361, Training Accuracy: 94.5986%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2229, Test Accuracy: 91.5954%\n",
      "Epoch 51/1000-------------------\n",
      "loss: 0.203660 [    0/ 5994]\n",
      "loss: 0.192136 [ 1600/ 5994]\n",
      "loss: 0.223415 [ 3200/ 5994]\n",
      "loss: 0.228783 [ 4800/ 5994]\n",
      "Total accuracy: 0.0001668335%\n",
      "Training Loss: 0.1342, Training Accuracy: 94.6429%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2258, Test Accuracy: 91.5722%\n",
      "Epoch 52/1000-------------------\n",
      "loss: 0.230276 [    0/ 5994]\n",
      "loss: 0.222878 [ 1600/ 5994]\n",
      "loss: 0.211541 [ 3200/ 5994]\n",
      "loss: 0.204878 [ 4800/ 5994]\n",
      "Total accuracy: 0.0003336670%\n",
      "Training Loss: 0.1345, Training Accuracy: 94.6206%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2297, Test Accuracy: 91.4594%\n",
      "Epoch 53/1000-------------------\n",
      "loss: 0.214848 [    0/ 5994]\n",
      "loss: 0.215141 [ 1600/ 5994]\n",
      "loss: 0.228959 [ 3200/ 5994]\n",
      "loss: 0.262661 [ 4800/ 5994]\n",
      "Total accuracy: 0.0005005005%\n",
      "Training Loss: 0.1325, Training Accuracy: 94.7038%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2279, Test Accuracy: 91.5483%\n",
      "Epoch 54/1000-------------------\n",
      "loss: 0.150774 [    0/ 5994]\n",
      "loss: 0.200326 [ 1600/ 5994]\n",
      "loss: 0.218309 [ 3200/ 5994]\n",
      "loss: 0.219566 [ 4800/ 5994]\n",
      "Total accuracy: 0.0000000000%\n",
      "Training Loss: 0.1314, Training Accuracy: 94.7584%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2296, Test Accuracy: 91.4568%\n",
      "Epoch 55/1000-------------------\n",
      "loss: 0.226429 [    0/ 5994]\n",
      "loss: 0.209350 [ 1600/ 5994]\n",
      "loss: 0.258883 [ 3200/ 5994]\n",
      "loss: 0.228994 [ 4800/ 5994]\n",
      "Total accuracy: 0.0008341675%\n",
      "Training Loss: 0.1303, Training Accuracy: 94.8071%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2301, Test Accuracy: 91.5477%\n",
      "Epoch 56/1000-------------------\n",
      "loss: 0.217167 [    0/ 5994]\n",
      "loss: 0.213581 [ 1600/ 5994]\n",
      "loss: 0.223415 [ 3200/ 5994]\n",
      "loss: 0.199727 [ 4800/ 5994]\n",
      "Total accuracy: 0.0008341675%\n",
      "Training Loss: 0.1298, Training Accuracy: 94.8057%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2305, Test Accuracy: 91.5269%\n",
      "Epoch 57/1000-------------------\n",
      "loss: 0.210862 [    0/ 5994]\n",
      "loss: 0.190626 [ 1600/ 5994]\n",
      "loss: 0.213761 [ 3200/ 5994]\n",
      "loss: 0.176729 [ 4800/ 5994]\n",
      "Total accuracy: 0.0008341675%\n",
      "Training Loss: 0.1281, Training Accuracy: 94.9006%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2309, Test Accuracy: 91.4308%\n",
      "Epoch 58/1000-------------------\n",
      "loss: 0.203258 [    0/ 5994]\n",
      "loss: 0.212961 [ 1600/ 5994]\n",
      "loss: 0.200178 [ 3200/ 5994]\n",
      "loss: 0.247447 [ 4800/ 5994]\n",
      "Total accuracy: 0.0005005005%\n",
      "Training Loss: 0.1276, Training Accuracy: 94.9110%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2320, Test Accuracy: 91.4852%\n",
      "Epoch 59/1000-------------------\n",
      "loss: 0.197506 [    0/ 5994]\n",
      "loss: 0.171119 [ 1600/ 5994]\n",
      "loss: 0.203372 [ 3200/ 5994]\n",
      "loss: 0.199739 [ 4800/ 5994]\n",
      "Total accuracy: 0.0006673340%\n",
      "Training Loss: 0.1276, Training Accuracy: 94.9307%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2341, Test Accuracy: 91.3786%\n",
      "Epoch 60/1000-------------------\n",
      "loss: 0.193899 [    0/ 5994]\n",
      "loss: 0.184880 [ 1600/ 5994]\n",
      "loss: 0.214923 [ 3200/ 5994]\n",
      "loss: 0.198673 [ 4800/ 5994]\n",
      "Total accuracy: 0.0001668335%\n",
      "Training Loss: 0.1258, Training Accuracy: 94.9745%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2312, Test Accuracy: 91.4364%\n",
      "Epoch 61/1000-------------------\n",
      "loss: 0.186736 [    0/ 5994]\n",
      "loss: 0.212979 [ 1600/ 5994]\n",
      "loss: 0.201598 [ 3200/ 5994]\n",
      "loss: 0.244234 [ 4800/ 5994]\n",
      "Total accuracy: 0.0006673340%\n",
      "Training Loss: 0.1241, Training Accuracy: 95.0786%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2334, Test Accuracy: 91.4760%\n",
      "Epoch 62/1000-------------------\n",
      "loss: 0.200805 [    0/ 5994]\n",
      "loss: 0.219424 [ 1600/ 5994]\n",
      "loss: 0.190673 [ 3200/ 5994]\n",
      "loss: 0.190309 [ 4800/ 5994]\n",
      "Total accuracy: 0.0010010010%\n",
      "Training Loss: 0.1238, Training Accuracy: 95.0823%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2346, Test Accuracy: 91.4219%\n",
      "Epoch 63/1000-------------------\n",
      "loss: 0.193411 [    0/ 5994]\n",
      "loss: 0.176508 [ 1600/ 5994]\n",
      "loss: 0.275694 [ 3200/ 5994]\n",
      "loss: 0.241672 [ 4800/ 5994]\n",
      "Total accuracy: 0.0008341675%\n",
      "Training Loss: 0.1240, Training Accuracy: 95.0677%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2377, Test Accuracy: 91.2719%\n",
      "Epoch 64/1000-------------------\n",
      "loss: 0.206082 [    0/ 5994]\n",
      "loss: 0.188800 [ 1600/ 5994]\n",
      "loss: 0.180307 [ 3200/ 5994]\n",
      "loss: 0.187936 [ 4800/ 5994]\n",
      "Total accuracy: 0.0013346680%\n",
      "Training Loss: 0.1231, Training Accuracy: 95.1156%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2329, Test Accuracy: 91.4800%\n",
      "Epoch 65/1000-------------------\n",
      "loss: 0.165000 [    0/ 5994]\n",
      "loss: 0.173228 [ 1600/ 5994]\n",
      "loss: 0.191196 [ 3200/ 5994]\n",
      "loss: 0.178476 [ 4800/ 5994]\n",
      "Total accuracy: 0.0010010010%\n",
      "Training Loss: 0.1225, Training Accuracy: 95.1148%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2344, Test Accuracy: 91.4696%\n",
      "Epoch 66/1000-------------------\n",
      "loss: 0.216325 [    0/ 5994]\n",
      "loss: 0.215862 [ 1600/ 5994]\n",
      "loss: 0.174775 [ 3200/ 5994]\n",
      "loss: 0.204351 [ 4800/ 5994]\n",
      "Total accuracy: 0.0016683350%\n",
      "Training Loss: 0.1213, Training Accuracy: 95.1867%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2350, Test Accuracy: 91.3798%\n",
      "Epoch 67/1000-------------------\n",
      "loss: 0.200264 [    0/ 5994]\n",
      "loss: 0.228519 [ 1600/ 5994]\n",
      "loss: 0.201218 [ 3200/ 5994]\n",
      "loss: 0.230914 [ 4800/ 5994]\n",
      "Total accuracy: 0.0008341675%\n",
      "Training Loss: 0.1203, Training Accuracy: 95.2113%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2344, Test Accuracy: 91.4043%\n",
      "Epoch 68/1000-------------------\n",
      "loss: 0.174634 [    0/ 5994]\n",
      "loss: 0.214930 [ 1600/ 5994]\n",
      "loss: 0.235771 [ 3200/ 5994]\n",
      "loss: 0.198645 [ 4800/ 5994]\n",
      "Total accuracy: 0.0013346680%\n",
      "Training Loss: 0.1183, Training Accuracy: 95.3039%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2361, Test Accuracy: 91.3544%\n",
      "Epoch 69/1000-------------------\n",
      "loss: 0.189356 [    0/ 5994]\n",
      "loss: 0.151873 [ 1600/ 5994]\n",
      "loss: 0.219834 [ 3200/ 5994]\n",
      "loss: 0.192068 [ 4800/ 5994]\n",
      "Total accuracy: 0.0011678345%\n",
      "Training Loss: 0.1165, Training Accuracy: 95.3666%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2384, Test Accuracy: 91.5059%\n",
      "Epoch 70/1000-------------------\n",
      "loss: 0.184435 [    0/ 5994]\n",
      "loss: 0.182397 [ 1600/ 5994]\n",
      "loss: 0.187506 [ 3200/ 5994]\n",
      "loss: 0.188576 [ 4800/ 5994]\n",
      "Total accuracy: 0.0010010010%\n",
      "Training Loss: 0.1163, Training Accuracy: 95.3870%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2347, Test Accuracy: 91.4782%\n",
      "Epoch 71/1000-------------------\n",
      "loss: 0.180201 [    0/ 5994]\n",
      "loss: 0.184276 [ 1600/ 5994]\n",
      "loss: 0.193613 [ 3200/ 5994]\n",
      "loss: 0.192490 [ 4800/ 5994]\n",
      "Total accuracy: 0.0010010010%\n",
      "Training Loss: 0.1162, Training Accuracy: 95.3998%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2360, Test Accuracy: 91.4512%\n",
      "Epoch 72/1000-------------------\n",
      "loss: 0.183290 [    0/ 5994]\n",
      "loss: 0.167496 [ 1600/ 5994]\n",
      "loss: 0.180863 [ 3200/ 5994]\n",
      "loss: 0.187179 [ 4800/ 5994]\n",
      "Total accuracy: 0.0015015015%\n",
      "Training Loss: 0.1155, Training Accuracy: 95.4335%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2413, Test Accuracy: 91.4311%\n",
      "Epoch 73/1000-------------------\n",
      "loss: 0.191223 [    0/ 5994]\n",
      "loss: 0.140520 [ 1600/ 5994]\n",
      "loss: 0.207459 [ 3200/ 5994]\n",
      "loss: 0.171210 [ 4800/ 5994]\n",
      "Total accuracy: 0.0011678345%\n",
      "Training Loss: 0.1145, Training Accuracy: 95.4745%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2412, Test Accuracy: 91.3344%\n",
      "Epoch 74/1000-------------------\n",
      "loss: 0.198945 [    0/ 5994]\n",
      "loss: 0.205746 [ 1600/ 5994]\n",
      "loss: 0.203672 [ 3200/ 5994]\n",
      "loss: 0.194291 [ 4800/ 5994]\n",
      "Total accuracy: 0.0018351685%\n",
      "Training Loss: 0.1150, Training Accuracy: 95.4237%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2440, Test Accuracy: 91.4779%\n",
      "Epoch 75/1000-------------------\n",
      "loss: 0.225387 [    0/ 5994]\n",
      "loss: 0.195191 [ 1600/ 5994]\n",
      "loss: 0.178008 [ 3200/ 5994]\n",
      "loss: 0.190378 [ 4800/ 5994]\n",
      "Total accuracy: 0.0020020020%\n",
      "Training Loss: 0.1122, Training Accuracy: 95.5629%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2425, Test Accuracy: 91.3129%\n",
      "Epoch 76/1000-------------------\n",
      "loss: 0.181315 [    0/ 5994]\n",
      "loss: 0.168023 [ 1600/ 5994]\n",
      "loss: 0.170316 [ 3200/ 5994]\n",
      "loss: 0.178345 [ 4800/ 5994]\n",
      "Total accuracy: 0.0011678345%\n",
      "Training Loss: 0.1115, Training Accuracy: 95.5623%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2425, Test Accuracy: 91.4175%\n",
      "Epoch 77/1000-------------------\n",
      "loss: 0.177793 [    0/ 5994]\n",
      "loss: 0.175188 [ 1600/ 5994]\n",
      "loss: 0.180477 [ 3200/ 5994]\n",
      "loss: 0.161591 [ 4800/ 5994]\n",
      "Total accuracy: 0.0020020020%\n",
      "Training Loss: 0.1115, Training Accuracy: 95.5804%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2449, Test Accuracy: 91.2732%\n",
      "Epoch 78/1000-------------------\n",
      "loss: 0.190214 [    0/ 5994]\n",
      "loss: 0.184687 [ 1600/ 5994]\n",
      "loss: 0.150441 [ 3200/ 5994]\n",
      "loss: 0.174616 [ 4800/ 5994]\n",
      "Total accuracy: 0.0016683350%\n",
      "Training Loss: 0.1101, Training Accuracy: 95.6350%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2424, Test Accuracy: 91.3591%\n",
      "Epoch 79/1000-------------------\n",
      "loss: 0.188353 [    0/ 5994]\n",
      "loss: 0.198225 [ 1600/ 5994]\n",
      "loss: 0.165781 [ 3200/ 5994]\n",
      "loss: 0.211120 [ 4800/ 5994]\n",
      "Total accuracy: 0.0015015015%\n",
      "Training Loss: 0.1101, Training Accuracy: 95.6495%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2390, Test Accuracy: 91.3906%\n",
      "Epoch 80/1000-------------------\n",
      "loss: 0.158191 [    0/ 5994]\n",
      "loss: 0.166706 [ 1600/ 5994]\n",
      "loss: 0.183876 [ 3200/ 5994]\n",
      "loss: 0.189161 [ 4800/ 5994]\n",
      "Total accuracy: 0.0020020020%\n",
      "Training Loss: 0.1078, Training Accuracy: 95.7395%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2449, Test Accuracy: 91.3335%\n",
      "Epoch 81/1000-------------------\n",
      "loss: 0.180345 [    0/ 5994]\n",
      "loss: 0.209943 [ 1600/ 5994]\n",
      "loss: 0.223362 [ 3200/ 5994]\n",
      "loss: 0.230075 [ 4800/ 5994]\n",
      "Total accuracy: 0.0023356690%\n",
      "Training Loss: 0.1082, Training Accuracy: 95.7274%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2448, Test Accuracy: 91.3058%\n",
      "Epoch 82/1000-------------------\n",
      "loss: 0.209484 [    0/ 5994]\n",
      "loss: 0.203508 [ 1600/ 5994]\n",
      "loss: 0.169059 [ 3200/ 5994]\n",
      "loss: 0.208224 [ 4800/ 5994]\n",
      "Total accuracy: 0.0026693360%\n",
      "Training Loss: 0.1064, Training Accuracy: 95.7819%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2444, Test Accuracy: 91.3953%\n",
      "Epoch 83/1000-------------------\n",
      "loss: 0.149425 [    0/ 5994]\n",
      "loss: 0.185194 [ 1600/ 5994]\n",
      "loss: 0.190833 [ 3200/ 5994]\n",
      "loss: 0.174740 [ 4800/ 5994]\n",
      "Total accuracy: 0.0033366700%\n",
      "Training Loss: 0.1064, Training Accuracy: 95.7942%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2449, Test Accuracy: 91.4243%\n",
      "Epoch 84/1000-------------------\n",
      "loss: 0.156085 [    0/ 5994]\n",
      "loss: 0.199723 [ 1600/ 5994]\n",
      "loss: 0.187168 [ 3200/ 5994]\n",
      "loss: 0.200828 [ 4800/ 5994]\n",
      "Total accuracy: 0.0046713380%\n",
      "Training Loss: 0.1035, Training Accuracy: 95.9054%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2447, Test Accuracy: 91.2467%\n",
      "Epoch 85/1000-------------------\n",
      "loss: 0.205209 [    0/ 5994]\n",
      "loss: 0.198430 [ 1600/ 5994]\n",
      "loss: 0.172841 [ 3200/ 5994]\n",
      "loss: 0.178602 [ 4800/ 5994]\n",
      "Total accuracy: 0.0028361695%\n",
      "Training Loss: 0.1030, Training Accuracy: 95.9303%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2465, Test Accuracy: 91.2825%\n",
      "Epoch 86/1000-------------------\n",
      "loss: 0.161171 [    0/ 5994]\n",
      "loss: 0.161836 [ 1600/ 5994]\n",
      "loss: 0.145384 [ 3200/ 5994]\n",
      "loss: 0.212612 [ 4800/ 5994]\n",
      "Total accuracy: 0.0033366700%\n",
      "Training Loss: 0.1030, Training Accuracy: 95.9142%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2462, Test Accuracy: 91.3809%\n",
      "Epoch 87/1000-------------------\n",
      "loss: 0.161525 [    0/ 5994]\n",
      "loss: 0.150678 [ 1600/ 5994]\n",
      "loss: 0.150573 [ 3200/ 5994]\n",
      "loss: 0.159726 [ 4800/ 5994]\n",
      "Total accuracy: 0.0035035035%\n",
      "Training Loss: 0.1020, Training Accuracy: 95.9638%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2498, Test Accuracy: 91.3327%\n",
      "Epoch 88/1000-------------------\n",
      "loss: 0.187664 [    0/ 5994]\n",
      "loss: 0.166944 [ 1600/ 5994]\n",
      "loss: 0.171713 [ 3200/ 5994]\n",
      "loss: 0.197765 [ 4800/ 5994]\n",
      "Total accuracy: 0.0023356690%\n",
      "Training Loss: 0.1001, Training Accuracy: 96.0514%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2530, Test Accuracy: 91.3692%\n",
      "Epoch 89/1000-------------------\n",
      "loss: 0.170990 [    0/ 5994]\n",
      "loss: 0.134613 [ 1600/ 5994]\n",
      "loss: 0.180002 [ 3200/ 5994]\n",
      "loss: 0.191813 [ 4800/ 5994]\n",
      "Total accuracy: 0.0045045045%\n",
      "Training Loss: 0.1007, Training Accuracy: 96.0345%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2450, Test Accuracy: 91.3520%\n",
      "Epoch 90/1000-------------------\n",
      "loss: 0.162242 [    0/ 5994]\n",
      "loss: 0.167485 [ 1600/ 5994]\n",
      "loss: 0.187113 [ 3200/ 5994]\n",
      "loss: 0.159299 [ 4800/ 5994]\n",
      "Total accuracy: 0.0043376710%\n",
      "Training Loss: 0.0987, Training Accuracy: 96.1114%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2482, Test Accuracy: 91.3112%\n",
      "Epoch 91/1000-------------------\n",
      "loss: 0.171475 [    0/ 5994]\n",
      "loss: 0.177858 [ 1600/ 5994]\n",
      "loss: 0.197246 [ 3200/ 5994]\n",
      "loss: 0.166505 [ 4800/ 5994]\n",
      "Total accuracy: 0.0036703370%\n",
      "Training Loss: 0.0991, Training Accuracy: 96.0957%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2473, Test Accuracy: 91.2775%\n",
      "Epoch 92/1000-------------------\n",
      "loss: 0.178054 [    0/ 5994]\n",
      "loss: 0.206065 [ 1600/ 5994]\n",
      "loss: 0.167520 [ 3200/ 5994]\n",
      "loss: 0.193038 [ 4800/ 5994]\n",
      "Total accuracy: 0.0045045045%\n",
      "Training Loss: 0.0983, Training Accuracy: 96.1406%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2547, Test Accuracy: 91.2423%\n",
      "Epoch 93/1000-------------------\n",
      "loss: 0.150575 [    0/ 5994]\n",
      "loss: 0.189196 [ 1600/ 5994]\n",
      "loss: 0.160181 [ 3200/ 5994]\n",
      "loss: 0.197269 [ 4800/ 5994]\n",
      "Total accuracy: 0.0045045045%\n",
      "Training Loss: 0.0968, Training Accuracy: 96.1874%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2509, Test Accuracy: 91.3389%\n",
      "Epoch 94/1000-------------------\n",
      "loss: 0.160333 [    0/ 5994]\n",
      "loss: 0.185601 [ 1600/ 5994]\n",
      "loss: 0.160751 [ 3200/ 5994]\n",
      "loss: 0.203627 [ 4800/ 5994]\n",
      "Total accuracy: 0.0055055055%\n",
      "Training Loss: 0.0948, Training Accuracy: 96.2526%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2545, Test Accuracy: 91.3603%\n",
      "Epoch 95/1000-------------------\n",
      "loss: 0.197803 [    0/ 5994]\n",
      "loss: 0.163012 [ 1600/ 5994]\n",
      "loss: 0.175547 [ 3200/ 5994]\n",
      "loss: 0.138771 [ 4800/ 5994]\n",
      "Total accuracy: 0.0075075075%\n",
      "Training Loss: 0.0955, Training Accuracy: 96.2544%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2468, Test Accuracy: 91.2713%\n",
      "Epoch 96/1000-------------------\n",
      "loss: 0.153352 [    0/ 5994]\n",
      "loss: 0.190702 [ 1600/ 5994]\n",
      "loss: 0.180497 [ 3200/ 5994]\n",
      "loss: 0.161837 [ 4800/ 5994]\n",
      "Total accuracy: 0.0050050050%\n",
      "Training Loss: 0.0963, Training Accuracy: 96.2076%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2541, Test Accuracy: 91.2032%\n",
      "Epoch 97/1000-------------------\n",
      "loss: 0.136158 [    0/ 5994]\n",
      "loss: 0.136660 [ 1600/ 5994]\n",
      "loss: 0.170940 [ 3200/ 5994]\n",
      "loss: 0.150811 [ 4800/ 5994]\n",
      "Total accuracy: 0.0061728395%\n",
      "Training Loss: 0.0930, Training Accuracy: 96.3388%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2533, Test Accuracy: 91.3248%\n",
      "Epoch 98/1000-------------------\n",
      "loss: 0.152253 [    0/ 5994]\n",
      "loss: 0.198468 [ 1600/ 5994]\n",
      "loss: 0.137475 [ 3200/ 5994]\n",
      "loss: 0.162895 [ 4800/ 5994]\n",
      "Total accuracy: 0.0060060060%\n",
      "Training Loss: 0.0935, Training Accuracy: 96.3204%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2533, Test Accuracy: 91.2937%\n",
      "Epoch 99/1000-------------------\n",
      "loss: 0.160443 [    0/ 5994]\n",
      "loss: 0.188692 [ 1600/ 5994]\n",
      "loss: 0.177503 [ 3200/ 5994]\n",
      "loss: 0.209052 [ 4800/ 5994]\n",
      "Total accuracy: 0.0065065065%\n",
      "Training Loss: 0.0933, Training Accuracy: 96.3345%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2538, Test Accuracy: 91.3198%\n",
      "Epoch 100/1000-------------------\n",
      "loss: 0.154957 [    0/ 5994]\n",
      "loss: 0.219656 [ 1600/ 5994]\n",
      "loss: 0.145901 [ 3200/ 5994]\n",
      "loss: 0.162188 [ 4800/ 5994]\n",
      "Total accuracy: 0.0058391725%\n",
      "Training Loss: 0.0923, Training Accuracy: 96.3733%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2535, Test Accuracy: 91.3120%\n",
      "Epoch 101/1000-------------------\n",
      "loss: 0.132772 [    0/ 5994]\n",
      "loss: 0.154278 [ 1600/ 5994]\n",
      "loss: 0.185286 [ 3200/ 5994]\n",
      "loss: 0.176448 [ 4800/ 5994]\n",
      "Total accuracy: 0.0070070070%\n",
      "Training Loss: 0.0899, Training Accuracy: 96.4689%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2534, Test Accuracy: 91.2996%\n",
      "Epoch 102/1000-------------------\n",
      "loss: 0.164429 [    0/ 5994]\n",
      "loss: 0.176757 [ 1600/ 5994]\n",
      "loss: 0.133421 [ 3200/ 5994]\n",
      "loss: 0.137437 [ 4800/ 5994]\n",
      "Total accuracy: 0.0071738405%\n",
      "Training Loss: 0.0897, Training Accuracy: 96.4745%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2576, Test Accuracy: 91.2118%\n",
      "Epoch 103/1000-------------------\n",
      "loss: 0.165544 [    0/ 5994]\n",
      "loss: 0.153947 [ 1600/ 5994]\n",
      "loss: 0.151807 [ 3200/ 5994]\n",
      "loss: 0.159007 [ 4800/ 5994]\n",
      "Total accuracy: 0.0081748415%\n",
      "Training Loss: 0.0891, Training Accuracy: 96.4987%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2578, Test Accuracy: 91.2564%\n",
      "Epoch 104/1000-------------------\n",
      "loss: 0.139298 [    0/ 5994]\n",
      "loss: 0.198563 [ 1600/ 5994]\n",
      "loss: 0.165415 [ 3200/ 5994]\n",
      "loss: 0.169237 [ 4800/ 5994]\n",
      "Total accuracy: 0.0070070070%\n",
      "Training Loss: 0.0895, Training Accuracy: 96.4914%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2605, Test Accuracy: 91.2162%\n",
      "Epoch 105/1000-------------------\n",
      "loss: 0.149064 [    0/ 5994]\n",
      "loss: 0.128018 [ 1600/ 5994]\n",
      "loss: 0.165407 [ 3200/ 5994]\n",
      "loss: 0.139555 [ 4800/ 5994]\n",
      "Total accuracy: 0.0095095095%\n",
      "Training Loss: 0.0859, Training Accuracy: 96.6281%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2608, Test Accuracy: 91.2581%\n",
      "Epoch 106/1000-------------------\n",
      "loss: 0.154275 [    0/ 5994]\n",
      "loss: 0.144394 [ 1600/ 5994]\n",
      "loss: 0.134382 [ 3200/ 5994]\n",
      "loss: 0.177345 [ 4800/ 5994]\n",
      "Total accuracy: 0.0098431765%\n",
      "Training Loss: 0.0870, Training Accuracy: 96.5926%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2602, Test Accuracy: 91.2178%\n",
      "Epoch 107/1000-------------------\n",
      "loss: 0.187687 [    0/ 5994]\n",
      "loss: 0.170935 [ 1600/ 5994]\n",
      "loss: 0.173270 [ 3200/ 5994]\n",
      "loss: 0.192251 [ 4800/ 5994]\n",
      "Total accuracy: 0.0105105105%\n",
      "Training Loss: 0.0879, Training Accuracy: 96.5525%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2581, Test Accuracy: 91.3031%\n",
      "Epoch 108/1000-------------------\n",
      "loss: 0.146348 [    0/ 5994]\n",
      "loss: 0.147041 [ 1600/ 5994]\n",
      "loss: 0.146219 [ 3200/ 5994]\n",
      "loss: 0.144172 [ 4800/ 5994]\n",
      "Total accuracy: 0.0106773440%\n",
      "Training Loss: 0.0861, Training Accuracy: 96.6387%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2565, Test Accuracy: 91.2893%\n",
      "Epoch 109/1000-------------------\n",
      "loss: 0.159774 [    0/ 5994]\n",
      "loss: 0.126442 [ 1600/ 5994]\n",
      "loss: 0.147997 [ 3200/ 5994]\n",
      "loss: 0.148217 [ 4800/ 5994]\n",
      "Total accuracy: 0.0123456790%\n",
      "Training Loss: 0.0851, Training Accuracy: 96.6594%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2586, Test Accuracy: 91.1421%\n",
      "Epoch 110/1000-------------------\n",
      "loss: 0.161730 [    0/ 5994]\n",
      "loss: 0.182149 [ 1600/ 5994]\n",
      "loss: 0.169890 [ 3200/ 5994]\n",
      "loss: 0.187050 [ 4800/ 5994]\n",
      "Total accuracy: 0.0135135135%\n",
      "Training Loss: 0.0841, Training Accuracy: 96.7115%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2591, Test Accuracy: 91.2108%\n",
      "Epoch 111/1000-------------------\n",
      "loss: 0.154846 [    0/ 5994]\n",
      "loss: 0.157907 [ 1600/ 5994]\n",
      "loss: 0.193091 [ 3200/ 5994]\n",
      "loss: 0.151111 [ 4800/ 5994]\n",
      "Total accuracy: 0.0138471805%\n",
      "Training Loss: 0.0839, Training Accuracy: 96.7248%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2604, Test Accuracy: 91.2866%\n",
      "Epoch 112/1000-------------------\n",
      "loss: 0.131062 [    0/ 5994]\n",
      "loss: 0.147487 [ 1600/ 5994]\n",
      "loss: 0.172868 [ 3200/ 5994]\n",
      "loss: 0.147006 [ 4800/ 5994]\n",
      "Total accuracy: 0.0140140140%\n",
      "Training Loss: 0.0829, Training Accuracy: 96.7623%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2588, Test Accuracy: 91.2775%\n",
      "Epoch 113/1000-------------------\n",
      "loss: 0.130149 [    0/ 5994]\n",
      "loss: 0.128990 [ 1600/ 5994]\n",
      "loss: 0.133292 [ 3200/ 5994]\n",
      "loss: 0.143409 [ 4800/ 5994]\n",
      "Total accuracy: 0.0141808475%\n",
      "Training Loss: 0.0830, Training Accuracy: 96.7446%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2645, Test Accuracy: 91.2365%\n",
      "Epoch 114/1000-------------------\n",
      "loss: 0.187099 [    0/ 5994]\n",
      "loss: 0.148888 [ 1600/ 5994]\n",
      "loss: 0.142801 [ 3200/ 5994]\n",
      "loss: 0.181739 [ 4800/ 5994]\n",
      "Total accuracy: 0.0131798465%\n",
      "Training Loss: 0.0811, Training Accuracy: 96.8354%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2601, Test Accuracy: 91.1505%\n",
      "Epoch 115/1000-------------------\n",
      "loss: 0.149432 [    0/ 5994]\n",
      "loss: 0.144493 [ 1600/ 5994]\n",
      "loss: 0.163865 [ 3200/ 5994]\n",
      "loss: 0.141691 [ 4800/ 5994]\n",
      "Total accuracy: 0.0121788455%\n",
      "Training Loss: 0.0822, Training Accuracy: 96.7819%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2628, Test Accuracy: 91.2456%\n",
      "Epoch 116/1000-------------------\n",
      "loss: 0.174514 [    0/ 5994]\n",
      "loss: 0.188539 [ 1600/ 5994]\n",
      "loss: 0.177230 [ 3200/ 5994]\n",
      "loss: 0.133288 [ 4800/ 5994]\n",
      "Total accuracy: 0.0183516850%\n",
      "Training Loss: 0.0804, Training Accuracy: 96.8868%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2613, Test Accuracy: 91.1887%\n",
      "Epoch 117/1000-------------------\n",
      "loss: 0.148622 [    0/ 5994]\n",
      "loss: 0.152436 [ 1600/ 5994]\n",
      "loss: 0.163202 [ 3200/ 5994]\n",
      "loss: 0.157699 [ 4800/ 5994]\n",
      "Total accuracy: 0.0180180180%\n",
      "Training Loss: 0.0780, Training Accuracy: 96.9846%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2607, Test Accuracy: 91.2308%\n",
      "Epoch 118/1000-------------------\n",
      "loss: 0.149333 [    0/ 5994]\n",
      "loss: 0.139530 [ 1600/ 5994]\n",
      "loss: 0.136004 [ 3200/ 5994]\n",
      "loss: 0.128073 [ 4800/ 5994]\n",
      "Total accuracy: 0.0198531865%\n",
      "Training Loss: 0.0796, Training Accuracy: 96.9077%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2644, Test Accuracy: 91.2620%\n",
      "Epoch 119/1000-------------------\n",
      "loss: 0.151929 [    0/ 5994]\n",
      "loss: 0.124159 [ 1600/ 5994]\n",
      "loss: 0.170584 [ 3200/ 5994]\n",
      "loss: 0.132349 [ 4800/ 5994]\n",
      "Total accuracy: 0.0216883550%\n",
      "Training Loss: 0.0785, Training Accuracy: 96.9614%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2603, Test Accuracy: 91.2305%\n",
      "Epoch 120/1000-------------------\n",
      "loss: 0.182421 [    0/ 5994]\n",
      "loss: 0.137757 [ 1600/ 5994]\n",
      "loss: 0.150110 [ 3200/ 5994]\n",
      "loss: 0.166763 [ 4800/ 5994]\n",
      "Total accuracy: 0.0203536870%\n",
      "Training Loss: 0.0786, Training Accuracy: 96.9533%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2611, Test Accuracy: 91.1438%\n",
      "Epoch 121/1000-------------------\n",
      "loss: 0.148567 [    0/ 5994]\n",
      "loss: 0.178780 [ 1600/ 5994]\n",
      "loss: 0.135381 [ 3200/ 5994]\n",
      "loss: 0.275029 [ 4800/ 5994]\n",
      "Total accuracy: 0.0236903570%\n",
      "Training Loss: 0.0794, Training Accuracy: 96.9378%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2632, Test Accuracy: 91.1348%\n",
      "Epoch 122/1000-------------------\n",
      "loss: 0.166787 [    0/ 5994]\n",
      "loss: 0.136731 [ 1600/ 5994]\n",
      "loss: 0.137354 [ 3200/ 5994]\n",
      "loss: 0.134894 [ 4800/ 5994]\n",
      "Total accuracy: 0.0215215215%\n",
      "Training Loss: 0.0767, Training Accuracy: 97.0370%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2625, Test Accuracy: 91.2609%\n",
      "Epoch 123/1000-------------------\n",
      "loss: 0.128045 [    0/ 5994]\n",
      "loss: 0.168527 [ 1600/ 5994]\n",
      "loss: 0.158970 [ 3200/ 5994]\n",
      "loss: 0.176611 [ 4800/ 5994]\n",
      "Total accuracy: 0.0261928595%\n",
      "Training Loss: 0.0752, Training Accuracy: 97.0876%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2705, Test Accuracy: 91.1597%\n",
      "Epoch 124/1000-------------------\n",
      "loss: 0.151778 [    0/ 5994]\n",
      "loss: 0.229754 [ 1600/ 5994]\n",
      "loss: 0.145952 [ 3200/ 5994]\n",
      "loss: 0.129457 [ 4800/ 5994]\n",
      "Total accuracy: 0.0253586920%\n",
      "Training Loss: 0.0759, Training Accuracy: 97.0595%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2645, Test Accuracy: 91.2499%\n",
      "Epoch 125/1000-------------------\n",
      "loss: 0.137044 [    0/ 5994]\n",
      "loss: 0.140802 [ 1600/ 5994]\n",
      "loss: 0.158646 [ 3200/ 5994]\n",
      "loss: 0.159318 [ 4800/ 5994]\n",
      "Total accuracy: 0.0241908575%\n",
      "Training Loss: 0.0744, Training Accuracy: 97.1037%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2654, Test Accuracy: 91.1871%\n",
      "Epoch 126/1000-------------------\n",
      "loss: 0.204389 [    0/ 5994]\n",
      "loss: 0.170962 [ 1600/ 5994]\n",
      "loss: 0.128114 [ 3200/ 5994]\n",
      "loss: 0.139239 [ 4800/ 5994]\n",
      "Total accuracy: 0.0310310310%\n",
      "Training Loss: 0.0754, Training Accuracy: 97.0997%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2658, Test Accuracy: 91.2085%\n",
      "Epoch 127/1000-------------------\n",
      "loss: 0.116362 [    0/ 5994]\n",
      "loss: 0.137580 [ 1600/ 5994]\n",
      "loss: 0.132998 [ 3200/ 5994]\n",
      "loss: 0.108951 [ 4800/ 5994]\n",
      "Total accuracy: 0.0305305305%\n",
      "Training Loss: 0.0734, Training Accuracy: 97.1571%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2667, Test Accuracy: 91.2202%\n",
      "Epoch 128/1000-------------------\n",
      "loss: 0.150498 [    0/ 5994]\n",
      "loss: 0.129880 [ 1600/ 5994]\n",
      "loss: 0.150901 [ 3200/ 5994]\n",
      "loss: 0.187137 [ 4800/ 5994]\n",
      "Total accuracy: 0.0316983650%\n",
      "Training Loss: 0.0739, Training Accuracy: 97.1342%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2660, Test Accuracy: 91.1977%\n",
      "Epoch 129/1000-------------------\n",
      "loss: 0.125393 [    0/ 5994]\n",
      "loss: 0.123220 [ 1600/ 5994]\n",
      "loss: 0.153843 [ 3200/ 5994]\n",
      "loss: 0.141726 [ 4800/ 5994]\n",
      "Total accuracy: 0.0333667000%\n",
      "Training Loss: 0.0727, Training Accuracy: 97.1822%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2727, Test Accuracy: 91.2233%\n",
      "Epoch 130/1000-------------------\n",
      "loss: 0.146130 [    0/ 5994]\n",
      "loss: 0.189728 [ 1600/ 5994]\n",
      "loss: 0.140693 [ 3200/ 5994]\n",
      "loss: 0.183178 [ 4800/ 5994]\n",
      "Total accuracy: 0.0320320320%\n",
      "Training Loss: 0.0703, Training Accuracy: 97.3013%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2640, Test Accuracy: 91.2632%\n",
      "Epoch 131/1000-------------------\n",
      "loss: 0.108146 [    0/ 5994]\n",
      "loss: 0.184221 [ 1600/ 5994]\n",
      "loss: 0.146770 [ 3200/ 5994]\n",
      "loss: 0.153369 [ 4800/ 5994]\n",
      "Total accuracy: 0.0355355355%\n",
      "Training Loss: 0.0706, Training Accuracy: 97.2813%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2684, Test Accuracy: 91.1237%\n",
      "Epoch 132/1000-------------------\n",
      "loss: 0.150897 [    0/ 5994]\n",
      "loss: 0.139099 [ 1600/ 5994]\n",
      "loss: 0.131236 [ 3200/ 5994]\n",
      "loss: 0.106065 [ 4800/ 5994]\n",
      "Total accuracy: 0.0373707040%\n",
      "Training Loss: 0.0690, Training Accuracy: 97.3548%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2693, Test Accuracy: 91.1814%\n",
      "Epoch 133/1000-------------------\n",
      "loss: 0.131499 [    0/ 5994]\n",
      "loss: 0.139924 [ 1600/ 5994]\n",
      "loss: 0.136168 [ 3200/ 5994]\n",
      "loss: 0.212051 [ 4800/ 5994]\n",
      "Total accuracy: 0.0420420420%\n",
      "Training Loss: 0.0706, Training Accuracy: 97.2993%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2704, Test Accuracy: 91.2205%\n",
      "Epoch 134/1000-------------------\n",
      "loss: 0.120948 [    0/ 5994]\n",
      "loss: 0.153298 [ 1600/ 5994]\n",
      "loss: 0.130791 [ 3200/ 5994]\n",
      "loss: 0.126658 [ 4800/ 5994]\n",
      "Total accuracy: 0.0393727060%\n",
      "Training Loss: 0.0694, Training Accuracy: 97.3294%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2705, Test Accuracy: 91.1300%\n",
      "Epoch 135/1000-------------------\n",
      "loss: 0.127001 [    0/ 5994]\n",
      "loss: 0.158986 [ 1600/ 5994]\n",
      "loss: 0.121181 [ 3200/ 5994]\n",
      "loss: 0.124716 [ 4800/ 5994]\n",
      "Total accuracy: 0.0408742075%\n",
      "Training Loss: 0.0685, Training Accuracy: 97.3606%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2722, Test Accuracy: 91.1603%\n",
      "Epoch 136/1000-------------------\n",
      "loss: 0.114851 [    0/ 5994]\n",
      "loss: 0.150935 [ 1600/ 5994]\n",
      "loss: 0.132200 [ 3200/ 5994]\n",
      "loss: 0.117389 [ 4800/ 5994]\n",
      "Total accuracy: 0.0407073740%\n",
      "Training Loss: 0.0691, Training Accuracy: 97.3550%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2664, Test Accuracy: 91.1271%\n",
      "Epoch 137/1000-------------------\n",
      "loss: 0.165832 [    0/ 5994]\n",
      "loss: 0.126833 [ 1600/ 5994]\n",
      "loss: 0.124358 [ 3200/ 5994]\n",
      "loss: 0.111232 [ 4800/ 5994]\n",
      "Total accuracy: 0.0452118785%\n",
      "Training Loss: 0.0673, Training Accuracy: 97.4260%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2701, Test Accuracy: 91.1770%\n",
      "Epoch 138/1000-------------------\n",
      "loss: 0.149302 [    0/ 5994]\n",
      "loss: 0.124477 [ 1600/ 5994]\n",
      "loss: 0.142776 [ 3200/ 5994]\n",
      "loss: 0.142827 [ 4800/ 5994]\n",
      "Total accuracy: 0.0387053720%\n",
      "Training Loss: 0.0677, Training Accuracy: 97.3789%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2744, Test Accuracy: 91.1573%\n",
      "Epoch 139/1000-------------------\n",
      "loss: 0.146369 [    0/ 5994]\n",
      "loss: 0.112634 [ 1600/ 5994]\n",
      "loss: 0.126886 [ 3200/ 5994]\n",
      "loss: 0.141409 [ 4800/ 5994]\n",
      "Total accuracy: 0.0495495495%\n",
      "Training Loss: 0.0663, Training Accuracy: 97.4780%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2711, Test Accuracy: 91.2572%\n",
      "Epoch 140/1000-------------------\n",
      "loss: 0.125068 [    0/ 5994]\n",
      "loss: 0.140577 [ 1600/ 5994]\n",
      "loss: 0.191236 [ 3200/ 5994]\n",
      "loss: 0.176039 [ 4800/ 5994]\n",
      "Total accuracy: 0.0547213881%\n",
      "Training Loss: 0.0657, Training Accuracy: 97.4859%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2693, Test Accuracy: 91.1947%\n",
      "Epoch 141/1000-------------------\n",
      "loss: 0.126272 [    0/ 5994]\n",
      "loss: 0.130963 [ 1600/ 5994]\n",
      "loss: 0.129669 [ 3200/ 5994]\n",
      "loss: 0.114307 [ 4800/ 5994]\n",
      "Total accuracy: 0.0500500501%\n",
      "Training Loss: 0.0661, Training Accuracy: 97.4650%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2739, Test Accuracy: 91.1333%\n",
      "Epoch 142/1000-------------------\n",
      "loss: 0.126913 [    0/ 5994]\n",
      "loss: 0.124184 [ 1600/ 5994]\n",
      "loss: 0.140589 [ 3200/ 5994]\n",
      "loss: 0.151182 [ 4800/ 5994]\n",
      "Total accuracy: 0.0552218886%\n",
      "Training Loss: 0.0675, Training Accuracy: 97.4217%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2743, Test Accuracy: 91.2346%\n",
      "Epoch 143/1000-------------------\n",
      "loss: 0.124268 [    0/ 5994]\n",
      "loss: 0.128880 [ 1600/ 5994]\n",
      "loss: 0.149461 [ 3200/ 5994]\n",
      "loss: 0.151846 [ 4800/ 5994]\n",
      "Total accuracy: 0.0598932266%\n",
      "Training Loss: 0.0632, Training Accuracy: 97.5930%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2761, Test Accuracy: 91.2357%\n",
      "Epoch 144/1000-------------------\n",
      "loss: 0.128635 [    0/ 5994]\n",
      "loss: 0.152892 [ 1600/ 5994]\n",
      "loss: 0.139990 [ 3200/ 5994]\n",
      "loss: 0.151623 [ 4800/ 5994]\n",
      "Total accuracy: 0.0607273941%\n",
      "Training Loss: 0.0632, Training Accuracy: 97.5912%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2740, Test Accuracy: 91.1834%\n",
      "Epoch 145/1000-------------------\n",
      "loss: 0.148562 [    0/ 5994]\n",
      "loss: 0.117741 [ 1600/ 5994]\n",
      "loss: 0.126259 [ 3200/ 5994]\n",
      "loss: 0.147949 [ 4800/ 5994]\n",
      "Total accuracy: 0.0592258926%\n",
      "Training Loss: 0.0621, Training Accuracy: 97.6074%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2800, Test Accuracy: 91.1838%\n",
      "Epoch 146/1000-------------------\n",
      "loss: 0.120557 [    0/ 5994]\n",
      "loss: 0.167494 [ 1600/ 5994]\n",
      "loss: 0.168353 [ 3200/ 5994]\n",
      "loss: 0.124969 [ 4800/ 5994]\n",
      "Total accuracy: 0.0570570571%\n",
      "Training Loss: 0.0625, Training Accuracy: 97.6172%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2719, Test Accuracy: 91.1069%\n",
      "Epoch 147/1000-------------------\n",
      "loss: 0.102903 [    0/ 5994]\n",
      "loss: 0.113009 [ 1600/ 5994]\n",
      "loss: 0.161307 [ 3200/ 5994]\n",
      "loss: 0.111040 [ 4800/ 5994]\n",
      "Total accuracy: 0.0638972306%\n",
      "Training Loss: 0.0619, Training Accuracy: 97.6380%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2757, Test Accuracy: 91.2781%\n",
      "Epoch 148/1000-------------------\n",
      "loss: 0.121886 [    0/ 5994]\n",
      "loss: 0.107016 [ 1600/ 5994]\n",
      "loss: 0.111529 [ 3200/ 5994]\n",
      "loss: 0.128146 [ 4800/ 5994]\n",
      "Total accuracy: 0.0632298966%\n",
      "Training Loss: 0.0598, Training Accuracy: 97.7126%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2815, Test Accuracy: 91.1720%\n",
      "Epoch 149/1000-------------------\n",
      "loss: 0.177886 [    0/ 5994]\n",
      "loss: 0.122283 [ 1600/ 5994]\n",
      "loss: 0.117738 [ 3200/ 5994]\n",
      "loss: 0.131754 [ 4800/ 5994]\n",
      "Total accuracy: 0.0682349016%\n",
      "Training Loss: 0.0621, Training Accuracy: 97.6356%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2734, Test Accuracy: 91.2317%\n",
      "Epoch 150/1000-------------------\n",
      "loss: 0.149170 [    0/ 5994]\n",
      "loss: 0.138567 [ 1600/ 5994]\n",
      "loss: 0.104750 [ 3200/ 5994]\n",
      "loss: 0.164257 [ 4800/ 5994]\n",
      "Total accuracy: 0.0725725726%\n",
      "Training Loss: 0.0604, Training Accuracy: 97.7033%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2774, Test Accuracy: 91.1334%\n",
      "Epoch 151/1000-------------------\n",
      "loss: 0.128849 [    0/ 5994]\n",
      "loss: 0.131108 [ 1600/ 5994]\n",
      "loss: 0.138976 [ 3200/ 5994]\n",
      "loss: 0.122131 [ 4800/ 5994]\n",
      "Total accuracy: 0.0705705706%\n",
      "Training Loss: 0.0603, Training Accuracy: 97.7143%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2759, Test Accuracy: 91.1654%\n",
      "Epoch 152/1000-------------------\n",
      "loss: 0.103214 [    0/ 5994]\n",
      "loss: 0.109190 [ 1600/ 5994]\n",
      "loss: 0.111817 [ 3200/ 5994]\n",
      "loss: 0.147460 [ 4800/ 5994]\n",
      "Total accuracy: 0.0762429096%\n",
      "Training Loss: 0.0589, Training Accuracy: 97.7656%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2821, Test Accuracy: 91.1821%\n",
      "Epoch 153/1000-------------------\n",
      "loss: 0.128236 [    0/ 5994]\n",
      "loss: 0.112404 [ 1600/ 5994]\n",
      "loss: 0.136388 [ 3200/ 5994]\n",
      "loss: 0.188038 [ 4800/ 5994]\n",
      "Total accuracy: 0.0777444111%\n",
      "Training Loss: 0.0590, Training Accuracy: 97.7660%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2775, Test Accuracy: 91.0970%\n",
      "Epoch 154/1000-------------------\n",
      "loss: 0.108829 [    0/ 5994]\n",
      "loss: 0.175111 [ 1600/ 5994]\n",
      "loss: 0.100629 [ 3200/ 5994]\n",
      "loss: 0.164100 [ 4800/ 5994]\n",
      "Total accuracy: 0.0824157491%\n",
      "Training Loss: 0.0597, Training Accuracy: 97.7402%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2770, Test Accuracy: 91.1232%\n",
      "Epoch 155/1000-------------------\n",
      "loss: 0.145660 [    0/ 5994]\n",
      "loss: 0.160199 [ 1600/ 5994]\n",
      "loss: 0.107546 [ 3200/ 5994]\n",
      "loss: 0.117897 [ 4800/ 5994]\n",
      "Total accuracy: 0.0837504171%\n",
      "Training Loss: 0.0585, Training Accuracy: 97.7741%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2763, Test Accuracy: 91.1068%\n",
      "Epoch 156/1000-------------------\n",
      "loss: 0.128974 [    0/ 5994]\n",
      "loss: 0.122757 [ 1600/ 5994]\n",
      "loss: 0.165837 [ 3200/ 5994]\n",
      "loss: 0.133625 [ 4800/ 5994]\n",
      "Total accuracy: 0.0852519186%\n",
      "Training Loss: 0.0576, Training Accuracy: 97.8246%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2816, Test Accuracy: 91.1161%\n",
      "Epoch 157/1000-------------------\n",
      "loss: 0.148024 [    0/ 5994]\n",
      "loss: 0.156193 [ 1600/ 5994]\n",
      "loss: 0.144409 [ 3200/ 5994]\n",
      "loss: 0.082433 [ 4800/ 5994]\n",
      "Total accuracy: 0.0974307641%\n",
      "Training Loss: 0.0585, Training Accuracy: 97.7916%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2791, Test Accuracy: 91.1751%\n",
      "Epoch 158/1000-------------------\n",
      "loss: 0.101289 [    0/ 5994]\n",
      "loss: 0.141906 [ 1600/ 5994]\n",
      "loss: 0.142807 [ 3200/ 5994]\n",
      "loss: 0.125632 [ 4800/ 5994]\n",
      "Total accuracy: 0.0939272606%\n",
      "Training Loss: 0.0577, Training Accuracy: 97.7965%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2865, Test Accuracy: 91.0931%\n",
      "Epoch 159/1000-------------------\n",
      "loss: 0.125846 [    0/ 5994]\n",
      "loss: 0.123857 [ 1600/ 5994]\n",
      "loss: 0.165022 [ 3200/ 5994]\n",
      "loss: 0.129754 [ 4800/ 5994]\n",
      "Total accuracy: 0.1002669336%\n",
      "Training Loss: 0.0557, Training Accuracy: 97.9081%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2776, Test Accuracy: 91.1643%\n",
      "Epoch 160/1000-------------------\n",
      "loss: 0.111487 [    0/ 5994]\n",
      "loss: 0.193672 [ 1600/ 5994]\n",
      "loss: 0.134283 [ 3200/ 5994]\n",
      "loss: 0.142263 [ 4800/ 5994]\n",
      "Total accuracy: 0.0947614281%\n",
      "Training Loss: 0.0561, Training Accuracy: 97.8788%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2801, Test Accuracy: 91.1407%\n",
      "Epoch 161/1000-------------------\n",
      "loss: 0.122896 [    0/ 5994]\n",
      "loss: 0.124538 [ 1600/ 5994]\n",
      "loss: 0.166864 [ 3200/ 5994]\n",
      "loss: 0.126357 [ 4800/ 5994]\n",
      "Total accuracy: 0.1062729396%\n",
      "Training Loss: 0.0553, Training Accuracy: 97.9055%\n",
      "Total accuracy: 0.0003451847%\n",
      "Test Loss: 0.2843, Test Accuracy: 91.2018%\n",
      "Epoch 162/1000-------------------\n",
      "loss: 0.107620 [    0/ 5994]\n",
      "loss: 0.129358 [ 1600/ 5994]\n",
      "loss: 0.107746 [ 3200/ 5994]\n",
      "loss: 0.150357 [ 4800/ 5994]\n",
      "Total accuracy: 0.1056056056%\n",
      "Training Loss: 0.0562, Training Accuracy: 97.8666%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2813, Test Accuracy: 91.1583%\n",
      "Epoch 163/1000-------------------\n",
      "loss: 0.139698 [    0/ 5994]\n",
      "loss: 0.125319 [ 1600/ 5994]\n",
      "loss: 0.115630 [ 3200/ 5994]\n",
      "loss: 0.145793 [ 4800/ 5994]\n",
      "Total accuracy: 0.1056056056%\n",
      "Training Loss: 0.0549, Training Accuracy: 97.9257%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2828, Test Accuracy: 91.1395%\n",
      "Epoch 164/1000-------------------\n",
      "loss: 0.125880 [    0/ 5994]\n",
      "loss: 0.106075 [ 1600/ 5994]\n",
      "loss: 0.125055 [ 3200/ 5994]\n",
      "loss: 0.139990 [ 4800/ 5994]\n",
      "Total accuracy: 0.1096096096%\n",
      "Training Loss: 0.0540, Training Accuracy: 97.9656%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2819, Test Accuracy: 91.1716%\n",
      "Epoch 165/1000-------------------\n",
      "loss: 0.117839 [    0/ 5994]\n",
      "loss: 0.143602 [ 1600/ 5994]\n",
      "loss: 0.177174 [ 3200/ 5994]\n",
      "loss: 0.116945 [ 4800/ 5994]\n",
      "Total accuracy: 0.1119452786%\n",
      "Training Loss: 0.0537, Training Accuracy: 97.9664%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2852, Test Accuracy: 91.1212%\n",
      "Epoch 166/1000-------------------\n",
      "loss: 0.127675 [    0/ 5994]\n",
      "loss: 0.105210 [ 1600/ 5994]\n",
      "loss: 0.104199 [ 3200/ 5994]\n",
      "loss: 0.132532 [ 4800/ 5994]\n",
      "Total accuracy: 0.1134467801%\n",
      "Training Loss: 0.0546, Training Accuracy: 97.9236%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2830, Test Accuracy: 91.2081%\n",
      "Epoch 167/1000-------------------\n",
      "loss: 0.123244 [    0/ 5994]\n",
      "loss: 0.118063 [ 1600/ 5994]\n",
      "loss: 0.137555 [ 3200/ 5994]\n",
      "loss: 0.156899 [ 4800/ 5994]\n",
      "Total accuracy: 0.1214547881%\n",
      "Training Loss: 0.0521, Training Accuracy: 98.0398%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2878, Test Accuracy: 91.1327%\n",
      "Epoch 168/1000-------------------\n",
      "loss: 0.158926 [    0/ 5994]\n",
      "loss: 0.154053 [ 1600/ 5994]\n",
      "loss: 0.111545 [ 3200/ 5994]\n",
      "loss: 0.120984 [ 4800/ 5994]\n",
      "Total accuracy: 0.1314647981%\n",
      "Training Loss: 0.0529, Training Accuracy: 98.0185%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2816, Test Accuracy: 91.1120%\n",
      "Epoch 169/1000-------------------\n",
      "loss: 0.178582 [    0/ 5994]\n",
      "loss: 0.126126 [ 1600/ 5994]\n",
      "loss: 0.124656 [ 3200/ 5994]\n",
      "loss: 0.124384 [ 4800/ 5994]\n",
      "Total accuracy: 0.1261261261%\n",
      "Training Loss: 0.0514, Training Accuracy: 98.0490%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2899, Test Accuracy: 91.1170%\n",
      "Epoch 170/1000-------------------\n",
      "loss: 0.116929 [    0/ 5994]\n",
      "loss: 0.170673 [ 1600/ 5994]\n",
      "loss: 0.133900 [ 3200/ 5994]\n",
      "loss: 0.123515 [ 4800/ 5994]\n",
      "Total accuracy: 0.1277944611%\n",
      "Training Loss: 0.0529, Training Accuracy: 98.0106%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2834, Test Accuracy: 91.0860%\n",
      "Epoch 171/1000-------------------\n",
      "loss: 0.122165 [    0/ 5994]\n",
      "loss: 0.132735 [ 1600/ 5994]\n",
      "loss: 0.123499 [ 3200/ 5994]\n",
      "loss: 0.085827 [ 4800/ 5994]\n",
      "Total accuracy: 0.1344678011%\n",
      "Training Loss: 0.0514, Training Accuracy: 98.0676%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2867, Test Accuracy: 91.1004%\n",
      "Epoch 172/1000-------------------\n",
      "loss: 0.117263 [    0/ 5994]\n",
      "loss: 0.096701 [ 1600/ 5994]\n",
      "loss: 0.147204 [ 3200/ 5994]\n",
      "loss: 0.169114 [ 4800/ 5994]\n",
      "Total accuracy: 0.1307974641%\n",
      "Training Loss: 0.0518, Training Accuracy: 98.0479%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2866, Test Accuracy: 91.0836%\n",
      "Epoch 173/1000-------------------\n",
      "loss: 0.136875 [    0/ 5994]\n",
      "loss: 0.079364 [ 1600/ 5994]\n",
      "loss: 0.154284 [ 3200/ 5994]\n",
      "loss: 0.147208 [ 4800/ 5994]\n",
      "Total accuracy: 0.1428094761%\n",
      "Training Loss: 0.0506, Training Accuracy: 98.1126%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2808, Test Accuracy: 91.1055%\n",
      "Epoch 174/1000-------------------\n",
      "loss: 0.146207 [    0/ 5994]\n",
      "loss: 0.081009 [ 1600/ 5994]\n",
      "loss: 0.147400 [ 3200/ 5994]\n",
      "loss: 0.138282 [ 4800/ 5994]\n",
      "Total accuracy: 0.1434768101%\n",
      "Training Loss: 0.0501, Training Accuracy: 98.1175%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2937, Test Accuracy: 91.1545%\n",
      "Epoch 175/1000-------------------\n",
      "loss: 0.115001 [    0/ 5994]\n",
      "loss: 0.143526 [ 1600/ 5994]\n",
      "loss: 0.128396 [ 3200/ 5994]\n",
      "loss: 0.137266 [ 4800/ 5994]\n",
      "Total accuracy: 0.1468134801%\n",
      "Training Loss: 0.0504, Training Accuracy: 98.1323%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2849, Test Accuracy: 91.1280%\n",
      "Epoch 176/1000-------------------\n",
      "loss: 0.131183 [    0/ 5994]\n",
      "loss: 0.112763 [ 1600/ 5994]\n",
      "loss: 0.147636 [ 3200/ 5994]\n",
      "loss: 0.130432 [ 4800/ 5994]\n",
      "Total accuracy: 0.1539873207%\n",
      "Training Loss: 0.0517, Training Accuracy: 98.0617%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2841, Test Accuracy: 91.1950%\n",
      "Epoch 177/1000-------------------\n",
      "loss: 0.091008 [    0/ 5994]\n",
      "loss: 0.102049 [ 1600/ 5994]\n",
      "loss: 0.123937 [ 3200/ 5994]\n",
      "loss: 0.104774 [ 4800/ 5994]\n",
      "Total accuracy: 0.1459793126%\n",
      "Training Loss: 0.0503, Training Accuracy: 98.1232%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2888, Test Accuracy: 91.1477%\n",
      "Epoch 178/1000-------------------\n",
      "loss: 0.104937 [    0/ 5994]\n",
      "loss: 0.106248 [ 1600/ 5994]\n",
      "loss: 0.112693 [ 3200/ 5994]\n",
      "loss: 0.112784 [ 4800/ 5994]\n",
      "Total accuracy: 0.1573239907%\n",
      "Training Loss: 0.0507, Training Accuracy: 98.1209%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2822, Test Accuracy: 91.1396%\n",
      "Epoch 179/1000-------------------\n",
      "loss: 0.110569 [    0/ 5994]\n",
      "loss: 0.118559 [ 1600/ 5994]\n",
      "loss: 0.152126 [ 3200/ 5994]\n",
      "loss: 0.104846 [ 4800/ 5994]\n",
      "Total accuracy: 0.1693360027%\n",
      "Training Loss: 0.0487, Training Accuracy: 98.1826%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2879, Test Accuracy: 91.1505%\n",
      "Epoch 180/1000-------------------\n",
      "loss: 0.161070 [    0/ 5994]\n",
      "loss: 0.166827 [ 1600/ 5994]\n",
      "loss: 0.118406 [ 3200/ 5994]\n",
      "loss: 0.114626 [ 4800/ 5994]\n",
      "Total accuracy: 0.1641641642%\n",
      "Training Loss: 0.0493, Training Accuracy: 98.1862%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2806, Test Accuracy: 90.9969%\n",
      "Epoch 181/1000-------------------\n",
      "loss: 0.117141 [    0/ 5994]\n",
      "loss: 0.182746 [ 1600/ 5994]\n",
      "loss: 0.103889 [ 3200/ 5994]\n",
      "loss: 0.126881 [ 4800/ 5994]\n",
      "Total accuracy: 0.1663329997%\n",
      "Training Loss: 0.0487, Training Accuracy: 98.1801%\n",
      "Total accuracy: 0.0001725923%\n",
      "Test Loss: 0.2895, Test Accuracy: 91.0536%\n",
      "Epoch 182/1000-------------------\n",
      "loss: 0.124840 [    0/ 5994]\n",
      "loss: 0.134296 [ 1600/ 5994]\n",
      "loss: 0.126180 [ 3200/ 5994]\n",
      "loss: 0.121960 [ 4800/ 5994]\n",
      "Total accuracy: 0.1644978312%\n",
      "Training Loss: 0.0487, Training Accuracy: 98.1728%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2937, Test Accuracy: 91.2455%\n",
      "Epoch 183/1000-------------------\n",
      "loss: 0.132041 [    0/ 5994]\n",
      "loss: 0.121367 [ 1600/ 5994]\n",
      "loss: 0.119100 [ 3200/ 5994]\n",
      "loss: 0.145085 [ 4800/ 5994]\n",
      "Total accuracy: 0.1810143477%\n",
      "Training Loss: 0.0462, Training Accuracy: 98.2675%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2935, Test Accuracy: 91.1127%\n",
      "Epoch 184/1000-------------------\n",
      "loss: 0.132134 [    0/ 5994]\n",
      "loss: 0.100025 [ 1600/ 5994]\n",
      "loss: 0.095112 [ 3200/ 5994]\n",
      "loss: 0.110692 [ 4800/ 5994]\n",
      "Total accuracy: 0.1845178512%\n",
      "Training Loss: 0.0461, Training Accuracy: 98.2961%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2913, Test Accuracy: 91.1284%\n",
      "Epoch 185/1000-------------------\n",
      "loss: 0.090788 [    0/ 5994]\n",
      "loss: 0.132618 [ 1600/ 5994]\n",
      "loss: 0.131725 [ 3200/ 5994]\n",
      "loss: 0.103497 [ 4800/ 5994]\n",
      "Total accuracy: 0.1901901902%\n",
      "Training Loss: 0.0469, Training Accuracy: 98.2526%\n",
      "Total accuracy: 0.0000000000%\n",
      "Test Loss: 0.2883, Test Accuracy: 91.1354%\n",
      "Epoch 186/1000-------------------\n",
      "loss: 0.094684 [    0/ 5994]\n",
      "loss: 0.084052 [ 1600/ 5994]\n",
      "loss: 0.096742 [ 3200/ 5994]\n",
      "loss: 0.112291 [ 4800/ 5994]\n",
      "Total accuracy: 0.1940273607%\n",
      "Training Loss: 0.0462, Training Accuracy: 98.2812%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m test_fn: TestFn \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m model, dataloader: test(model, dataloader, loss_fn, device)\n\u001b[1;32m     12\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[0;32m---> 14\u001b[0m run_epochs(\n\u001b[1;32m     15\u001b[0m     epochs,\n\u001b[1;32m     16\u001b[0m     model,\n\u001b[1;32m     17\u001b[0m     train_fn,\n\u001b[1;32m     18\u001b[0m     test_fn,\n\u001b[1;32m     19\u001b[0m     training_dataloader,\n\u001b[1;32m     20\u001b[0m     test_dataloader,\n\u001b[1;32m     21\u001b[0m     save_name\u001b[39m=\u001b[39;49mINDEPENDENT_IMAGE_TO_ATTRIBUTES_MODEL_NAME,\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/interactive-concept-bottleneck/src/concept_bottleneck/train.py:35\u001b[0m, in \u001b[0;36mrun_epochs\u001b[0;34m(epochs, model, train, test, training_dataloader, test_dataloader, save_name)\u001b[0m\n\u001b[1;32m     30\u001b[0m training_loss, training_acc \u001b[39m=\u001b[39m test(model, training_dataloader)\n\u001b[1;32m     31\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[1;32m     32\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining Loss: \u001b[39m\u001b[39m{\u001b[39;00mtraining_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Training Accuracy: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m100\u001b[39m \u001b[39m*\u001b[39m training_acc\u001b[39m:\u001b[39;00m\u001b[39m>0.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m )\n\u001b[0;32m---> 35\u001b[0m test_loss, test_acc \u001b[39m=\u001b[39m test(model, test_dataloader)\n\u001b[1;32m     36\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTest Loss: \u001b[39m\u001b[39m{\u001b[39;00mtest_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Test Accuracy: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m100\u001b[39m \u001b[39m*\u001b[39m test_acc\u001b[39m:\u001b[39;00m\u001b[39m>0.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[39mif\u001b[39;00m test_acc \u001b[39m>\u001b[39m best_acc:\n",
      "Cell \u001b[0;32mIn [4], line 10\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m      5\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m)\n\u001b[1;32m      7\u001b[0m train_fn: TrainFn \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m model: train(\n\u001b[1;32m      8\u001b[0m     model, training_dataloader, loss_fn, optimizer, device\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m test_fn: TestFn \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m model, dataloader: test(model, dataloader, loss_fn, device)\n\u001b[1;32m     12\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m     14\u001b[0m run_epochs(\n\u001b[1;32m     15\u001b[0m     epochs,\n\u001b[1;32m     16\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     save_name\u001b[39m=\u001b[39mINDEPENDENT_IMAGE_TO_ATTRIBUTES_MODEL_NAME,\n\u001b[1;32m     22\u001b[0m )\n",
      "Cell \u001b[0;32mIn [3], line 42\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, dataloader, loss_fn, device)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m     41\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 42\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     44\u001b[0m     logits \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     45\u001b[0m     test_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_fn(logits, y)\u001b[39m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.concept_bottleneck.train import TrainFn, TestFn, run_epochs\n",
    "from src.concept_bottleneck.inference import INDEPENDENT_IMAGE_TO_ATTRIBUTES_MODEL_NAME\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "train_fn: TrainFn = lambda model: train(\n",
    "    model, training_dataloader, loss_fn, optimizer, device\n",
    ")\n",
    "test_fn: TestFn = lambda model, dataloader: test(model, dataloader, loss_fn, device)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "run_epochs(\n",
    "    epochs,\n",
    "    model,\n",
    "    train_fn,\n",
    "    test_fn,\n",
    "    training_dataloader,\n",
    "    test_dataloader,\n",
    "    save_name=INDEPENDENT_IMAGE_TO_ATTRIBUTES_MODEL_NAME,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d4040fe446a930194e7f49e706fe5ca82fc3ae21142ec3efeed3554a6698e7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
