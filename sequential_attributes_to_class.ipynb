{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.concept_bottleneck.dataset import CUB200ImageToClass\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 2\n",
    "\n",
    "training_data = CUB200ImageToClass(train=True)\n",
    "test_data = CUB200ImageToClass(train=False)\n",
    "\n",
    "training_dataloader = DataLoader(training_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from src.concept_bottleneck.networks import get_mlp\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = get_mlp().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: DataLoader[tuple[torch.Tensor, np.int_]],\n",
    "    trained_image_to_attributes_model: torch.nn.Module,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: str,\n",
    "):\n",
    "    model.train()\n",
    "    trained_image_to_attributes_model.eval()\n",
    "    size = len(dataloader.dataset)  # type: ignore\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x = trained_image_to_attributes_model(x.to(device))\n",
    "        y = y.to(device)\n",
    "\n",
    "        logits = model(torch.sigmoid(x))\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f\"loss: {loss.item():>7f} [{batch * len(x):>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: DataLoader[tuple[torch.Tensor, np.int_]],\n",
    "    trained_image_to_attributes_model: torch.nn.Module,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    device: str,\n",
    "):\n",
    "    model.eval()\n",
    "    trained_image_to_attributes_model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = trained_image_to_attributes_model(x.to(device))\n",
    "            y = y.to(device)\n",
    "\n",
    "            logits = model(torch.sigmoid(x))\n",
    "            test_loss += loss_fn(logits, y).item()\n",
    "            correct += (logits.argmax(dim=1) == y).sum().item()\n",
    "\n",
    "    test_loss /= len(dataloader)\n",
    "    accuracy = correct / len(dataloader.dataset)  # type: ignore\n",
    "\n",
    "    return test_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/shuangwu/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500-------------------\n",
      "loss: 5.357333 [    0/ 5994]\n",
      "loss: 4.265321 [ 1600/ 5994]\n",
      "loss: 3.860470 [ 3200/ 5994]\n",
      "loss: 3.470402 [ 4800/ 5994]\n",
      "Training Loss: 3.1721, Training Accuracy: 30.7307%\n",
      "Test Loss: 3.2647, Test Accuracy: 28.5640%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 28.5640%\n",
      "Epoch 2/500-------------------\n",
      "loss: 3.251681 [    0/ 5994]\n",
      "loss: 3.175524 [ 1600/ 5994]\n",
      "loss: 2.910761 [ 3200/ 5994]\n",
      "loss: 2.831971 [ 4800/ 5994]\n",
      "Training Loss: 2.5456, Training Accuracy: 39.7564%\n",
      "Test Loss: 2.6765, Test Accuracy: 37.5043%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 37.5043%\n",
      "Epoch 3/500-------------------\n",
      "loss: 2.357429 [    0/ 5994]\n",
      "loss: 2.444016 [ 1600/ 5994]\n",
      "loss: 2.105848 [ 3200/ 5994]\n",
      "loss: 2.401489 [ 4800/ 5994]\n",
      "Training Loss: 2.2636, Training Accuracy: 44.7447%\n",
      "Test Loss: 2.4183, Test Accuracy: 41.9054%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 41.9054%\n",
      "Epoch 4/500-------------------\n",
      "loss: 2.380240 [    0/ 5994]\n",
      "loss: 1.782041 [ 1600/ 5994]\n",
      "loss: 1.995786 [ 3200/ 5994]\n",
      "loss: 2.118485 [ 4800/ 5994]\n",
      "Training Loss: 2.0909, Training Accuracy: 47.2639%\n",
      "Test Loss: 2.2688, Test Accuracy: 43.0790%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 43.0790%\n",
      "Epoch 5/500-------------------\n",
      "loss: 2.380391 [    0/ 5994]\n",
      "loss: 2.340183 [ 1600/ 5994]\n",
      "loss: 2.416414 [ 3200/ 5994]\n",
      "loss: 2.260951 [ 4800/ 5994]\n",
      "Training Loss: 1.9593, Training Accuracy: 50.7007%\n",
      "Test Loss: 2.1481, Test Accuracy: 46.3410%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 46.3410%\n",
      "Epoch 6/500-------------------\n",
      "loss: 1.919529 [    0/ 5994]\n",
      "loss: 2.222448 [ 1600/ 5994]\n",
      "loss: 2.112647 [ 3200/ 5994]\n",
      "loss: 2.229271 [ 4800/ 5994]\n",
      "Training Loss: 1.8710, Training Accuracy: 51.6350%\n",
      "Test Loss: 2.0779, Test Accuracy: 45.9613%\n",
      "Epoch 7/500-------------------\n",
      "loss: 1.867617 [    0/ 5994]\n",
      "loss: 2.064787 [ 1600/ 5994]\n",
      "loss: 1.597039 [ 3200/ 5994]\n",
      "loss: 1.872998 [ 4800/ 5994]\n",
      "Training Loss: 1.7807, Training Accuracy: 54.0707%\n",
      "Test Loss: 1.9950, Test Accuracy: 48.8954%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 48.8954%\n",
      "Epoch 8/500-------------------\n",
      "loss: 2.562875 [    0/ 5994]\n",
      "loss: 1.744949 [ 1600/ 5994]\n",
      "loss: 2.178034 [ 3200/ 5994]\n",
      "loss: 1.712229 [ 4800/ 5994]\n",
      "Training Loss: 1.7350, Training Accuracy: 53.6537%\n",
      "Test Loss: 1.9609, Test Accuracy: 48.4122%\n",
      "Epoch 9/500-------------------\n",
      "loss: 1.566244 [    0/ 5994]\n",
      "loss: 1.681702 [ 1600/ 5994]\n",
      "loss: 1.261945 [ 3200/ 5994]\n",
      "loss: 1.985038 [ 4800/ 5994]\n",
      "Training Loss: 1.6824, Training Accuracy: 55.5722%\n",
      "Test Loss: 1.9224, Test Accuracy: 48.6710%\n",
      "Epoch 10/500-------------------\n",
      "loss: 1.962320 [    0/ 5994]\n",
      "loss: 1.672898 [ 1600/ 5994]\n",
      "loss: 2.133248 [ 3200/ 5994]\n",
      "loss: 1.815206 [ 4800/ 5994]\n",
      "Training Loss: 1.6300, Training Accuracy: 55.2553%\n",
      "Test Loss: 1.8794, Test Accuracy: 49.5167%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 49.5167%\n",
      "Epoch 11/500-------------------\n",
      "loss: 1.736927 [    0/ 5994]\n",
      "loss: 2.398107 [ 1600/ 5994]\n",
      "loss: 1.863440 [ 3200/ 5994]\n",
      "loss: 1.546102 [ 4800/ 5994]\n",
      "Training Loss: 1.5907, Training Accuracy: 57.3740%\n",
      "Test Loss: 1.8453, Test Accuracy: 50.5523%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 50.5523%\n",
      "Epoch 12/500-------------------\n",
      "loss: 1.829665 [    0/ 5994]\n",
      "loss: 0.873011 [ 1600/ 5994]\n",
      "loss: 1.445621 [ 3200/ 5994]\n",
      "loss: 1.633874 [ 4800/ 5994]\n",
      "Training Loss: 1.5607, Training Accuracy: 58.2249%\n",
      "Test Loss: 1.8225, Test Accuracy: 50.4660%\n",
      "Epoch 13/500-------------------\n",
      "loss: 1.701048 [    0/ 5994]\n",
      "loss: 1.734302 [ 1600/ 5994]\n",
      "loss: 1.276627 [ 3200/ 5994]\n",
      "loss: 1.325225 [ 4800/ 5994]\n",
      "Training Loss: 1.5339, Training Accuracy: 58.8255%\n",
      "Test Loss: 1.8058, Test Accuracy: 50.9147%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 50.9147%\n",
      "Epoch 14/500-------------------\n",
      "loss: 1.186451 [    0/ 5994]\n",
      "loss: 1.393851 [ 1600/ 5994]\n",
      "loss: 1.428992 [ 3200/ 5994]\n",
      "loss: 1.577607 [ 4800/ 5994]\n",
      "Training Loss: 1.4960, Training Accuracy: 58.8589%\n",
      "Test Loss: 1.7785, Test Accuracy: 51.6051%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 51.6051%\n",
      "Epoch 15/500-------------------\n",
      "loss: 1.851210 [    0/ 5994]\n",
      "loss: 1.701514 [ 1600/ 5994]\n",
      "loss: 1.214491 [ 3200/ 5994]\n",
      "loss: 1.961498 [ 4800/ 5994]\n",
      "Training Loss: 1.4746, Training Accuracy: 59.1592%\n",
      "Test Loss: 1.7639, Test Accuracy: 52.2092%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 52.2092%\n",
      "Epoch 16/500-------------------\n",
      "loss: 1.491876 [    0/ 5994]\n",
      "loss: 1.689244 [ 1600/ 5994]\n",
      "loss: 1.204481 [ 3200/ 5994]\n",
      "loss: 1.153531 [ 4800/ 5994]\n",
      "Training Loss: 1.4565, Training Accuracy: 59.9933%\n",
      "Test Loss: 1.7514, Test Accuracy: 51.5878%\n",
      "Epoch 17/500-------------------\n",
      "loss: 1.214164 [    0/ 5994]\n",
      "loss: 1.304147 [ 1600/ 5994]\n",
      "loss: 1.409191 [ 3200/ 5994]\n",
      "loss: 1.859763 [ 4800/ 5994]\n",
      "Training Loss: 1.4346, Training Accuracy: 60.6440%\n",
      "Test Loss: 1.7342, Test Accuracy: 52.8650%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 52.8650%\n",
      "Epoch 18/500-------------------\n",
      "loss: 0.917871 [    0/ 5994]\n",
      "loss: 1.054443 [ 1600/ 5994]\n",
      "loss: 1.059186 [ 3200/ 5994]\n",
      "loss: 1.142698 [ 4800/ 5994]\n",
      "Training Loss: 1.4169, Training Accuracy: 60.8942%\n",
      "Test Loss: 1.7263, Test Accuracy: 52.4853%\n",
      "Epoch 19/500-------------------\n",
      "loss: 1.279255 [    0/ 5994]\n",
      "loss: 1.639686 [ 1600/ 5994]\n",
      "loss: 1.795938 [ 3200/ 5994]\n",
      "loss: 1.654836 [ 4800/ 5994]\n",
      "Training Loss: 1.3836, Training Accuracy: 61.5949%\n",
      "Test Loss: 1.6964, Test Accuracy: 53.9696%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 53.9696%\n",
      "Epoch 20/500-------------------\n",
      "loss: 1.460329 [    0/ 5994]\n",
      "loss: 1.832535 [ 1600/ 5994]\n",
      "loss: 1.202097 [ 3200/ 5994]\n",
      "loss: 1.411328 [ 4800/ 5994]\n",
      "Training Loss: 1.3793, Training Accuracy: 61.7951%\n",
      "Test Loss: 1.7030, Test Accuracy: 53.1412%\n",
      "Epoch 21/500-------------------\n",
      "loss: 0.873076 [    0/ 5994]\n",
      "loss: 1.709342 [ 1600/ 5994]\n",
      "loss: 0.884929 [ 3200/ 5994]\n",
      "loss: 1.300355 [ 4800/ 5994]\n",
      "Training Loss: 1.3637, Training Accuracy: 61.5115%\n",
      "Test Loss: 1.6890, Test Accuracy: 52.8650%\n",
      "Epoch 22/500-------------------\n",
      "loss: 1.421799 [    0/ 5994]\n",
      "loss: 1.297353 [ 1600/ 5994]\n",
      "loss: 1.100332 [ 3200/ 5994]\n",
      "loss: 1.249988 [ 4800/ 5994]\n",
      "Training Loss: 1.3514, Training Accuracy: 62.1788%\n",
      "Test Loss: 1.6826, Test Accuracy: 53.4864%\n",
      "Epoch 23/500-------------------\n",
      "loss: 0.476359 [    0/ 5994]\n",
      "loss: 1.113772 [ 1600/ 5994]\n",
      "loss: 1.861455 [ 3200/ 5994]\n",
      "loss: 1.385242 [ 4800/ 5994]\n",
      "Training Loss: 1.3331, Training Accuracy: 62.8128%\n",
      "Test Loss: 1.6730, Test Accuracy: 53.4173%\n",
      "Epoch 24/500-------------------\n",
      "loss: 1.256954 [    0/ 5994]\n",
      "loss: 1.486589 [ 1600/ 5994]\n",
      "loss: 1.707319 [ 3200/ 5994]\n",
      "loss: 1.388671 [ 4800/ 5994]\n",
      "Training Loss: 1.3206, Training Accuracy: 62.6126%\n",
      "Test Loss: 1.6668, Test Accuracy: 52.9686%\n",
      "Epoch 25/500-------------------\n",
      "loss: 1.214422 [    0/ 5994]\n",
      "loss: 1.412967 [ 1600/ 5994]\n",
      "loss: 1.421983 [ 3200/ 5994]\n",
      "loss: 1.565542 [ 4800/ 5994]\n",
      "Training Loss: 1.3106, Training Accuracy: 63.2633%\n",
      "Test Loss: 1.6639, Test Accuracy: 53.8315%\n",
      "Epoch 26/500-------------------\n",
      "loss: 1.166413 [    0/ 5994]\n",
      "loss: 1.062681 [ 1600/ 5994]\n",
      "loss: 1.570180 [ 3200/ 5994]\n",
      "loss: 0.964358 [ 4800/ 5994]\n",
      "Training Loss: 1.2954, Training Accuracy: 63.0464%\n",
      "Test Loss: 1.6518, Test Accuracy: 53.5554%\n",
      "Epoch 27/500-------------------\n",
      "loss: 1.404718 [    0/ 5994]\n",
      "loss: 0.968796 [ 1600/ 5994]\n",
      "loss: 1.777339 [ 3200/ 5994]\n",
      "loss: 1.054195 [ 4800/ 5994]\n",
      "Training Loss: 1.2768, Training Accuracy: 64.2976%\n",
      "Test Loss: 1.6314, Test Accuracy: 54.3321%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 54.3321%\n",
      "Epoch 28/500-------------------\n",
      "loss: 1.497833 [    0/ 5994]\n",
      "loss: 1.247459 [ 1600/ 5994]\n",
      "loss: 1.369581 [ 3200/ 5994]\n",
      "loss: 1.518307 [ 4800/ 5994]\n",
      "Training Loss: 1.2619, Training Accuracy: 64.8148%\n",
      "Test Loss: 1.6257, Test Accuracy: 54.5219%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 54.5219%\n",
      "Epoch 29/500-------------------\n",
      "loss: 1.151688 [    0/ 5994]\n",
      "loss: 1.344731 [ 1600/ 5994]\n",
      "loss: 1.506259 [ 3200/ 5994]\n",
      "loss: 1.298533 [ 4800/ 5994]\n",
      "Training Loss: 1.2539, Training Accuracy: 65.4321%\n",
      "Test Loss: 1.6238, Test Accuracy: 54.9016%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 54.9016%\n",
      "Epoch 30/500-------------------\n",
      "loss: 1.508232 [    0/ 5994]\n",
      "loss: 0.869647 [ 1600/ 5994]\n",
      "loss: 1.034575 [ 3200/ 5994]\n",
      "loss: 1.046299 [ 4800/ 5994]\n",
      "Training Loss: 1.2483, Training Accuracy: 64.6480%\n",
      "Test Loss: 1.6176, Test Accuracy: 54.7118%\n",
      "Epoch 31/500-------------------\n",
      "loss: 1.452571 [    0/ 5994]\n",
      "loss: 1.465597 [ 1600/ 5994]\n",
      "loss: 0.821910 [ 3200/ 5994]\n",
      "loss: 1.224348 [ 4800/ 5994]\n",
      "Training Loss: 1.2384, Training Accuracy: 64.7648%\n",
      "Test Loss: 1.6084, Test Accuracy: 54.8153%\n",
      "Epoch 32/500-------------------\n",
      "loss: 1.286254 [    0/ 5994]\n",
      "loss: 1.689146 [ 1600/ 5994]\n",
      "loss: 1.868452 [ 3200/ 5994]\n",
      "loss: 1.259185 [ 4800/ 5994]\n",
      "Training Loss: 1.2426, Training Accuracy: 64.6647%\n",
      "Test Loss: 1.6230, Test Accuracy: 54.3838%\n",
      "Epoch 33/500-------------------\n",
      "loss: 1.456913 [    0/ 5994]\n",
      "loss: 0.990821 [ 1600/ 5994]\n",
      "loss: 0.879873 [ 3200/ 5994]\n",
      "loss: 1.050804 [ 4800/ 5994]\n",
      "Training Loss: 1.2238, Training Accuracy: 65.5155%\n",
      "Test Loss: 1.6092, Test Accuracy: 55.4884%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 55.4884%\n",
      "Epoch 34/500-------------------\n",
      "loss: 1.427971 [    0/ 5994]\n",
      "loss: 1.067220 [ 1600/ 5994]\n",
      "loss: 1.536262 [ 3200/ 5994]\n",
      "loss: 1.625090 [ 4800/ 5994]\n",
      "Training Loss: 1.2089, Training Accuracy: 65.7658%\n",
      "Test Loss: 1.5990, Test Accuracy: 55.7301%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 55.7301%\n",
      "Epoch 35/500-------------------\n",
      "loss: 1.329034 [    0/ 5994]\n",
      "loss: 1.680817 [ 1600/ 5994]\n",
      "loss: 1.494214 [ 3200/ 5994]\n",
      "loss: 1.652557 [ 4800/ 5994]\n",
      "Training Loss: 1.1963, Training Accuracy: 66.0327%\n",
      "Test Loss: 1.5940, Test Accuracy: 55.5230%\n",
      "Epoch 36/500-------------------\n",
      "loss: 0.838170 [    0/ 5994]\n",
      "loss: 0.913110 [ 1600/ 5994]\n",
      "loss: 1.534560 [ 3200/ 5994]\n",
      "loss: 1.075159 [ 4800/ 5994]\n",
      "Training Loss: 1.1944, Training Accuracy: 65.8992%\n",
      "Test Loss: 1.5893, Test Accuracy: 55.8336%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 55.8336%\n",
      "Epoch 37/500-------------------\n",
      "loss: 1.779186 [    0/ 5994]\n",
      "loss: 1.038143 [ 1600/ 5994]\n",
      "loss: 1.014281 [ 3200/ 5994]\n",
      "loss: 1.217088 [ 4800/ 5994]\n",
      "Training Loss: 1.1970, Training Accuracy: 66.4498%\n",
      "Test Loss: 1.6002, Test Accuracy: 55.1433%\n",
      "Epoch 38/500-------------------\n",
      "loss: 1.507898 [    0/ 5994]\n",
      "loss: 1.079639 [ 1600/ 5994]\n",
      "loss: 1.676590 [ 3200/ 5994]\n",
      "loss: 0.841676 [ 4800/ 5994]\n",
      "Training Loss: 1.1809, Training Accuracy: 66.8669%\n",
      "Test Loss: 1.5887, Test Accuracy: 54.7808%\n",
      "Epoch 39/500-------------------\n",
      "loss: 1.168324 [    0/ 5994]\n",
      "loss: 0.817477 [ 1600/ 5994]\n",
      "loss: 1.146549 [ 3200/ 5994]\n",
      "loss: 1.454133 [ 4800/ 5994]\n",
      "Training Loss: 1.1737, Training Accuracy: 65.7824%\n",
      "Test Loss: 1.5815, Test Accuracy: 55.7991%\n",
      "Epoch 40/500-------------------\n",
      "loss: 1.207428 [    0/ 5994]\n",
      "loss: 1.113275 [ 1600/ 5994]\n",
      "loss: 2.083344 [ 3200/ 5994]\n",
      "loss: 1.875690 [ 4800/ 5994]\n",
      "Training Loss: 1.1568, Training Accuracy: 67.3173%\n",
      "Test Loss: 1.5678, Test Accuracy: 56.1615%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 56.1615%\n",
      "Epoch 41/500-------------------\n",
      "loss: 1.564921 [    0/ 5994]\n",
      "loss: 1.152880 [ 1600/ 5994]\n",
      "loss: 1.374244 [ 3200/ 5994]\n",
      "loss: 1.691880 [ 4800/ 5994]\n",
      "Training Loss: 1.1521, Training Accuracy: 66.6667%\n",
      "Test Loss: 1.5692, Test Accuracy: 55.4367%\n",
      "Epoch 42/500-------------------\n",
      "loss: 0.757266 [    0/ 5994]\n",
      "loss: 0.910353 [ 1600/ 5994]\n",
      "loss: 0.587679 [ 3200/ 5994]\n",
      "loss: 1.310147 [ 4800/ 5994]\n",
      "Training Loss: 1.1525, Training Accuracy: 67.0337%\n",
      "Test Loss: 1.5702, Test Accuracy: 55.5920%\n",
      "Epoch 43/500-------------------\n",
      "loss: 1.216175 [    0/ 5994]\n",
      "loss: 1.205820 [ 1600/ 5994]\n",
      "loss: 1.396040 [ 3200/ 5994]\n",
      "loss: 0.896107 [ 4800/ 5994]\n",
      "Training Loss: 1.1469, Training Accuracy: 66.8836%\n",
      "Test Loss: 1.5722, Test Accuracy: 55.5575%\n",
      "Epoch 44/500-------------------\n",
      "loss: 1.103843 [    0/ 5994]\n",
      "loss: 0.860093 [ 1600/ 5994]\n",
      "loss: 1.266540 [ 3200/ 5994]\n",
      "loss: 0.796473 [ 4800/ 5994]\n",
      "Training Loss: 1.1413, Training Accuracy: 67.2840%\n",
      "Test Loss: 1.5739, Test Accuracy: 55.2641%\n",
      "Epoch 45/500-------------------\n",
      "loss: 0.665482 [    0/ 5994]\n",
      "loss: 1.352823 [ 1600/ 5994]\n",
      "loss: 1.193076 [ 3200/ 5994]\n",
      "loss: 1.177409 [ 4800/ 5994]\n",
      "Training Loss: 1.1248, Training Accuracy: 68.5185%\n",
      "Test Loss: 1.5578, Test Accuracy: 55.7991%\n",
      "Epoch 46/500-------------------\n",
      "loss: 1.495366 [    0/ 5994]\n",
      "loss: 1.027272 [ 1600/ 5994]\n",
      "loss: 1.250729 [ 3200/ 5994]\n",
      "loss: 1.666881 [ 4800/ 5994]\n",
      "Training Loss: 1.1246, Training Accuracy: 68.4518%\n",
      "Test Loss: 1.5556, Test Accuracy: 56.4204%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 56.4204%\n",
      "Epoch 47/500-------------------\n",
      "loss: 1.240281 [    0/ 5994]\n",
      "loss: 1.275451 [ 1600/ 5994]\n",
      "loss: 1.009100 [ 3200/ 5994]\n",
      "loss: 1.124985 [ 4800/ 5994]\n",
      "Training Loss: 1.1127, Training Accuracy: 68.0848%\n",
      "Test Loss: 1.5531, Test Accuracy: 56.3169%\n",
      "Epoch 48/500-------------------\n",
      "loss: 1.149288 [    0/ 5994]\n",
      "loss: 0.958376 [ 1600/ 5994]\n",
      "loss: 0.681545 [ 3200/ 5994]\n",
      "loss: 1.174768 [ 4800/ 5994]\n",
      "Training Loss: 1.1145, Training Accuracy: 67.9179%\n",
      "Test Loss: 1.5601, Test Accuracy: 56.0062%\n",
      "Epoch 49/500-------------------\n",
      "loss: 0.980511 [    0/ 5994]\n",
      "loss: 0.998040 [ 1600/ 5994]\n",
      "loss: 1.270471 [ 3200/ 5994]\n",
      "loss: 0.941617 [ 4800/ 5994]\n",
      "Training Loss: 1.1176, Training Accuracy: 68.1014%\n",
      "Test Loss: 1.5643, Test Accuracy: 55.2986%\n",
      "Epoch 50/500-------------------\n",
      "loss: 1.437419 [    0/ 5994]\n",
      "loss: 0.701573 [ 1600/ 5994]\n",
      "loss: 1.369381 [ 3200/ 5994]\n",
      "loss: 1.348115 [ 4800/ 5994]\n",
      "Training Loss: 1.1031, Training Accuracy: 67.9680%\n",
      "Test Loss: 1.5530, Test Accuracy: 55.8854%\n",
      "Epoch 51/500-------------------\n",
      "loss: 1.260888 [    0/ 5994]\n",
      "loss: 1.530234 [ 1600/ 5994]\n",
      "loss: 1.262466 [ 3200/ 5994]\n",
      "loss: 1.027948 [ 4800/ 5994]\n",
      "Training Loss: 1.1016, Training Accuracy: 68.5185%\n",
      "Test Loss: 1.5536, Test Accuracy: 56.2996%\n",
      "Epoch 52/500-------------------\n",
      "loss: 0.856168 [    0/ 5994]\n",
      "loss: 0.969894 [ 1600/ 5994]\n",
      "loss: 1.262897 [ 3200/ 5994]\n",
      "loss: 0.879298 [ 4800/ 5994]\n",
      "Training Loss: 1.0870, Training Accuracy: 68.7521%\n",
      "Test Loss: 1.5438, Test Accuracy: 56.5067%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 56.5067%\n",
      "Epoch 53/500-------------------\n",
      "loss: 0.799465 [    0/ 5994]\n",
      "loss: 0.869240 [ 1600/ 5994]\n",
      "loss: 0.846177 [ 3200/ 5994]\n",
      "loss: 0.928354 [ 4800/ 5994]\n",
      "Training Loss: 1.0796, Training Accuracy: 68.8188%\n",
      "Test Loss: 1.5352, Test Accuracy: 56.8174%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 56.8174%\n",
      "Epoch 54/500-------------------\n",
      "loss: 1.460781 [    0/ 5994]\n",
      "loss: 0.752997 [ 1600/ 5994]\n",
      "loss: 0.850375 [ 3200/ 5994]\n",
      "loss: 1.350297 [ 4800/ 5994]\n",
      "Training Loss: 1.0890, Training Accuracy: 68.2850%\n",
      "Test Loss: 1.5465, Test Accuracy: 56.3687%\n",
      "Epoch 55/500-------------------\n",
      "loss: 1.513196 [    0/ 5994]\n",
      "loss: 1.210913 [ 1600/ 5994]\n",
      "loss: 0.766166 [ 3200/ 5994]\n",
      "loss: 0.790289 [ 4800/ 5994]\n",
      "Training Loss: 1.0824, Training Accuracy: 68.3350%\n",
      "Test Loss: 1.5444, Test Accuracy: 56.7656%\n",
      "Epoch 56/500-------------------\n",
      "loss: 0.744493 [    0/ 5994]\n",
      "loss: 1.283808 [ 1600/ 5994]\n",
      "loss: 0.902658 [ 3200/ 5994]\n",
      "loss: 1.151085 [ 4800/ 5994]\n",
      "Training Loss: 1.0864, Training Accuracy: 68.4017%\n",
      "Test Loss: 1.5527, Test Accuracy: 56.3687%\n",
      "Epoch 57/500-------------------\n",
      "loss: 1.070988 [    0/ 5994]\n",
      "loss: 1.135969 [ 1600/ 5994]\n",
      "loss: 1.176921 [ 3200/ 5994]\n",
      "loss: 1.073349 [ 4800/ 5994]\n",
      "Training Loss: 1.0768, Training Accuracy: 68.5519%\n",
      "Test Loss: 1.5465, Test Accuracy: 55.9890%\n",
      "Epoch 58/500-------------------\n",
      "loss: 0.605305 [    0/ 5994]\n",
      "loss: 1.168729 [ 1600/ 5994]\n",
      "loss: 1.254327 [ 3200/ 5994]\n",
      "loss: 0.820093 [ 4800/ 5994]\n",
      "Training Loss: 1.0558, Training Accuracy: 69.6196%\n",
      "Test Loss: 1.5315, Test Accuracy: 56.5412%\n",
      "Epoch 59/500-------------------\n",
      "loss: 2.017907 [    0/ 5994]\n",
      "loss: 1.099632 [ 1600/ 5994]\n",
      "loss: 0.621780 [ 3200/ 5994]\n",
      "loss: 0.846510 [ 4800/ 5994]\n",
      "Training Loss: 1.0612, Training Accuracy: 69.7698%\n",
      "Test Loss: 1.5371, Test Accuracy: 56.5930%\n",
      "Epoch 60/500-------------------\n",
      "loss: 1.433373 [    0/ 5994]\n",
      "loss: 1.081363 [ 1600/ 5994]\n",
      "loss: 0.841044 [ 3200/ 5994]\n",
      "loss: 0.517597 [ 4800/ 5994]\n",
      "Training Loss: 1.0604, Training Accuracy: 69.3026%\n",
      "Test Loss: 1.5409, Test Accuracy: 56.9382%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 56.9382%\n",
      "Epoch 61/500-------------------\n",
      "loss: 1.975059 [    0/ 5994]\n",
      "loss: 1.159702 [ 1600/ 5994]\n",
      "loss: 0.950225 [ 3200/ 5994]\n",
      "loss: 0.972980 [ 4800/ 5994]\n",
      "Training Loss: 1.0512, Training Accuracy: 69.8031%\n",
      "Test Loss: 1.5323, Test Accuracy: 56.1098%\n",
      "Epoch 62/500-------------------\n",
      "loss: 0.892731 [    0/ 5994]\n",
      "loss: 0.790464 [ 1600/ 5994]\n",
      "loss: 0.969263 [ 3200/ 5994]\n",
      "loss: 1.098404 [ 4800/ 5994]\n",
      "Training Loss: 1.0439, Training Accuracy: 69.8365%\n",
      "Test Loss: 1.5293, Test Accuracy: 57.0418%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 57.0418%\n",
      "Epoch 63/500-------------------\n",
      "loss: 1.025787 [    0/ 5994]\n",
      "loss: 1.343256 [ 1600/ 5994]\n",
      "loss: 1.112708 [ 3200/ 5994]\n",
      "loss: 1.054906 [ 4800/ 5994]\n",
      "Training Loss: 1.0409, Training Accuracy: 70.2035%\n",
      "Test Loss: 1.5338, Test Accuracy: 56.6966%\n",
      "Epoch 64/500-------------------\n",
      "loss: 1.146913 [    0/ 5994]\n",
      "loss: 1.063690 [ 1600/ 5994]\n",
      "loss: 1.004725 [ 3200/ 5994]\n",
      "loss: 0.948948 [ 4800/ 5994]\n",
      "Training Loss: 1.0397, Training Accuracy: 70.3370%\n",
      "Test Loss: 1.5298, Test Accuracy: 56.4722%\n",
      "Epoch 65/500-------------------\n",
      "loss: 0.985236 [    0/ 5994]\n",
      "loss: 1.014436 [ 1600/ 5994]\n",
      "loss: 1.205092 [ 3200/ 5994]\n",
      "loss: 1.344404 [ 4800/ 5994]\n",
      "Training Loss: 1.0386, Training Accuracy: 70.0367%\n",
      "Test Loss: 1.5304, Test Accuracy: 56.7829%\n",
      "Epoch 66/500-------------------\n",
      "loss: 1.288128 [    0/ 5994]\n",
      "loss: 0.895663 [ 1600/ 5994]\n",
      "loss: 1.449889 [ 3200/ 5994]\n",
      "loss: 0.818376 [ 4800/ 5994]\n",
      "Training Loss: 1.0305, Training Accuracy: 70.6707%\n",
      "Test Loss: 1.5277, Test Accuracy: 56.9727%\n",
      "Epoch 67/500-------------------\n",
      "loss: 0.964406 [    0/ 5994]\n",
      "loss: 0.991254 [ 1600/ 5994]\n",
      "loss: 0.887685 [ 3200/ 5994]\n",
      "loss: 1.078434 [ 4800/ 5994]\n",
      "Training Loss: 1.0257, Training Accuracy: 70.4538%\n",
      "Test Loss: 1.5249, Test Accuracy: 57.0072%\n",
      "Epoch 68/500-------------------\n",
      "loss: 0.907801 [    0/ 5994]\n",
      "loss: 0.764811 [ 1600/ 5994]\n",
      "loss: 1.216074 [ 3200/ 5994]\n",
      "loss: 0.814083 [ 4800/ 5994]\n",
      "Training Loss: 1.0280, Training Accuracy: 70.0367%\n",
      "Test Loss: 1.5295, Test Accuracy: 57.0935%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 57.0935%\n",
      "Epoch 69/500-------------------\n",
      "loss: 1.111551 [    0/ 5994]\n",
      "loss: 0.968202 [ 1600/ 5994]\n",
      "loss: 1.218462 [ 3200/ 5994]\n",
      "loss: 0.814481 [ 4800/ 5994]\n",
      "Training Loss: 1.0168, Training Accuracy: 71.0711%\n",
      "Test Loss: 1.5213, Test Accuracy: 57.0418%\n",
      "Epoch 70/500-------------------\n",
      "loss: 1.222963 [    0/ 5994]\n",
      "loss: 0.533275 [ 1600/ 5994]\n",
      "loss: 0.781409 [ 3200/ 5994]\n",
      "loss: 0.790372 [ 4800/ 5994]\n",
      "Training Loss: 1.0192, Training Accuracy: 70.4705%\n",
      "Test Loss: 1.5262, Test Accuracy: 56.2306%\n",
      "Epoch 71/500-------------------\n",
      "loss: 0.918412 [    0/ 5994]\n",
      "loss: 1.816680 [ 1600/ 5994]\n",
      "loss: 0.679770 [ 3200/ 5994]\n",
      "loss: 0.748977 [ 4800/ 5994]\n",
      "Training Loss: 1.0173, Training Accuracy: 70.5205%\n",
      "Test Loss: 1.5291, Test Accuracy: 56.5585%\n",
      "Epoch 72/500-------------------\n",
      "loss: 1.209758 [    0/ 5994]\n",
      "loss: 0.761990 [ 1600/ 5994]\n",
      "loss: 0.615308 [ 3200/ 5994]\n",
      "loss: 0.848346 [ 4800/ 5994]\n",
      "Training Loss: 1.0108, Training Accuracy: 70.0868%\n",
      "Test Loss: 1.5170, Test Accuracy: 57.1626%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 57.1626%\n",
      "Epoch 73/500-------------------\n",
      "loss: 1.539546 [    0/ 5994]\n",
      "loss: 1.216606 [ 1600/ 5994]\n",
      "loss: 0.764466 [ 3200/ 5994]\n",
      "loss: 1.381304 [ 4800/ 5994]\n",
      "Training Loss: 1.0057, Training Accuracy: 70.9710%\n",
      "Test Loss: 1.5141, Test Accuracy: 56.9727%\n",
      "Epoch 74/500-------------------\n",
      "loss: 1.357850 [    0/ 5994]\n",
      "loss: 1.414946 [ 1600/ 5994]\n",
      "loss: 1.523525 [ 3200/ 5994]\n",
      "loss: 0.560446 [ 4800/ 5994]\n",
      "Training Loss: 1.0047, Training Accuracy: 71.0878%\n",
      "Test Loss: 1.5240, Test Accuracy: 56.6448%\n",
      "Epoch 75/500-------------------\n",
      "loss: 0.833240 [    0/ 5994]\n",
      "loss: 1.059319 [ 1600/ 5994]\n",
      "loss: 0.711119 [ 3200/ 5994]\n",
      "loss: 0.735418 [ 4800/ 5994]\n",
      "Training Loss: 0.9944, Training Accuracy: 71.5716%\n",
      "Test Loss: 1.5080, Test Accuracy: 57.8012%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 57.8012%\n",
      "Epoch 76/500-------------------\n",
      "loss: 0.579829 [    0/ 5994]\n",
      "loss: 1.654336 [ 1600/ 5994]\n",
      "loss: 0.619029 [ 3200/ 5994]\n",
      "loss: 1.324578 [ 4800/ 5994]\n",
      "Training Loss: 0.9922, Training Accuracy: 71.0878%\n",
      "Test Loss: 1.5088, Test Accuracy: 57.7321%\n",
      "Epoch 77/500-------------------\n",
      "loss: 1.265167 [    0/ 5994]\n",
      "loss: 1.081571 [ 1600/ 5994]\n",
      "loss: 1.198213 [ 3200/ 5994]\n",
      "loss: 1.302646 [ 4800/ 5994]\n",
      "Training Loss: 0.9906, Training Accuracy: 70.7875%\n",
      "Test Loss: 1.5083, Test Accuracy: 57.4042%\n",
      "Epoch 78/500-------------------\n",
      "loss: 1.197691 [    0/ 5994]\n",
      "loss: 0.957072 [ 1600/ 5994]\n",
      "loss: 1.010661 [ 3200/ 5994]\n",
      "loss: 1.202523 [ 4800/ 5994]\n",
      "Training Loss: 0.9965, Training Accuracy: 71.0043%\n",
      "Test Loss: 1.5216, Test Accuracy: 56.7656%\n",
      "Epoch 79/500-------------------\n",
      "loss: 0.885306 [    0/ 5994]\n",
      "loss: 1.484290 [ 1600/ 5994]\n",
      "loss: 0.874806 [ 3200/ 5994]\n",
      "loss: 0.803973 [ 4800/ 5994]\n",
      "Training Loss: 0.9909, Training Accuracy: 71.3881%\n",
      "Test Loss: 1.5187, Test Accuracy: 56.7138%\n",
      "Epoch 80/500-------------------\n",
      "loss: 1.041699 [    0/ 5994]\n",
      "loss: 0.676446 [ 1600/ 5994]\n",
      "loss: 1.559446 [ 3200/ 5994]\n",
      "loss: 1.035837 [ 4800/ 5994]\n",
      "Training Loss: 0.9891, Training Accuracy: 71.2045%\n",
      "Test Loss: 1.5134, Test Accuracy: 57.3352%\n",
      "Epoch 81/500-------------------\n",
      "loss: 0.800321 [    0/ 5994]\n",
      "loss: 0.886329 [ 1600/ 5994]\n",
      "loss: 1.003228 [ 3200/ 5994]\n",
      "loss: 0.891236 [ 4800/ 5994]\n",
      "Training Loss: 0.9756, Training Accuracy: 72.1388%\n",
      "Test Loss: 1.5024, Test Accuracy: 57.7321%\n",
      "Epoch 82/500-------------------\n",
      "loss: 1.135902 [    0/ 5994]\n",
      "loss: 1.283307 [ 1600/ 5994]\n",
      "loss: 1.237812 [ 3200/ 5994]\n",
      "loss: 1.190890 [ 4800/ 5994]\n",
      "Training Loss: 0.9729, Training Accuracy: 71.7551%\n",
      "Test Loss: 1.5077, Test Accuracy: 57.5078%\n",
      "Epoch 83/500-------------------\n",
      "loss: 1.083654 [    0/ 5994]\n",
      "loss: 0.796708 [ 1600/ 5994]\n",
      "loss: 0.841518 [ 3200/ 5994]\n",
      "loss: 0.884678 [ 4800/ 5994]\n",
      "Training Loss: 0.9695, Training Accuracy: 71.9386%\n",
      "Test Loss: 1.5038, Test Accuracy: 57.9220%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 57.9220%\n",
      "Epoch 84/500-------------------\n",
      "loss: 1.026326 [    0/ 5994]\n",
      "loss: 1.155120 [ 1600/ 5994]\n",
      "loss: 1.185025 [ 3200/ 5994]\n",
      "loss: 1.084335 [ 4800/ 5994]\n",
      "Training Loss: 0.9684, Training Accuracy: 72.2055%\n",
      "Test Loss: 1.5046, Test Accuracy: 57.3697%\n",
      "Epoch 85/500-------------------\n",
      "loss: 0.966556 [    0/ 5994]\n",
      "loss: 1.084228 [ 1600/ 5994]\n",
      "loss: 0.982064 [ 3200/ 5994]\n",
      "loss: 0.816894 [ 4800/ 5994]\n",
      "Training Loss: 0.9734, Training Accuracy: 71.4214%\n",
      "Test Loss: 1.5145, Test Accuracy: 56.9382%\n",
      "Epoch 86/500-------------------\n",
      "loss: 0.829531 [    0/ 5994]\n",
      "loss: 0.536044 [ 1600/ 5994]\n",
      "loss: 0.961722 [ 3200/ 5994]\n",
      "loss: 1.171990 [ 4800/ 5994]\n",
      "Training Loss: 0.9667, Training Accuracy: 72.1388%\n",
      "Test Loss: 1.5109, Test Accuracy: 57.3870%\n",
      "Epoch 87/500-------------------\n",
      "loss: 1.063872 [    0/ 5994]\n",
      "loss: 0.943795 [ 1600/ 5994]\n",
      "loss: 1.301721 [ 3200/ 5994]\n",
      "loss: 0.461993 [ 4800/ 5994]\n",
      "Training Loss: 0.9643, Training Accuracy: 72.1388%\n",
      "Test Loss: 1.5114, Test Accuracy: 57.1281%\n",
      "Epoch 88/500-------------------\n",
      "loss: 1.593655 [    0/ 5994]\n",
      "loss: 1.829350 [ 1600/ 5994]\n",
      "loss: 0.773295 [ 3200/ 5994]\n",
      "loss: 0.655967 [ 4800/ 5994]\n",
      "Training Loss: 0.9551, Training Accuracy: 72.2723%\n",
      "Test Loss: 1.4994, Test Accuracy: 57.5941%\n",
      "Epoch 89/500-------------------\n",
      "loss: 1.215624 [    0/ 5994]\n",
      "loss: 1.150983 [ 1600/ 5994]\n",
      "loss: 0.945356 [ 3200/ 5994]\n",
      "loss: 0.841016 [ 4800/ 5994]\n",
      "Training Loss: 0.9549, Training Accuracy: 72.3557%\n",
      "Test Loss: 1.5053, Test Accuracy: 57.9910%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 57.9910%\n",
      "Epoch 90/500-------------------\n",
      "loss: 0.930068 [    0/ 5994]\n",
      "loss: 0.607369 [ 1600/ 5994]\n",
      "loss: 1.033897 [ 3200/ 5994]\n",
      "loss: 1.161905 [ 4800/ 5994]\n",
      "Training Loss: 0.9471, Training Accuracy: 72.7895%\n",
      "Test Loss: 1.5029, Test Accuracy: 57.9910%\n",
      "Epoch 91/500-------------------\n",
      "loss: 1.269538 [    0/ 5994]\n",
      "loss: 0.751680 [ 1600/ 5994]\n",
      "loss: 0.659389 [ 3200/ 5994]\n",
      "loss: 1.367660 [ 4800/ 5994]\n",
      "Training Loss: 0.9444, Training Accuracy: 72.4224%\n",
      "Test Loss: 1.4990, Test Accuracy: 57.6286%\n",
      "Epoch 92/500-------------------\n",
      "loss: 1.482470 [    0/ 5994]\n",
      "loss: 0.758834 [ 1600/ 5994]\n",
      "loss: 0.711979 [ 3200/ 5994]\n",
      "loss: 1.264821 [ 4800/ 5994]\n",
      "Training Loss: 0.9414, Training Accuracy: 72.7728%\n",
      "Test Loss: 1.4973, Test Accuracy: 58.3017%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 58.3017%\n",
      "Epoch 93/500-------------------\n",
      "loss: 1.327046 [    0/ 5994]\n",
      "loss: 0.988092 [ 1600/ 5994]\n",
      "loss: 1.530716 [ 3200/ 5994]\n",
      "loss: 1.027755 [ 4800/ 5994]\n",
      "Training Loss: 0.9408, Training Accuracy: 72.8562%\n",
      "Test Loss: 1.5034, Test Accuracy: 57.8012%\n",
      "Epoch 94/500-------------------\n",
      "loss: 0.566612 [    0/ 5994]\n",
      "loss: 1.604491 [ 1600/ 5994]\n",
      "loss: 0.413364 [ 3200/ 5994]\n",
      "loss: 0.788107 [ 4800/ 5994]\n",
      "Training Loss: 0.9439, Training Accuracy: 73.0731%\n",
      "Test Loss: 1.5080, Test Accuracy: 57.3007%\n",
      "Epoch 95/500-------------------\n",
      "loss: 0.772669 [    0/ 5994]\n",
      "loss: 0.979896 [ 1600/ 5994]\n",
      "loss: 1.266898 [ 3200/ 5994]\n",
      "loss: 1.206871 [ 4800/ 5994]\n",
      "Training Loss: 0.9423, Training Accuracy: 72.4725%\n",
      "Test Loss: 1.5098, Test Accuracy: 57.3352%\n",
      "Epoch 96/500-------------------\n",
      "loss: 0.791616 [    0/ 5994]\n",
      "loss: 1.350283 [ 1600/ 5994]\n",
      "loss: 0.679076 [ 3200/ 5994]\n",
      "loss: 1.024953 [ 4800/ 5994]\n",
      "Training Loss: 0.9346, Training Accuracy: 72.6059%\n",
      "Test Loss: 1.4979, Test Accuracy: 57.3007%\n",
      "Epoch 97/500-------------------\n",
      "loss: 0.463337 [    0/ 5994]\n",
      "loss: 0.724738 [ 1600/ 5994]\n",
      "loss: 0.665791 [ 3200/ 5994]\n",
      "loss: 0.724653 [ 4800/ 5994]\n",
      "Training Loss: 0.9333, Training Accuracy: 72.6226%\n",
      "Test Loss: 1.4979, Test Accuracy: 57.6804%\n",
      "Epoch 98/500-------------------\n",
      "loss: 0.986181 [    0/ 5994]\n",
      "loss: 1.194063 [ 1600/ 5994]\n",
      "loss: 1.229433 [ 3200/ 5994]\n",
      "loss: 0.698508 [ 4800/ 5994]\n",
      "Training Loss: 0.9284, Training Accuracy: 72.6393%\n",
      "Test Loss: 1.4942, Test Accuracy: 57.7839%\n",
      "Epoch 99/500-------------------\n",
      "loss: 1.282431 [    0/ 5994]\n",
      "loss: 0.825666 [ 1600/ 5994]\n",
      "loss: 0.856295 [ 3200/ 5994]\n",
      "loss: 0.950724 [ 4800/ 5994]\n",
      "Training Loss: 0.9309, Training Accuracy: 72.0053%\n",
      "Test Loss: 1.5037, Test Accuracy: 57.7839%\n",
      "Epoch 100/500-------------------\n",
      "loss: 0.665252 [    0/ 5994]\n",
      "loss: 0.701808 [ 1600/ 5994]\n",
      "loss: 0.863098 [ 3200/ 5994]\n",
      "loss: 1.409511 [ 4800/ 5994]\n",
      "Training Loss: 0.9282, Training Accuracy: 72.4558%\n",
      "Test Loss: 1.4957, Test Accuracy: 58.1981%\n",
      "Epoch 101/500-------------------\n",
      "loss: 0.996988 [    0/ 5994]\n",
      "loss: 1.390790 [ 1600/ 5994]\n",
      "loss: 1.299027 [ 3200/ 5994]\n",
      "loss: 1.549589 [ 4800/ 5994]\n",
      "Training Loss: 0.9188, Training Accuracy: 73.2232%\n",
      "Test Loss: 1.4924, Test Accuracy: 57.8357%\n",
      "Epoch 102/500-------------------\n",
      "loss: 0.532225 [    0/ 5994]\n",
      "loss: 0.686324 [ 1600/ 5994]\n",
      "loss: 1.033496 [ 3200/ 5994]\n",
      "loss: 0.757480 [ 4800/ 5994]\n",
      "Training Loss: 0.9165, Training Accuracy: 73.2733%\n",
      "Test Loss: 1.4969, Test Accuracy: 57.8012%\n",
      "Epoch 103/500-------------------\n",
      "loss: 0.721553 [    0/ 5994]\n",
      "loss: 1.602314 [ 1600/ 5994]\n",
      "loss: 0.947641 [ 3200/ 5994]\n",
      "loss: 0.702821 [ 4800/ 5994]\n",
      "Training Loss: 0.9146, Training Accuracy: 73.3400%\n",
      "Test Loss: 1.4916, Test Accuracy: 58.2499%\n",
      "Epoch 104/500-------------------\n",
      "loss: 1.558856 [    0/ 5994]\n",
      "loss: 1.082783 [ 1600/ 5994]\n",
      "loss: 0.921437 [ 3200/ 5994]\n",
      "loss: 1.177875 [ 4800/ 5994]\n",
      "Training Loss: 0.9101, Training Accuracy: 73.5569%\n",
      "Test Loss: 1.4898, Test Accuracy: 58.2327%\n",
      "Epoch 105/500-------------------\n",
      "loss: 0.974738 [    0/ 5994]\n",
      "loss: 0.849731 [ 1600/ 5994]\n",
      "loss: 1.021786 [ 3200/ 5994]\n",
      "loss: 0.905125 [ 4800/ 5994]\n",
      "Training Loss: 0.9158, Training Accuracy: 72.6560%\n",
      "Test Loss: 1.4952, Test Accuracy: 57.8357%\n",
      "Epoch 106/500-------------------\n",
      "loss: 0.924823 [    0/ 5994]\n",
      "loss: 1.231746 [ 1600/ 5994]\n",
      "loss: 0.972891 [ 3200/ 5994]\n",
      "loss: 0.763264 [ 4800/ 5994]\n",
      "Training Loss: 0.9090, Training Accuracy: 73.3400%\n",
      "Test Loss: 1.4926, Test Accuracy: 58.4398%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 58.4398%\n",
      "Epoch 107/500-------------------\n",
      "loss: 0.791141 [    0/ 5994]\n",
      "loss: 0.978649 [ 1600/ 5994]\n",
      "loss: 0.962382 [ 3200/ 5994]\n",
      "loss: 0.594058 [ 4800/ 5994]\n",
      "Training Loss: 0.9082, Training Accuracy: 73.8906%\n",
      "Test Loss: 1.4955, Test Accuracy: 57.8012%\n",
      "Epoch 108/500-------------------\n",
      "loss: 0.610054 [    0/ 5994]\n",
      "loss: 1.210370 [ 1600/ 5994]\n",
      "loss: 0.440352 [ 3200/ 5994]\n",
      "loss: 0.877757 [ 4800/ 5994]\n",
      "Training Loss: 0.9061, Training Accuracy: 73.9072%\n",
      "Test Loss: 1.4969, Test Accuracy: 58.1291%\n",
      "Epoch 109/500-------------------\n",
      "loss: 0.784673 [    0/ 5994]\n",
      "loss: 1.305710 [ 1600/ 5994]\n",
      "loss: 0.514861 [ 3200/ 5994]\n",
      "loss: 0.613495 [ 4800/ 5994]\n",
      "Training Loss: 0.9040, Training Accuracy: 73.6236%\n",
      "Test Loss: 1.4930, Test Accuracy: 57.9220%\n",
      "Epoch 110/500-------------------\n",
      "loss: 0.790750 [    0/ 5994]\n",
      "loss: 0.628055 [ 1600/ 5994]\n",
      "loss: 0.913046 [ 3200/ 5994]\n",
      "loss: 0.830611 [ 4800/ 5994]\n",
      "Training Loss: 0.8990, Training Accuracy: 74.2075%\n",
      "Test Loss: 1.4935, Test Accuracy: 58.0255%\n",
      "Epoch 111/500-------------------\n",
      "loss: 0.872485 [    0/ 5994]\n",
      "loss: 0.928685 [ 1600/ 5994]\n",
      "loss: 0.790468 [ 3200/ 5994]\n",
      "loss: 1.251376 [ 4800/ 5994]\n",
      "Training Loss: 0.8970, Training Accuracy: 73.4234%\n",
      "Test Loss: 1.4918, Test Accuracy: 57.8530%\n",
      "Epoch 112/500-------------------\n",
      "loss: 0.981989 [    0/ 5994]\n",
      "loss: 0.743451 [ 1600/ 5994]\n",
      "loss: 0.622764 [ 3200/ 5994]\n",
      "loss: 1.078753 [ 4800/ 5994]\n",
      "Training Loss: 0.8975, Training Accuracy: 73.6570%\n",
      "Test Loss: 1.4948, Test Accuracy: 58.0428%\n",
      "Epoch 113/500-------------------\n",
      "loss: 0.787295 [    0/ 5994]\n",
      "loss: 0.921174 [ 1600/ 5994]\n",
      "loss: 0.892166 [ 3200/ 5994]\n",
      "loss: 1.371354 [ 4800/ 5994]\n",
      "Training Loss: 0.8982, Training Accuracy: 73.6236%\n",
      "Test Loss: 1.4932, Test Accuracy: 57.5250%\n",
      "Epoch 114/500-------------------\n",
      "loss: 1.153589 [    0/ 5994]\n",
      "loss: 0.572541 [ 1600/ 5994]\n",
      "loss: 0.503237 [ 3200/ 5994]\n",
      "loss: 1.174016 [ 4800/ 5994]\n",
      "Training Loss: 0.8942, Training Accuracy: 73.9740%\n",
      "Test Loss: 1.4949, Test Accuracy: 57.4042%\n",
      "Epoch 115/500-------------------\n",
      "loss: 0.510878 [    0/ 5994]\n",
      "loss: 0.806313 [ 1600/ 5994]\n",
      "loss: 1.091934 [ 3200/ 5994]\n",
      "loss: 0.553305 [ 4800/ 5994]\n",
      "Training Loss: 0.8898, Training Accuracy: 74.0407%\n",
      "Test Loss: 1.4937, Test Accuracy: 57.6286%\n",
      "Epoch 116/500-------------------\n",
      "loss: 0.932621 [    0/ 5994]\n",
      "loss: 1.052485 [ 1600/ 5994]\n",
      "loss: 1.077416 [ 3200/ 5994]\n",
      "loss: 1.224953 [ 4800/ 5994]\n",
      "Training Loss: 0.8856, Training Accuracy: 74.4077%\n",
      "Test Loss: 1.4853, Test Accuracy: 58.3017%\n",
      "Epoch 117/500-------------------\n",
      "loss: 0.556984 [    0/ 5994]\n",
      "loss: 0.735579 [ 1600/ 5994]\n",
      "loss: 0.787896 [ 3200/ 5994]\n",
      "loss: 0.583479 [ 4800/ 5994]\n",
      "Training Loss: 0.8872, Training Accuracy: 74.2743%\n",
      "Test Loss: 1.4880, Test Accuracy: 58.4052%\n",
      "Epoch 118/500-------------------\n",
      "loss: 0.772192 [    0/ 5994]\n",
      "loss: 0.775154 [ 1600/ 5994]\n",
      "loss: 1.271876 [ 3200/ 5994]\n",
      "loss: 1.371156 [ 4800/ 5994]\n",
      "Training Loss: 0.8864, Training Accuracy: 74.4244%\n",
      "Test Loss: 1.4946, Test Accuracy: 58.0601%\n",
      "Epoch 119/500-------------------\n",
      "loss: 0.975729 [    0/ 5994]\n",
      "loss: 0.818676 [ 1600/ 5994]\n",
      "loss: 0.879312 [ 3200/ 5994]\n",
      "loss: 1.234142 [ 4800/ 5994]\n",
      "Training Loss: 0.8909, Training Accuracy: 73.4568%\n",
      "Test Loss: 1.4997, Test Accuracy: 57.4905%\n",
      "Epoch 120/500-------------------\n",
      "loss: 0.835895 [    0/ 5994]\n",
      "loss: 0.634069 [ 1600/ 5994]\n",
      "loss: 1.141076 [ 3200/ 5994]\n",
      "loss: 0.694909 [ 4800/ 5994]\n",
      "Training Loss: 0.8788, Training Accuracy: 74.0240%\n",
      "Test Loss: 1.4850, Test Accuracy: 58.6296%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 58.6296%\n",
      "Epoch 121/500-------------------\n",
      "loss: 0.611503 [    0/ 5994]\n",
      "loss: 0.415712 [ 1600/ 5994]\n",
      "loss: 0.608115 [ 3200/ 5994]\n",
      "loss: 1.004423 [ 4800/ 5994]\n",
      "Training Loss: 0.8781, Training Accuracy: 74.0908%\n",
      "Test Loss: 1.4918, Test Accuracy: 58.2844%\n",
      "Epoch 122/500-------------------\n",
      "loss: 1.008607 [    0/ 5994]\n",
      "loss: 1.677123 [ 1600/ 5994]\n",
      "loss: 0.839930 [ 3200/ 5994]\n",
      "loss: 0.933676 [ 4800/ 5994]\n",
      "Training Loss: 0.8799, Training Accuracy: 74.2242%\n",
      "Test Loss: 1.4891, Test Accuracy: 58.3880%\n",
      "Epoch 123/500-------------------\n",
      "loss: 0.777612 [    0/ 5994]\n",
      "loss: 1.211955 [ 1600/ 5994]\n",
      "loss: 1.148527 [ 3200/ 5994]\n",
      "loss: 0.878215 [ 4800/ 5994]\n",
      "Training Loss: 0.8765, Training Accuracy: 73.9406%\n",
      "Test Loss: 1.4927, Test Accuracy: 57.8875%\n",
      "Epoch 124/500-------------------\n",
      "loss: 0.768101 [    0/ 5994]\n",
      "loss: 0.686602 [ 1600/ 5994]\n",
      "loss: 0.810080 [ 3200/ 5994]\n",
      "loss: 0.741337 [ 4800/ 5994]\n",
      "Training Loss: 0.8824, Training Accuracy: 73.3901%\n",
      "Test Loss: 1.5008, Test Accuracy: 57.6631%\n",
      "Epoch 125/500-------------------\n",
      "loss: 0.853542 [    0/ 5994]\n",
      "loss: 0.843384 [ 1600/ 5994]\n",
      "loss: 0.312435 [ 3200/ 5994]\n",
      "loss: 0.841216 [ 4800/ 5994]\n",
      "Training Loss: 0.8719, Training Accuracy: 74.4411%\n",
      "Test Loss: 1.4915, Test Accuracy: 57.9738%\n",
      "Epoch 126/500-------------------\n",
      "loss: 1.092065 [    0/ 5994]\n",
      "loss: 1.196093 [ 1600/ 5994]\n",
      "loss: 0.409605 [ 3200/ 5994]\n",
      "loss: 1.207429 [ 4800/ 5994]\n",
      "Training Loss: 0.8693, Training Accuracy: 74.6580%\n",
      "Test Loss: 1.4930, Test Accuracy: 57.9738%\n",
      "Epoch 127/500-------------------\n",
      "loss: 0.893736 [    0/ 5994]\n",
      "loss: 1.070819 [ 1600/ 5994]\n",
      "loss: 0.382396 [ 3200/ 5994]\n",
      "loss: 0.710673 [ 4800/ 5994]\n",
      "Training Loss: 0.8672, Training Accuracy: 74.4077%\n",
      "Test Loss: 1.4928, Test Accuracy: 58.0083%\n",
      "Epoch 128/500-------------------\n",
      "loss: 0.494029 [    0/ 5994]\n",
      "loss: 0.617432 [ 1600/ 5994]\n",
      "loss: 0.758496 [ 3200/ 5994]\n",
      "loss: 1.478534 [ 4800/ 5994]\n",
      "Training Loss: 0.8630, Training Accuracy: 74.3577%\n",
      "Test Loss: 1.4784, Test Accuracy: 58.8540%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 58.8540%\n",
      "Epoch 129/500-------------------\n",
      "loss: 0.516922 [    0/ 5994]\n",
      "loss: 1.038983 [ 1600/ 5994]\n",
      "loss: 0.704524 [ 3200/ 5994]\n",
      "loss: 0.985406 [ 4800/ 5994]\n",
      "Training Loss: 0.8656, Training Accuracy: 75.0584%\n",
      "Test Loss: 1.4941, Test Accuracy: 58.2844%\n",
      "Epoch 130/500-------------------\n",
      "loss: 0.871557 [    0/ 5994]\n",
      "loss: 0.898875 [ 1600/ 5994]\n",
      "loss: 1.047379 [ 3200/ 5994]\n",
      "loss: 0.865361 [ 4800/ 5994]\n",
      "Training Loss: 0.8634, Training Accuracy: 74.5245%\n",
      "Test Loss: 1.4886, Test Accuracy: 58.0428%\n",
      "Epoch 131/500-------------------\n",
      "loss: 0.451932 [    0/ 5994]\n",
      "loss: 1.163901 [ 1600/ 5994]\n",
      "loss: 0.810677 [ 3200/ 5994]\n",
      "loss: 0.873125 [ 4800/ 5994]\n",
      "Training Loss: 0.8580, Training Accuracy: 75.2753%\n",
      "Test Loss: 1.4872, Test Accuracy: 57.8702%\n",
      "Epoch 132/500-------------------\n",
      "loss: 0.829231 [    0/ 5994]\n",
      "loss: 0.769555 [ 1600/ 5994]\n",
      "loss: 1.062910 [ 3200/ 5994]\n",
      "loss: 0.790814 [ 4800/ 5994]\n",
      "Training Loss: 0.8570, Training Accuracy: 75.5255%\n",
      "Test Loss: 1.4858, Test Accuracy: 58.2499%\n",
      "Epoch 133/500-------------------\n",
      "loss: 0.780841 [    0/ 5994]\n",
      "loss: 1.057644 [ 1600/ 5994]\n",
      "loss: 0.930753 [ 3200/ 5994]\n",
      "loss: 0.396077 [ 4800/ 5994]\n",
      "Training Loss: 0.8601, Training Accuracy: 74.7915%\n",
      "Test Loss: 1.4960, Test Accuracy: 58.0428%\n",
      "Epoch 134/500-------------------\n",
      "loss: 0.763392 [    0/ 5994]\n",
      "loss: 0.696327 [ 1600/ 5994]\n",
      "loss: 1.321005 [ 3200/ 5994]\n",
      "loss: 1.227080 [ 4800/ 5994]\n",
      "Training Loss: 0.8568, Training Accuracy: 75.1418%\n",
      "Test Loss: 1.4912, Test Accuracy: 58.0083%\n",
      "Epoch 135/500-------------------\n",
      "loss: 1.000352 [    0/ 5994]\n",
      "loss: 1.261173 [ 1600/ 5994]\n",
      "loss: 1.133556 [ 3200/ 5994]\n",
      "loss: 0.460874 [ 4800/ 5994]\n",
      "Training Loss: 0.8543, Training Accuracy: 74.8749%\n",
      "Test Loss: 1.4869, Test Accuracy: 58.4225%\n",
      "Epoch 136/500-------------------\n",
      "loss: 0.532169 [    0/ 5994]\n",
      "loss: 1.106752 [ 1600/ 5994]\n",
      "loss: 0.449056 [ 3200/ 5994]\n",
      "loss: 1.543314 [ 4800/ 5994]\n",
      "Training Loss: 0.8511, Training Accuracy: 75.1919%\n",
      "Test Loss: 1.4870, Test Accuracy: 58.3017%\n",
      "Epoch 137/500-------------------\n",
      "loss: 0.660381 [    0/ 5994]\n",
      "loss: 0.910209 [ 1600/ 5994]\n",
      "loss: 1.192452 [ 3200/ 5994]\n",
      "loss: 0.849414 [ 4800/ 5994]\n",
      "Training Loss: 0.8528, Training Accuracy: 74.9416%\n",
      "Test Loss: 1.4957, Test Accuracy: 57.8702%\n",
      "Epoch 138/500-------------------\n",
      "loss: 0.724310 [    0/ 5994]\n",
      "loss: 0.895075 [ 1600/ 5994]\n",
      "loss: 0.896416 [ 3200/ 5994]\n",
      "loss: 0.885979 [ 4800/ 5994]\n",
      "Training Loss: 0.8473, Training Accuracy: 75.2920%\n",
      "Test Loss: 1.4903, Test Accuracy: 58.3707%\n",
      "Epoch 139/500-------------------\n",
      "loss: 1.269519 [    0/ 5994]\n",
      "loss: 1.163241 [ 1600/ 5994]\n",
      "loss: 0.664424 [ 3200/ 5994]\n",
      "loss: 0.741438 [ 4800/ 5994]\n",
      "Training Loss: 0.8463, Training Accuracy: 75.0918%\n",
      "Test Loss: 1.4890, Test Accuracy: 58.4052%\n",
      "Epoch 140/500-------------------\n",
      "loss: 1.134029 [    0/ 5994]\n",
      "loss: 0.936451 [ 1600/ 5994]\n",
      "loss: 0.637413 [ 3200/ 5994]\n",
      "loss: 1.015147 [ 4800/ 5994]\n",
      "Training Loss: 0.8458, Training Accuracy: 75.4588%\n",
      "Test Loss: 1.4952, Test Accuracy: 57.7494%\n",
      "Epoch 141/500-------------------\n",
      "loss: 0.888371 [    0/ 5994]\n",
      "loss: 1.246320 [ 1600/ 5994]\n",
      "loss: 1.159361 [ 3200/ 5994]\n",
      "loss: 1.143551 [ 4800/ 5994]\n",
      "Training Loss: 0.8420, Training Accuracy: 75.4087%\n",
      "Test Loss: 1.4808, Test Accuracy: 58.3880%\n",
      "Epoch 142/500-------------------\n",
      "loss: 0.740707 [    0/ 5994]\n",
      "loss: 0.661056 [ 1600/ 5994]\n",
      "loss: 0.739828 [ 3200/ 5994]\n",
      "loss: 1.029566 [ 4800/ 5994]\n",
      "Training Loss: 0.8407, Training Accuracy: 75.2252%\n",
      "Test Loss: 1.4875, Test Accuracy: 58.7677%\n",
      "Epoch 143/500-------------------\n",
      "loss: 0.872058 [    0/ 5994]\n",
      "loss: 0.956943 [ 1600/ 5994]\n",
      "loss: 0.949884 [ 3200/ 5994]\n",
      "loss: 0.748415 [ 4800/ 5994]\n",
      "Training Loss: 0.8397, Training Accuracy: 75.5088%\n",
      "Test Loss: 1.4888, Test Accuracy: 58.3017%\n",
      "Epoch 144/500-------------------\n",
      "loss: 0.502775 [    0/ 5994]\n",
      "loss: 0.578920 [ 1600/ 5994]\n",
      "loss: 0.959660 [ 3200/ 5994]\n",
      "loss: 1.124442 [ 4800/ 5994]\n",
      "Training Loss: 0.8349, Training Accuracy: 75.9092%\n",
      "Test Loss: 1.4861, Test Accuracy: 58.5606%\n",
      "Epoch 145/500-------------------\n",
      "loss: 0.754227 [    0/ 5994]\n",
      "loss: 0.862324 [ 1600/ 5994]\n",
      "loss: 1.377541 [ 3200/ 5994]\n",
      "loss: 0.573617 [ 4800/ 5994]\n",
      "Training Loss: 0.8400, Training Accuracy: 75.6089%\n",
      "Test Loss: 1.4904, Test Accuracy: 58.4225%\n",
      "Epoch 146/500-------------------\n",
      "loss: 1.230024 [    0/ 5994]\n",
      "loss: 0.858433 [ 1600/ 5994]\n",
      "loss: 1.356591 [ 3200/ 5994]\n",
      "loss: 0.924143 [ 4800/ 5994]\n",
      "Training Loss: 0.8344, Training Accuracy: 76.0427%\n",
      "Test Loss: 1.4864, Test Accuracy: 58.3880%\n",
      "Epoch 147/500-------------------\n",
      "loss: 0.575483 [    0/ 5994]\n",
      "loss: 0.990067 [ 1600/ 5994]\n",
      "loss: 0.637771 [ 3200/ 5994]\n",
      "loss: 0.895471 [ 4800/ 5994]\n",
      "Training Loss: 0.8308, Training Accuracy: 75.7257%\n",
      "Test Loss: 1.4851, Test Accuracy: 58.7159%\n",
      "Epoch 148/500-------------------\n",
      "loss: 1.338254 [    0/ 5994]\n",
      "loss: 0.810534 [ 1600/ 5994]\n",
      "loss: 0.605438 [ 3200/ 5994]\n",
      "loss: 1.229559 [ 4800/ 5994]\n",
      "Training Loss: 0.8317, Training Accuracy: 75.9426%\n",
      "Test Loss: 1.4867, Test Accuracy: 58.4743%\n",
      "Epoch 149/500-------------------\n",
      "loss: 1.254988 [    0/ 5994]\n",
      "loss: 0.507230 [ 1600/ 5994]\n",
      "loss: 0.836113 [ 3200/ 5994]\n",
      "loss: 0.785888 [ 4800/ 5994]\n",
      "Training Loss: 0.8291, Training Accuracy: 75.6089%\n",
      "Test Loss: 1.4908, Test Accuracy: 58.3017%\n",
      "Epoch 150/500-------------------\n",
      "loss: 0.862751 [    0/ 5994]\n",
      "loss: 1.270113 [ 1600/ 5994]\n",
      "loss: 0.609284 [ 3200/ 5994]\n",
      "loss: 0.758047 [ 4800/ 5994]\n",
      "Training Loss: 0.8305, Training Accuracy: 76.0427%\n",
      "Test Loss: 1.4872, Test Accuracy: 58.8195%\n",
      "Epoch 151/500-------------------\n",
      "loss: 0.745211 [    0/ 5994]\n",
      "loss: 1.068372 [ 1600/ 5994]\n",
      "loss: 0.953382 [ 3200/ 5994]\n",
      "loss: 0.950434 [ 4800/ 5994]\n",
      "Training Loss: 0.8331, Training Accuracy: 75.6757%\n",
      "Test Loss: 1.4976, Test Accuracy: 57.6804%\n",
      "Epoch 152/500-------------------\n",
      "loss: 0.824664 [    0/ 5994]\n",
      "loss: 0.794030 [ 1600/ 5994]\n",
      "loss: 0.884230 [ 3200/ 5994]\n",
      "loss: 0.426243 [ 4800/ 5994]\n",
      "Training Loss: 0.8226, Training Accuracy: 75.9259%\n",
      "Test Loss: 1.4805, Test Accuracy: 59.0956%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 59.0956%\n",
      "Epoch 153/500-------------------\n",
      "loss: 0.530944 [    0/ 5994]\n",
      "loss: 0.851574 [ 1600/ 5994]\n",
      "loss: 1.522044 [ 3200/ 5994]\n",
      "loss: 1.081522 [ 4800/ 5994]\n",
      "Training Loss: 0.8354, Training Accuracy: 74.9249%\n",
      "Test Loss: 1.5026, Test Accuracy: 58.1636%\n",
      "Epoch 154/500-------------------\n",
      "loss: 0.546944 [    0/ 5994]\n",
      "loss: 0.682617 [ 1600/ 5994]\n",
      "loss: 1.267877 [ 3200/ 5994]\n",
      "loss: 0.906014 [ 4800/ 5994]\n",
      "Training Loss: 0.8236, Training Accuracy: 75.3921%\n",
      "Test Loss: 1.4935, Test Accuracy: 58.5261%\n",
      "Epoch 155/500-------------------\n",
      "loss: 0.654681 [    0/ 5994]\n",
      "loss: 0.826383 [ 1600/ 5994]\n",
      "loss: 1.025197 [ 3200/ 5994]\n",
      "loss: 0.939553 [ 4800/ 5994]\n",
      "Training Loss: 0.8189, Training Accuracy: 76.2763%\n",
      "Test Loss: 1.4852, Test Accuracy: 58.1636%\n",
      "Epoch 156/500-------------------\n",
      "loss: 0.631690 [    0/ 5994]\n",
      "loss: 0.940607 [ 1600/ 5994]\n",
      "loss: 1.046785 [ 3200/ 5994]\n",
      "loss: 0.326645 [ 4800/ 5994]\n",
      "Training Loss: 0.8270, Training Accuracy: 75.3754%\n",
      "Test Loss: 1.4986, Test Accuracy: 58.0773%\n",
      "Epoch 157/500-------------------\n",
      "loss: 0.814191 [    0/ 5994]\n",
      "loss: 0.779557 [ 1600/ 5994]\n",
      "loss: 1.345974 [ 3200/ 5994]\n",
      "loss: 1.112182 [ 4800/ 5994]\n",
      "Training Loss: 0.8181, Training Accuracy: 75.8759%\n",
      "Test Loss: 1.4905, Test Accuracy: 58.7504%\n",
      "Epoch 158/500-------------------\n",
      "loss: 0.746786 [    0/ 5994]\n",
      "loss: 0.779267 [ 1600/ 5994]\n",
      "loss: 0.995755 [ 3200/ 5994]\n",
      "loss: 0.820073 [ 4800/ 5994]\n",
      "Training Loss: 0.8134, Training Accuracy: 76.6934%\n",
      "Test Loss: 1.4866, Test Accuracy: 58.5433%\n",
      "Epoch 159/500-------------------\n",
      "loss: 1.097522 [    0/ 5994]\n",
      "loss: 0.968549 [ 1600/ 5994]\n",
      "loss: 0.875059 [ 3200/ 5994]\n",
      "loss: 0.561585 [ 4800/ 5994]\n",
      "Training Loss: 0.8122, Training Accuracy: 76.2262%\n",
      "Test Loss: 1.4836, Test Accuracy: 58.3190%\n",
      "Epoch 160/500-------------------\n",
      "loss: 1.343116 [    0/ 5994]\n",
      "loss: 0.582085 [ 1600/ 5994]\n",
      "loss: 0.999684 [ 3200/ 5994]\n",
      "loss: 0.533753 [ 4800/ 5994]\n",
      "Training Loss: 0.8110, Training Accuracy: 76.3096%\n",
      "Test Loss: 1.4883, Test Accuracy: 58.1981%\n",
      "Epoch 161/500-------------------\n",
      "loss: 0.489110 [    0/ 5994]\n",
      "loss: 1.115173 [ 1600/ 5994]\n",
      "loss: 0.819387 [ 3200/ 5994]\n",
      "loss: 1.171956 [ 4800/ 5994]\n",
      "Training Loss: 0.8145, Training Accuracy: 76.1094%\n",
      "Test Loss: 1.4939, Test Accuracy: 58.9058%\n",
      "Epoch 162/500-------------------\n",
      "loss: 0.957935 [    0/ 5994]\n",
      "loss: 0.836356 [ 1600/ 5994]\n",
      "loss: 0.589175 [ 3200/ 5994]\n",
      "loss: 0.945557 [ 4800/ 5994]\n",
      "Training Loss: 0.8140, Training Accuracy: 76.4264%\n",
      "Test Loss: 1.4934, Test Accuracy: 58.2327%\n",
      "Epoch 163/500-------------------\n",
      "loss: 1.130558 [    0/ 5994]\n",
      "loss: 0.542008 [ 1600/ 5994]\n",
      "loss: 0.687050 [ 3200/ 5994]\n",
      "loss: 0.910551 [ 4800/ 5994]\n",
      "Training Loss: 0.8115, Training Accuracy: 75.9593%\n",
      "Test Loss: 1.4949, Test Accuracy: 58.5951%\n",
      "Epoch 164/500-------------------\n",
      "loss: 0.659769 [    0/ 5994]\n",
      "loss: 1.454478 [ 1600/ 5994]\n",
      "loss: 0.691614 [ 3200/ 5994]\n",
      "loss: 0.544507 [ 4800/ 5994]\n",
      "Training Loss: 0.8053, Training Accuracy: 76.6266%\n",
      "Test Loss: 1.4836, Test Accuracy: 58.2844%\n",
      "Epoch 165/500-------------------\n",
      "loss: 1.137262 [    0/ 5994]\n",
      "loss: 1.255551 [ 1600/ 5994]\n",
      "loss: 1.170479 [ 3200/ 5994]\n",
      "loss: 0.583693 [ 4800/ 5994]\n",
      "Training Loss: 0.7982, Training Accuracy: 76.6266%\n",
      "Test Loss: 1.4764, Test Accuracy: 58.9575%\n",
      "Epoch 166/500-------------------\n",
      "loss: 1.120764 [    0/ 5994]\n",
      "loss: 1.214837 [ 1600/ 5994]\n",
      "loss: 0.432737 [ 3200/ 5994]\n",
      "loss: 0.850561 [ 4800/ 5994]\n",
      "Training Loss: 0.8046, Training Accuracy: 76.4932%\n",
      "Test Loss: 1.4891, Test Accuracy: 58.9058%\n",
      "Epoch 167/500-------------------\n",
      "loss: 1.137694 [    0/ 5994]\n",
      "loss: 0.846500 [ 1600/ 5994]\n",
      "loss: 0.755956 [ 3200/ 5994]\n",
      "loss: 0.943538 [ 4800/ 5994]\n",
      "Training Loss: 0.8032, Training Accuracy: 76.5432%\n",
      "Test Loss: 1.4828, Test Accuracy: 58.7677%\n",
      "Epoch 168/500-------------------\n",
      "loss: 0.610466 [    0/ 5994]\n",
      "loss: 0.461681 [ 1600/ 5994]\n",
      "loss: 0.611914 [ 3200/ 5994]\n",
      "loss: 1.032271 [ 4800/ 5994]\n",
      "Training Loss: 0.8014, Training Accuracy: 76.7768%\n",
      "Test Loss: 1.4881, Test Accuracy: 58.1981%\n",
      "Epoch 169/500-------------------\n",
      "loss: 1.014331 [    0/ 5994]\n",
      "loss: 0.794532 [ 1600/ 5994]\n",
      "loss: 0.823960 [ 3200/ 5994]\n",
      "loss: 0.721701 [ 4800/ 5994]\n",
      "Training Loss: 0.7987, Training Accuracy: 76.7601%\n",
      "Test Loss: 1.4837, Test Accuracy: 58.6296%\n",
      "Epoch 170/500-------------------\n",
      "loss: 0.658456 [    0/ 5994]\n",
      "loss: 0.770812 [ 1600/ 5994]\n",
      "loss: 0.982793 [ 3200/ 5994]\n",
      "loss: 1.104826 [ 4800/ 5994]\n",
      "Training Loss: 0.7962, Training Accuracy: 76.7601%\n",
      "Test Loss: 1.4822, Test Accuracy: 59.3027%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 59.3027%\n",
      "Epoch 171/500-------------------\n",
      "loss: 0.906773 [    0/ 5994]\n",
      "loss: 0.928135 [ 1600/ 5994]\n",
      "loss: 0.737414 [ 3200/ 5994]\n",
      "loss: 0.824024 [ 4800/ 5994]\n",
      "Training Loss: 0.7958, Training Accuracy: 76.5432%\n",
      "Test Loss: 1.4866, Test Accuracy: 58.8367%\n",
      "Epoch 172/500-------------------\n",
      "loss: 0.953010 [    0/ 5994]\n",
      "loss: 0.822461 [ 1600/ 5994]\n",
      "loss: 0.916789 [ 3200/ 5994]\n",
      "loss: 0.942715 [ 4800/ 5994]\n",
      "Training Loss: 0.7990, Training Accuracy: 76.2763%\n",
      "Test Loss: 1.4910, Test Accuracy: 58.4915%\n",
      "Epoch 173/500-------------------\n",
      "loss: 0.767031 [    0/ 5994]\n",
      "loss: 1.138405 [ 1600/ 5994]\n",
      "loss: 0.672621 [ 3200/ 5994]\n",
      "loss: 0.858670 [ 4800/ 5994]\n",
      "Training Loss: 0.7942, Training Accuracy: 76.8769%\n",
      "Test Loss: 1.4858, Test Accuracy: 58.5778%\n",
      "Epoch 174/500-------------------\n",
      "loss: 0.984298 [    0/ 5994]\n",
      "loss: 0.673511 [ 1600/ 5994]\n",
      "loss: 0.676596 [ 3200/ 5994]\n",
      "loss: 0.637073 [ 4800/ 5994]\n",
      "Training Loss: 0.7925, Training Accuracy: 77.1939%\n",
      "Test Loss: 1.4856, Test Accuracy: 58.9230%\n",
      "Epoch 175/500-------------------\n",
      "loss: 1.086112 [    0/ 5994]\n",
      "loss: 0.659680 [ 1600/ 5994]\n",
      "loss: 0.730501 [ 3200/ 5994]\n",
      "loss: 0.951515 [ 4800/ 5994]\n",
      "Training Loss: 0.7925, Training Accuracy: 76.9102%\n",
      "Test Loss: 1.4932, Test Accuracy: 58.4398%\n",
      "Epoch 176/500-------------------\n",
      "loss: 0.916540 [    0/ 5994]\n",
      "loss: 0.968915 [ 1600/ 5994]\n",
      "loss: 1.600634 [ 3200/ 5994]\n",
      "loss: 0.629575 [ 4800/ 5994]\n",
      "Training Loss: 0.7937, Training Accuracy: 76.8936%\n",
      "Test Loss: 1.4848, Test Accuracy: 58.6469%\n",
      "Epoch 177/500-------------------\n",
      "loss: 0.756076 [    0/ 5994]\n",
      "loss: 0.971439 [ 1600/ 5994]\n",
      "loss: 0.942063 [ 3200/ 5994]\n",
      "loss: 0.938180 [ 4800/ 5994]\n",
      "Training Loss: 0.7913, Training Accuracy: 76.8602%\n",
      "Test Loss: 1.4897, Test Accuracy: 58.5778%\n",
      "Epoch 178/500-------------------\n",
      "loss: 1.188799 [    0/ 5994]\n",
      "loss: 0.233943 [ 1600/ 5994]\n",
      "loss: 1.042625 [ 3200/ 5994]\n",
      "loss: 0.663992 [ 4800/ 5994]\n",
      "Training Loss: 0.7839, Training Accuracy: 77.4608%\n",
      "Test Loss: 1.4816, Test Accuracy: 59.0093%\n",
      "Epoch 179/500-------------------\n",
      "loss: 1.513457 [    0/ 5994]\n",
      "loss: 0.888917 [ 1600/ 5994]\n",
      "loss: 0.526757 [ 3200/ 5994]\n",
      "loss: 0.963237 [ 4800/ 5994]\n",
      "Training Loss: 0.7822, Training Accuracy: 77.0938%\n",
      "Test Loss: 1.4840, Test Accuracy: 58.9575%\n",
      "Epoch 180/500-------------------\n",
      "loss: 1.209865 [    0/ 5994]\n",
      "loss: 1.155318 [ 1600/ 5994]\n",
      "loss: 0.873783 [ 3200/ 5994]\n",
      "loss: 0.887952 [ 4800/ 5994]\n",
      "Training Loss: 0.7952, Training Accuracy: 76.6266%\n",
      "Test Loss: 1.4959, Test Accuracy: 58.4225%\n",
      "Epoch 181/500-------------------\n",
      "loss: 0.758949 [    0/ 5994]\n",
      "loss: 0.963049 [ 1600/ 5994]\n",
      "loss: 0.786731 [ 3200/ 5994]\n",
      "loss: 0.419450 [ 4800/ 5994]\n",
      "Training Loss: 0.7823, Training Accuracy: 77.3440%\n",
      "Test Loss: 1.4857, Test Accuracy: 58.4398%\n",
      "Epoch 182/500-------------------\n",
      "loss: 0.823845 [    0/ 5994]\n",
      "loss: 1.113466 [ 1600/ 5994]\n",
      "loss: 0.691323 [ 3200/ 5994]\n",
      "loss: 0.952572 [ 4800/ 5994]\n",
      "Training Loss: 0.7902, Training Accuracy: 76.6600%\n",
      "Test Loss: 1.4928, Test Accuracy: 58.3535%\n",
      "Epoch 183/500-------------------\n",
      "loss: 0.837373 [    0/ 5994]\n",
      "loss: 0.554594 [ 1600/ 5994]\n",
      "loss: 0.602764 [ 3200/ 5994]\n",
      "loss: 1.206779 [ 4800/ 5994]\n",
      "Training Loss: 0.7907, Training Accuracy: 76.5599%\n",
      "Test Loss: 1.4954, Test Accuracy: 58.8195%\n",
      "Epoch 184/500-------------------\n",
      "loss: 0.732287 [    0/ 5994]\n",
      "loss: 0.547440 [ 1600/ 5994]\n",
      "loss: 0.568143 [ 3200/ 5994]\n",
      "loss: 0.728204 [ 4800/ 5994]\n",
      "Training Loss: 0.7828, Training Accuracy: 77.4775%\n",
      "Test Loss: 1.4905, Test Accuracy: 57.9392%\n",
      "Epoch 185/500-------------------\n",
      "loss: 0.447103 [    0/ 5994]\n",
      "loss: 0.881248 [ 1600/ 5994]\n",
      "loss: 0.938510 [ 3200/ 5994]\n",
      "loss: 1.021736 [ 4800/ 5994]\n",
      "Training Loss: 0.7778, Training Accuracy: 77.5108%\n",
      "Test Loss: 1.4874, Test Accuracy: 58.4225%\n",
      "Epoch 186/500-------------------\n",
      "loss: 0.792430 [    0/ 5994]\n",
      "loss: 0.702035 [ 1600/ 5994]\n",
      "loss: 1.231855 [ 3200/ 5994]\n",
      "loss: 0.649124 [ 4800/ 5994]\n",
      "Training Loss: 0.7765, Training Accuracy: 77.2940%\n",
      "Test Loss: 1.4886, Test Accuracy: 58.9403%\n",
      "Epoch 187/500-------------------\n",
      "loss: 0.788740 [    0/ 5994]\n",
      "loss: 1.203506 [ 1600/ 5994]\n",
      "loss: 0.506226 [ 3200/ 5994]\n",
      "loss: 1.181661 [ 4800/ 5994]\n",
      "Training Loss: 0.7697, Training Accuracy: 77.9947%\n",
      "Test Loss: 1.4812, Test Accuracy: 58.9575%\n",
      "Epoch 188/500-------------------\n",
      "loss: 1.026515 [    0/ 5994]\n",
      "loss: 0.603060 [ 1600/ 5994]\n",
      "loss: 1.437800 [ 3200/ 5994]\n",
      "loss: 0.892677 [ 4800/ 5994]\n",
      "Training Loss: 0.7702, Training Accuracy: 78.1949%\n",
      "Test Loss: 1.4838, Test Accuracy: 59.1129%\n",
      "Epoch 189/500-------------------\n",
      "loss: 0.702852 [    0/ 5994]\n",
      "loss: 1.001132 [ 1600/ 5994]\n",
      "loss: 0.473189 [ 3200/ 5994]\n",
      "loss: 0.487337 [ 4800/ 5994]\n",
      "Training Loss: 0.7749, Training Accuracy: 77.5442%\n",
      "Test Loss: 1.4895, Test Accuracy: 58.6124%\n",
      "Epoch 190/500-------------------\n",
      "loss: 0.793797 [    0/ 5994]\n",
      "loss: 0.746350 [ 1600/ 5994]\n",
      "loss: 0.708562 [ 3200/ 5994]\n",
      "loss: 0.547638 [ 4800/ 5994]\n",
      "Training Loss: 0.7768, Training Accuracy: 77.1939%\n",
      "Test Loss: 1.4909, Test Accuracy: 58.9575%\n",
      "Epoch 191/500-------------------\n",
      "loss: 0.801559 [    0/ 5994]\n",
      "loss: 0.893510 [ 1600/ 5994]\n",
      "loss: 0.766164 [ 3200/ 5994]\n",
      "loss: 1.200281 [ 4800/ 5994]\n",
      "Training Loss: 0.7810, Training Accuracy: 76.8435%\n",
      "Test Loss: 1.4946, Test Accuracy: 58.8540%\n",
      "Epoch 192/500-------------------\n",
      "loss: 0.902120 [    0/ 5994]\n",
      "loss: 0.736238 [ 1600/ 5994]\n",
      "loss: 0.820115 [ 3200/ 5994]\n",
      "loss: 0.590769 [ 4800/ 5994]\n",
      "Training Loss: 0.7722, Training Accuracy: 77.7778%\n",
      "Test Loss: 1.4916, Test Accuracy: 58.6987%\n",
      "Epoch 193/500-------------------\n",
      "loss: 0.846432 [    0/ 5994]\n",
      "loss: 0.659015 [ 1600/ 5994]\n",
      "loss: 0.872307 [ 3200/ 5994]\n",
      "loss: 0.530030 [ 4800/ 5994]\n",
      "Training Loss: 0.7656, Training Accuracy: 77.9613%\n",
      "Test Loss: 1.4872, Test Accuracy: 58.6987%\n",
      "Epoch 194/500-------------------\n",
      "loss: 0.618916 [    0/ 5994]\n",
      "loss: 0.383099 [ 1600/ 5994]\n",
      "loss: 1.210113 [ 3200/ 5994]\n",
      "loss: 0.563132 [ 4800/ 5994]\n",
      "Training Loss: 0.7687, Training Accuracy: 77.0270%\n",
      "Test Loss: 1.4900, Test Accuracy: 58.5606%\n",
      "Epoch 195/500-------------------\n",
      "loss: 0.865825 [    0/ 5994]\n",
      "loss: 0.946070 [ 1600/ 5994]\n",
      "loss: 0.731044 [ 3200/ 5994]\n",
      "loss: 0.575140 [ 4800/ 5994]\n",
      "Training Loss: 0.7687, Training Accuracy: 77.4107%\n",
      "Test Loss: 1.4927, Test Accuracy: 58.8540%\n",
      "Epoch 196/500-------------------\n",
      "loss: 0.659086 [    0/ 5994]\n",
      "loss: 0.758652 [ 1600/ 5994]\n",
      "loss: 1.076892 [ 3200/ 5994]\n",
      "loss: 0.851616 [ 4800/ 5994]\n",
      "Training Loss: 0.7637, Training Accuracy: 77.6610%\n",
      "Test Loss: 1.4844, Test Accuracy: 59.2682%\n",
      "Epoch 197/500-------------------\n",
      "loss: 0.821045 [    0/ 5994]\n",
      "loss: 0.465334 [ 1600/ 5994]\n",
      "loss: 0.786181 [ 3200/ 5994]\n",
      "loss: 1.169894 [ 4800/ 5994]\n",
      "Training Loss: 0.7645, Training Accuracy: 77.7611%\n",
      "Test Loss: 1.4971, Test Accuracy: 57.9738%\n",
      "Epoch 198/500-------------------\n",
      "loss: 0.752682 [    0/ 5994]\n",
      "loss: 0.821555 [ 1600/ 5994]\n",
      "loss: 0.979833 [ 3200/ 5994]\n",
      "loss: 0.778113 [ 4800/ 5994]\n",
      "Training Loss: 0.7636, Training Accuracy: 77.6777%\n",
      "Test Loss: 1.4899, Test Accuracy: 58.8022%\n",
      "Epoch 199/500-------------------\n",
      "loss: 0.514335 [    0/ 5994]\n",
      "loss: 0.679486 [ 1600/ 5994]\n",
      "loss: 0.902963 [ 3200/ 5994]\n",
      "loss: 0.700144 [ 4800/ 5994]\n",
      "Training Loss: 0.7600, Training Accuracy: 77.7778%\n",
      "Test Loss: 1.4857, Test Accuracy: 58.8885%\n",
      "Epoch 200/500-------------------\n",
      "loss: 0.626808 [    0/ 5994]\n",
      "loss: 0.782322 [ 1600/ 5994]\n",
      "loss: 0.724570 [ 3200/ 5994]\n",
      "loss: 1.064907 [ 4800/ 5994]\n",
      "Training Loss: 0.7650, Training Accuracy: 77.5943%\n",
      "Test Loss: 1.5005, Test Accuracy: 57.9738%\n",
      "Epoch 201/500-------------------\n",
      "loss: 0.527180 [    0/ 5994]\n",
      "loss: 0.600920 [ 1600/ 5994]\n",
      "loss: 0.797815 [ 3200/ 5994]\n",
      "loss: 0.942055 [ 4800/ 5994]\n",
      "Training Loss: 0.7633, Training Accuracy: 77.3607%\n",
      "Test Loss: 1.4986, Test Accuracy: 58.2154%\n",
      "Epoch 202/500-------------------\n",
      "loss: 0.335291 [    0/ 5994]\n",
      "loss: 1.154080 [ 1600/ 5994]\n",
      "loss: 0.507291 [ 3200/ 5994]\n",
      "loss: 0.931715 [ 4800/ 5994]\n",
      "Training Loss: 0.7630, Training Accuracy: 77.9279%\n",
      "Test Loss: 1.4971, Test Accuracy: 59.3027%\n",
      "Epoch 203/500-------------------\n",
      "loss: 0.692181 [    0/ 5994]\n",
      "loss: 0.600973 [ 1600/ 5994]\n",
      "loss: 0.469748 [ 3200/ 5994]\n",
      "loss: 1.259592 [ 4800/ 5994]\n",
      "Training Loss: 0.7526, Training Accuracy: 78.1114%\n",
      "Test Loss: 1.4841, Test Accuracy: 58.9921%\n",
      "Epoch 204/500-------------------\n",
      "loss: 0.703399 [    0/ 5994]\n",
      "loss: 1.102859 [ 1600/ 5994]\n",
      "loss: 0.867740 [ 3200/ 5994]\n",
      "loss: 0.973162 [ 4800/ 5994]\n",
      "Training Loss: 0.7614, Training Accuracy: 77.4441%\n",
      "Test Loss: 1.4909, Test Accuracy: 58.9575%\n",
      "Epoch 205/500-------------------\n",
      "loss: 1.527478 [    0/ 5994]\n",
      "loss: 0.719962 [ 1600/ 5994]\n",
      "loss: 1.149067 [ 3200/ 5994]\n",
      "loss: 0.239297 [ 4800/ 5994]\n",
      "Training Loss: 0.7536, Training Accuracy: 77.8111%\n",
      "Test Loss: 1.4928, Test Accuracy: 58.6469%\n",
      "Epoch 206/500-------------------\n",
      "loss: 1.075882 [    0/ 5994]\n",
      "loss: 0.507376 [ 1600/ 5994]\n",
      "loss: 0.669619 [ 3200/ 5994]\n",
      "loss: 0.557651 [ 4800/ 5994]\n",
      "Training Loss: 0.7535, Training Accuracy: 78.3617%\n",
      "Test Loss: 1.4917, Test Accuracy: 58.8540%\n",
      "Epoch 207/500-------------------\n",
      "loss: 0.707472 [    0/ 5994]\n",
      "loss: 0.557516 [ 1600/ 5994]\n",
      "loss: 0.620926 [ 3200/ 5994]\n",
      "loss: 0.606374 [ 4800/ 5994]\n",
      "Training Loss: 0.7604, Training Accuracy: 77.7277%\n",
      "Test Loss: 1.5014, Test Accuracy: 58.3017%\n",
      "Epoch 208/500-------------------\n",
      "loss: 0.779606 [    0/ 5994]\n",
      "loss: 0.752337 [ 1600/ 5994]\n",
      "loss: 0.697663 [ 3200/ 5994]\n",
      "loss: 0.439042 [ 4800/ 5994]\n",
      "Training Loss: 0.7527, Training Accuracy: 77.9947%\n",
      "Test Loss: 1.4930, Test Accuracy: 59.3372%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 59.3372%\n",
      "Epoch 209/500-------------------\n",
      "loss: 0.887284 [    0/ 5994]\n",
      "loss: 0.623565 [ 1600/ 5994]\n",
      "loss: 0.888460 [ 3200/ 5994]\n",
      "loss: 1.166621 [ 4800/ 5994]\n",
      "Training Loss: 0.7519, Training Accuracy: 77.8946%\n",
      "Test Loss: 1.4960, Test Accuracy: 58.6296%\n",
      "Epoch 210/500-------------------\n",
      "loss: 0.343119 [    0/ 5994]\n",
      "loss: 0.495897 [ 1600/ 5994]\n",
      "loss: 0.943058 [ 3200/ 5994]\n",
      "loss: 0.578844 [ 4800/ 5994]\n",
      "Training Loss: 0.7533, Training Accuracy: 77.7110%\n",
      "Test Loss: 1.4920, Test Accuracy: 59.1129%\n",
      "Epoch 211/500-------------------\n",
      "loss: 0.864035 [    0/ 5994]\n",
      "loss: 0.759694 [ 1600/ 5994]\n",
      "loss: 0.584723 [ 3200/ 5994]\n",
      "loss: 0.997357 [ 4800/ 5994]\n",
      "Training Loss: 0.7481, Training Accuracy: 78.1615%\n",
      "Test Loss: 1.4893, Test Accuracy: 59.2164%\n",
      "Epoch 212/500-------------------\n",
      "loss: 0.717619 [    0/ 5994]\n",
      "loss: 0.533119 [ 1600/ 5994]\n",
      "loss: 0.803432 [ 3200/ 5994]\n",
      "loss: 0.374696 [ 4800/ 5994]\n",
      "Training Loss: 0.7500, Training Accuracy: 78.0280%\n",
      "Test Loss: 1.5031, Test Accuracy: 58.2327%\n",
      "Epoch 213/500-------------------\n",
      "loss: 0.914344 [    0/ 5994]\n",
      "loss: 0.728811 [ 1600/ 5994]\n",
      "loss: 0.894331 [ 3200/ 5994]\n",
      "loss: 1.022779 [ 4800/ 5994]\n",
      "Training Loss: 0.7478, Training Accuracy: 78.0280%\n",
      "Test Loss: 1.4917, Test Accuracy: 58.4398%\n",
      "Epoch 214/500-------------------\n",
      "loss: 1.314462 [    0/ 5994]\n",
      "loss: 0.691248 [ 1600/ 5994]\n",
      "loss: 0.988528 [ 3200/ 5994]\n",
      "loss: 0.594342 [ 4800/ 5994]\n",
      "Training Loss: 0.7416, Training Accuracy: 78.1782%\n",
      "Test Loss: 1.4967, Test Accuracy: 58.6987%\n",
      "Epoch 215/500-------------------\n",
      "loss: 0.578060 [    0/ 5994]\n",
      "loss: 0.706313 [ 1600/ 5994]\n",
      "loss: 0.494060 [ 3200/ 5994]\n",
      "loss: 0.726532 [ 4800/ 5994]\n",
      "Training Loss: 0.7476, Training Accuracy: 78.1782%\n",
      "Test Loss: 1.4943, Test Accuracy: 58.9230%\n",
      "Epoch 216/500-------------------\n",
      "loss: 0.376221 [    0/ 5994]\n",
      "loss: 1.038423 [ 1600/ 5994]\n",
      "loss: 0.611814 [ 3200/ 5994]\n",
      "loss: 0.543790 [ 4800/ 5994]\n",
      "Training Loss: 0.7520, Training Accuracy: 78.1949%\n",
      "Test Loss: 1.5028, Test Accuracy: 58.8712%\n",
      "Epoch 217/500-------------------\n",
      "loss: 0.645092 [    0/ 5994]\n",
      "loss: 0.524278 [ 1600/ 5994]\n",
      "loss: 0.696678 [ 3200/ 5994]\n",
      "loss: 0.970906 [ 4800/ 5994]\n",
      "Training Loss: 0.7440, Training Accuracy: 78.4618%\n",
      "Test Loss: 1.4947, Test Accuracy: 58.9403%\n",
      "Epoch 218/500-------------------\n",
      "loss: 0.957794 [    0/ 5994]\n",
      "loss: 0.858817 [ 1600/ 5994]\n",
      "loss: 0.753658 [ 3200/ 5994]\n",
      "loss: 0.891981 [ 4800/ 5994]\n",
      "Training Loss: 0.7386, Training Accuracy: 78.7788%\n",
      "Test Loss: 1.4933, Test Accuracy: 59.3890%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 59.3890%\n",
      "Epoch 219/500-------------------\n",
      "loss: 0.731814 [    0/ 5994]\n",
      "loss: 0.783626 [ 1600/ 5994]\n",
      "loss: 0.878896 [ 3200/ 5994]\n",
      "loss: 0.730874 [ 4800/ 5994]\n",
      "Training Loss: 0.7339, Training Accuracy: 78.8789%\n",
      "Test Loss: 1.4880, Test Accuracy: 58.6987%\n",
      "Epoch 220/500-------------------\n",
      "loss: 0.872999 [    0/ 5994]\n",
      "loss: 0.679830 [ 1600/ 5994]\n",
      "loss: 1.083225 [ 3200/ 5994]\n",
      "loss: 0.360148 [ 4800/ 5994]\n",
      "Training Loss: 0.7378, Training Accuracy: 78.7120%\n",
      "Test Loss: 1.4940, Test Accuracy: 58.8367%\n",
      "Epoch 221/500-------------------\n",
      "loss: 0.916099 [    0/ 5994]\n",
      "loss: 0.516592 [ 1600/ 5994]\n",
      "loss: 0.465000 [ 3200/ 5994]\n",
      "loss: 0.762738 [ 4800/ 5994]\n",
      "Training Loss: 0.7529, Training Accuracy: 77.7110%\n",
      "Test Loss: 1.5113, Test Accuracy: 58.7849%\n",
      "Epoch 222/500-------------------\n",
      "loss: 0.651696 [    0/ 5994]\n",
      "loss: 0.463614 [ 1600/ 5994]\n",
      "loss: 0.841004 [ 3200/ 5994]\n",
      "loss: 0.784151 [ 4800/ 5994]\n",
      "Training Loss: 0.7348, Training Accuracy: 79.0791%\n",
      "Test Loss: 1.4907, Test Accuracy: 59.0266%\n",
      "Epoch 223/500-------------------\n",
      "loss: 0.726374 [    0/ 5994]\n",
      "loss: 0.483159 [ 1600/ 5994]\n",
      "loss: 0.574204 [ 3200/ 5994]\n",
      "loss: 0.649884 [ 4800/ 5994]\n",
      "Training Loss: 0.7355, Training Accuracy: 78.7454%\n",
      "Test Loss: 1.4876, Test Accuracy: 59.3890%\n",
      "Epoch 224/500-------------------\n",
      "loss: 0.648647 [    0/ 5994]\n",
      "loss: 0.665946 [ 1600/ 5994]\n",
      "loss: 0.717905 [ 3200/ 5994]\n",
      "loss: 0.923850 [ 4800/ 5994]\n",
      "Training Loss: 0.7343, Training Accuracy: 78.6286%\n",
      "Test Loss: 1.4970, Test Accuracy: 59.0956%\n",
      "Epoch 225/500-------------------\n",
      "loss: 0.495762 [    0/ 5994]\n",
      "loss: 0.906735 [ 1600/ 5994]\n",
      "loss: 0.516652 [ 3200/ 5994]\n",
      "loss: 0.930180 [ 4800/ 5994]\n",
      "Training Loss: 0.7345, Training Accuracy: 78.6787%\n",
      "Test Loss: 1.4915, Test Accuracy: 59.0784%\n",
      "Epoch 226/500-------------------\n",
      "loss: 0.411091 [    0/ 5994]\n",
      "loss: 0.539834 [ 1600/ 5994]\n",
      "loss: 0.951090 [ 3200/ 5994]\n",
      "loss: 0.929974 [ 4800/ 5994]\n",
      "Training Loss: 0.7318, Training Accuracy: 78.8956%\n",
      "Test Loss: 1.4937, Test Accuracy: 59.0611%\n",
      "Epoch 227/500-------------------\n",
      "loss: 0.724819 [    0/ 5994]\n",
      "loss: 0.300497 [ 1600/ 5994]\n",
      "loss: 0.962884 [ 3200/ 5994]\n",
      "loss: 0.499548 [ 4800/ 5994]\n",
      "Training Loss: 0.7343, Training Accuracy: 78.3951%\n",
      "Test Loss: 1.4929, Test Accuracy: 58.4570%\n",
      "Epoch 228/500-------------------\n",
      "loss: 0.665691 [    0/ 5994]\n",
      "loss: 0.802376 [ 1600/ 5994]\n",
      "loss: 0.514251 [ 3200/ 5994]\n",
      "loss: 0.667003 [ 4800/ 5994]\n",
      "Training Loss: 0.7339, Training Accuracy: 78.2282%\n",
      "Test Loss: 1.4951, Test Accuracy: 58.7849%\n",
      "Epoch 229/500-------------------\n",
      "loss: 0.701149 [    0/ 5994]\n",
      "loss: 0.485572 [ 1600/ 5994]\n",
      "loss: 1.037531 [ 3200/ 5994]\n",
      "loss: 0.491256 [ 4800/ 5994]\n",
      "Training Loss: 0.7283, Training Accuracy: 78.6787%\n",
      "Test Loss: 1.4950, Test Accuracy: 58.6469%\n",
      "Epoch 230/500-------------------\n",
      "loss: 0.579076 [    0/ 5994]\n",
      "loss: 1.237629 [ 1600/ 5994]\n",
      "loss: 0.548838 [ 3200/ 5994]\n",
      "loss: 0.829061 [ 4800/ 5994]\n",
      "Training Loss: 0.7307, Training Accuracy: 78.8455%\n",
      "Test Loss: 1.4959, Test Accuracy: 58.8022%\n",
      "Epoch 231/500-------------------\n",
      "loss: 0.877241 [    0/ 5994]\n",
      "loss: 0.420925 [ 1600/ 5994]\n",
      "loss: 0.799391 [ 3200/ 5994]\n",
      "loss: 0.942675 [ 4800/ 5994]\n",
      "Training Loss: 0.7231, Training Accuracy: 78.9122%\n",
      "Test Loss: 1.4836, Test Accuracy: 59.0611%\n",
      "Epoch 232/500-------------------\n",
      "loss: 0.575487 [    0/ 5994]\n",
      "loss: 0.803261 [ 1600/ 5994]\n",
      "loss: 0.293164 [ 3200/ 5994]\n",
      "loss: 0.503110 [ 4800/ 5994]\n",
      "Training Loss: 0.7286, Training Accuracy: 78.7454%\n",
      "Test Loss: 1.4954, Test Accuracy: 58.5433%\n",
      "Epoch 233/500-------------------\n",
      "loss: 0.852798 [    0/ 5994]\n",
      "loss: 0.632865 [ 1600/ 5994]\n",
      "loss: 0.964117 [ 3200/ 5994]\n",
      "loss: 0.510068 [ 4800/ 5994]\n",
      "Training Loss: 0.7268, Training Accuracy: 78.8622%\n",
      "Test Loss: 1.4983, Test Accuracy: 58.6987%\n",
      "Epoch 234/500-------------------\n",
      "loss: 0.815552 [    0/ 5994]\n",
      "loss: 0.566107 [ 1600/ 5994]\n",
      "loss: 1.151348 [ 3200/ 5994]\n",
      "loss: 0.654347 [ 4800/ 5994]\n",
      "Training Loss: 0.7264, Training Accuracy: 79.0791%\n",
      "Test Loss: 1.4981, Test Accuracy: 59.1129%\n",
      "Epoch 235/500-------------------\n",
      "loss: 0.617999 [    0/ 5994]\n",
      "loss: 1.114865 [ 1600/ 5994]\n",
      "loss: 0.946875 [ 3200/ 5994]\n",
      "loss: 0.418674 [ 4800/ 5994]\n",
      "Training Loss: 0.7191, Training Accuracy: 79.5796%\n",
      "Test Loss: 1.4911, Test Accuracy: 59.0093%\n",
      "Epoch 236/500-------------------\n",
      "loss: 0.786888 [    0/ 5994]\n",
      "loss: 0.938803 [ 1600/ 5994]\n",
      "loss: 1.008868 [ 3200/ 5994]\n",
      "loss: 0.671781 [ 4800/ 5994]\n",
      "Training Loss: 0.7245, Training Accuracy: 78.8789%\n",
      "Test Loss: 1.4960, Test Accuracy: 58.7677%\n",
      "Epoch 237/500-------------------\n",
      "loss: 0.615428 [    0/ 5994]\n",
      "loss: 0.478217 [ 1600/ 5994]\n",
      "loss: 0.463969 [ 3200/ 5994]\n",
      "loss: 0.638425 [ 4800/ 5994]\n",
      "Training Loss: 0.7207, Training Accuracy: 79.3126%\n",
      "Test Loss: 1.4959, Test Accuracy: 59.1129%\n",
      "Epoch 238/500-------------------\n",
      "loss: 0.779037 [    0/ 5994]\n",
      "loss: 0.534820 [ 1600/ 5994]\n",
      "loss: 0.662595 [ 3200/ 5994]\n",
      "loss: 1.059963 [ 4800/ 5994]\n",
      "Training Loss: 0.7235, Training Accuracy: 79.1458%\n",
      "Test Loss: 1.4964, Test Accuracy: 58.7504%\n",
      "Epoch 239/500-------------------\n",
      "loss: 0.731907 [    0/ 5994]\n",
      "loss: 0.638059 [ 1600/ 5994]\n",
      "loss: 0.708022 [ 3200/ 5994]\n",
      "loss: 0.942413 [ 4800/ 5994]\n",
      "Training Loss: 0.7291, Training Accuracy: 78.8288%\n",
      "Test Loss: 1.5068, Test Accuracy: 58.4743%\n",
      "Epoch 240/500-------------------\n",
      "loss: 0.717915 [    0/ 5994]\n",
      "loss: 0.479699 [ 1600/ 5994]\n",
      "loss: 0.939374 [ 3200/ 5994]\n",
      "loss: 0.705433 [ 4800/ 5994]\n",
      "Training Loss: 0.7222, Training Accuracy: 79.1625%\n",
      "Test Loss: 1.5006, Test Accuracy: 59.0784%\n",
      "Epoch 241/500-------------------\n",
      "loss: 1.147415 [    0/ 5994]\n",
      "loss: 0.814850 [ 1600/ 5994]\n",
      "loss: 0.640277 [ 3200/ 5994]\n",
      "loss: 1.364227 [ 4800/ 5994]\n",
      "Training Loss: 0.7168, Training Accuracy: 79.3126%\n",
      "Test Loss: 1.4967, Test Accuracy: 58.6814%\n",
      "Epoch 242/500-------------------\n",
      "loss: 1.032510 [    0/ 5994]\n",
      "loss: 0.870333 [ 1600/ 5994]\n",
      "loss: 0.969946 [ 3200/ 5994]\n",
      "loss: 0.262585 [ 4800/ 5994]\n",
      "Training Loss: 0.7179, Training Accuracy: 79.1792%\n",
      "Test Loss: 1.4959, Test Accuracy: 59.1301%\n",
      "Epoch 243/500-------------------\n",
      "loss: 0.655696 [    0/ 5994]\n",
      "loss: 0.835779 [ 1600/ 5994]\n",
      "loss: 0.943715 [ 3200/ 5994]\n",
      "loss: 0.819441 [ 4800/ 5994]\n",
      "Training Loss: 0.7174, Training Accuracy: 78.8789%\n",
      "Test Loss: 1.4956, Test Accuracy: 59.0438%\n",
      "Epoch 244/500-------------------\n",
      "loss: 0.870238 [    0/ 5994]\n",
      "loss: 0.597820 [ 1600/ 5994]\n",
      "loss: 0.432465 [ 3200/ 5994]\n",
      "loss: 0.760324 [ 4800/ 5994]\n",
      "Training Loss: 0.7138, Training Accuracy: 79.3961%\n",
      "Test Loss: 1.4894, Test Accuracy: 59.1129%\n",
      "Epoch 245/500-------------------\n",
      "loss: 0.665491 [    0/ 5994]\n",
      "loss: 1.611756 [ 1600/ 5994]\n",
      "loss: 0.680375 [ 3200/ 5994]\n",
      "loss: 0.700248 [ 4800/ 5994]\n",
      "Training Loss: 0.7276, Training Accuracy: 78.0280%\n",
      "Test Loss: 1.5058, Test Accuracy: 58.8885%\n",
      "Epoch 246/500-------------------\n",
      "loss: 0.606183 [    0/ 5994]\n",
      "loss: 0.806132 [ 1600/ 5994]\n",
      "loss: 0.656322 [ 3200/ 5994]\n",
      "loss: 0.690556 [ 4800/ 5994]\n",
      "Training Loss: 0.7117, Training Accuracy: 79.6964%\n",
      "Test Loss: 1.4956, Test Accuracy: 58.7677%\n",
      "Epoch 247/500-------------------\n",
      "loss: 0.483568 [    0/ 5994]\n",
      "loss: 0.233548 [ 1600/ 5994]\n",
      "loss: 0.410289 [ 3200/ 5994]\n",
      "loss: 1.027635 [ 4800/ 5994]\n",
      "Training Loss: 0.7138, Training Accuracy: 79.2793%\n",
      "Test Loss: 1.4980, Test Accuracy: 59.0611%\n",
      "Epoch 248/500-------------------\n",
      "loss: 0.920733 [    0/ 5994]\n",
      "loss: 0.862097 [ 1600/ 5994]\n",
      "loss: 0.968887 [ 3200/ 5994]\n",
      "loss: 0.470671 [ 4800/ 5994]\n",
      "Training Loss: 0.7140, Training Accuracy: 79.4461%\n",
      "Test Loss: 1.5075, Test Accuracy: 58.9921%\n",
      "Epoch 249/500-------------------\n",
      "loss: 1.163616 [    0/ 5994]\n",
      "loss: 0.599970 [ 1600/ 5994]\n",
      "loss: 0.664087 [ 3200/ 5994]\n",
      "loss: 0.980315 [ 4800/ 5994]\n",
      "Training Loss: 0.7140, Training Accuracy: 79.2626%\n",
      "Test Loss: 1.5018, Test Accuracy: 58.7159%\n",
      "Epoch 250/500-------------------\n",
      "loss: 0.707458 [    0/ 5994]\n",
      "loss: 1.030644 [ 1600/ 5994]\n",
      "loss: 0.577947 [ 3200/ 5994]\n",
      "loss: 0.383726 [ 4800/ 5994]\n",
      "Training Loss: 0.7185, Training Accuracy: 78.7955%\n",
      "Test Loss: 1.5071, Test Accuracy: 59.4063%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 59.4063%\n",
      "Epoch 251/500-------------------\n",
      "loss: 0.680296 [    0/ 5994]\n",
      "loss: 0.615249 [ 1600/ 5994]\n",
      "loss: 0.727780 [ 3200/ 5994]\n",
      "loss: 0.505717 [ 4800/ 5994]\n",
      "Training Loss: 0.7128, Training Accuracy: 79.1625%\n",
      "Test Loss: 1.5034, Test Accuracy: 58.6987%\n",
      "Epoch 252/500-------------------\n",
      "loss: 0.626622 [    0/ 5994]\n",
      "loss: 0.726940 [ 1600/ 5994]\n",
      "loss: 1.034742 [ 3200/ 5994]\n",
      "loss: 0.839162 [ 4800/ 5994]\n",
      "Training Loss: 0.7106, Training Accuracy: 79.4628%\n",
      "Test Loss: 1.5091, Test Accuracy: 58.7677%\n",
      "Epoch 253/500-------------------\n",
      "loss: 0.902427 [    0/ 5994]\n",
      "loss: 0.894100 [ 1600/ 5994]\n",
      "loss: 0.385516 [ 3200/ 5994]\n",
      "loss: 0.567156 [ 4800/ 5994]\n",
      "Training Loss: 0.7086, Training Accuracy: 79.4294%\n",
      "Test Loss: 1.5016, Test Accuracy: 59.4408%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 59.4408%\n",
      "Epoch 254/500-------------------\n",
      "loss: 0.624671 [    0/ 5994]\n",
      "loss: 1.024239 [ 1600/ 5994]\n",
      "loss: 0.451546 [ 3200/ 5994]\n",
      "loss: 0.709840 [ 4800/ 5994]\n",
      "Training Loss: 0.7102, Training Accuracy: 79.3961%\n",
      "Test Loss: 1.4982, Test Accuracy: 59.2164%\n",
      "Epoch 255/500-------------------\n",
      "loss: 0.760787 [    0/ 5994]\n",
      "loss: 0.589938 [ 1600/ 5994]\n",
      "loss: 0.715449 [ 3200/ 5994]\n",
      "loss: 0.715555 [ 4800/ 5994]\n",
      "Training Loss: 0.7202, Training Accuracy: 78.7287%\n",
      "Test Loss: 1.5147, Test Accuracy: 58.5261%\n",
      "Epoch 256/500-------------------\n",
      "loss: 0.492088 [    0/ 5994]\n",
      "loss: 0.532959 [ 1600/ 5994]\n",
      "loss: 0.356989 [ 3200/ 5994]\n",
      "loss: 1.182052 [ 4800/ 5994]\n",
      "Training Loss: 0.7069, Training Accuracy: 79.6964%\n",
      "Test Loss: 1.5035, Test Accuracy: 58.9230%\n",
      "Epoch 257/500-------------------\n",
      "loss: 0.848491 [    0/ 5994]\n",
      "loss: 0.860672 [ 1600/ 5994]\n",
      "loss: 0.975979 [ 3200/ 5994]\n",
      "loss: 0.397489 [ 4800/ 5994]\n",
      "Training Loss: 0.7050, Training Accuracy: 79.8298%\n",
      "Test Loss: 1.5007, Test Accuracy: 59.3372%\n",
      "Epoch 258/500-------------------\n",
      "loss: 0.738364 [    0/ 5994]\n",
      "loss: 0.694287 [ 1600/ 5994]\n",
      "loss: 1.102756 [ 3200/ 5994]\n",
      "loss: 0.730732 [ 4800/ 5994]\n",
      "Training Loss: 0.7043, Training Accuracy: 79.3794%\n",
      "Test Loss: 1.4978, Test Accuracy: 59.0784%\n",
      "Epoch 259/500-------------------\n",
      "loss: 0.441049 [    0/ 5994]\n",
      "loss: 0.745884 [ 1600/ 5994]\n",
      "loss: 0.857875 [ 3200/ 5994]\n",
      "loss: 0.564987 [ 4800/ 5994]\n",
      "Training Loss: 0.6998, Training Accuracy: 79.8966%\n",
      "Test Loss: 1.4988, Test Accuracy: 59.4581%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 59.4581%\n",
      "Epoch 260/500-------------------\n",
      "loss: 0.193899 [    0/ 5994]\n",
      "loss: 0.596074 [ 1600/ 5994]\n",
      "loss: 0.608098 [ 3200/ 5994]\n",
      "loss: 0.712495 [ 4800/ 5994]\n",
      "Training Loss: 0.7082, Training Accuracy: 79.5963%\n",
      "Test Loss: 1.5091, Test Accuracy: 59.1301%\n",
      "Epoch 261/500-------------------\n",
      "loss: 0.284961 [    0/ 5994]\n",
      "loss: 1.230742 [ 1600/ 5994]\n",
      "loss: 0.747016 [ 3200/ 5994]\n",
      "loss: 1.223902 [ 4800/ 5994]\n",
      "Training Loss: 0.7129, Training Accuracy: 79.1792%\n",
      "Test Loss: 1.5132, Test Accuracy: 58.1291%\n",
      "Epoch 262/500-------------------\n",
      "loss: 0.829213 [    0/ 5994]\n",
      "loss: 1.188262 [ 1600/ 5994]\n",
      "loss: 0.865011 [ 3200/ 5994]\n",
      "loss: 0.751525 [ 4800/ 5994]\n",
      "Training Loss: 0.6995, Training Accuracy: 79.6797%\n",
      "Test Loss: 1.5048, Test Accuracy: 59.2164%\n",
      "Epoch 263/500-------------------\n",
      "loss: 0.856226 [    0/ 5994]\n",
      "loss: 0.474292 [ 1600/ 5994]\n",
      "loss: 0.471219 [ 3200/ 5994]\n",
      "loss: 0.941837 [ 4800/ 5994]\n",
      "Training Loss: 0.7033, Training Accuracy: 79.8131%\n",
      "Test Loss: 1.5041, Test Accuracy: 59.0956%\n",
      "Epoch 264/500-------------------\n",
      "loss: 0.688927 [    0/ 5994]\n",
      "loss: 1.018619 [ 1600/ 5994]\n",
      "loss: 0.917865 [ 3200/ 5994]\n",
      "loss: 0.474512 [ 4800/ 5994]\n",
      "Training Loss: 0.7012, Training Accuracy: 79.6797%\n",
      "Test Loss: 1.5054, Test Accuracy: 58.9921%\n",
      "Epoch 265/500-------------------\n",
      "loss: 0.643437 [    0/ 5994]\n",
      "loss: 0.856832 [ 1600/ 5994]\n",
      "loss: 0.990548 [ 3200/ 5994]\n",
      "loss: 0.499016 [ 4800/ 5994]\n",
      "Training Loss: 0.6930, Training Accuracy: 80.1969%\n",
      "Test Loss: 1.4952, Test Accuracy: 58.9230%\n",
      "Epoch 266/500-------------------\n",
      "loss: 0.792263 [    0/ 5994]\n",
      "loss: 1.323261 [ 1600/ 5994]\n",
      "loss: 0.974390 [ 3200/ 5994]\n",
      "loss: 0.772591 [ 4800/ 5994]\n",
      "Training Loss: 0.6939, Training Accuracy: 79.8465%\n",
      "Test Loss: 1.4954, Test Accuracy: 59.2337%\n",
      "Epoch 267/500-------------------\n",
      "loss: 0.706685 [    0/ 5994]\n",
      "loss: 0.519249 [ 1600/ 5994]\n",
      "loss: 0.545481 [ 3200/ 5994]\n",
      "loss: 0.634082 [ 4800/ 5994]\n",
      "Training Loss: 0.7006, Training Accuracy: 79.2793%\n",
      "Test Loss: 1.5098, Test Accuracy: 58.7332%\n",
      "Epoch 268/500-------------------\n",
      "loss: 0.895168 [    0/ 5994]\n",
      "loss: 1.106195 [ 1600/ 5994]\n",
      "loss: 0.719816 [ 3200/ 5994]\n",
      "loss: 0.654238 [ 4800/ 5994]\n",
      "Training Loss: 0.6942, Training Accuracy: 79.9466%\n",
      "Test Loss: 1.5012, Test Accuracy: 59.7169%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 59.7169%\n",
      "Epoch 269/500-------------------\n",
      "loss: 0.432155 [    0/ 5994]\n",
      "loss: 0.686178 [ 1600/ 5994]\n",
      "loss: 0.485235 [ 3200/ 5994]\n",
      "loss: 0.715741 [ 4800/ 5994]\n",
      "Training Loss: 0.6974, Training Accuracy: 78.9623%\n",
      "Test Loss: 1.5007, Test Accuracy: 59.2509%\n",
      "Epoch 270/500-------------------\n",
      "loss: 0.728234 [    0/ 5994]\n",
      "loss: 0.529396 [ 1600/ 5994]\n",
      "loss: 1.264744 [ 3200/ 5994]\n",
      "loss: 0.569926 [ 4800/ 5994]\n",
      "Training Loss: 0.6948, Training Accuracy: 79.9466%\n",
      "Test Loss: 1.5034, Test Accuracy: 58.6124%\n",
      "Epoch 271/500-------------------\n",
      "loss: 0.501979 [    0/ 5994]\n",
      "loss: 0.735119 [ 1600/ 5994]\n",
      "loss: 0.600126 [ 3200/ 5994]\n",
      "loss: 0.565560 [ 4800/ 5994]\n",
      "Training Loss: 0.6981, Training Accuracy: 80.0300%\n",
      "Test Loss: 1.5106, Test Accuracy: 59.0956%\n",
      "Epoch 272/500-------------------\n",
      "loss: 0.393488 [    0/ 5994]\n",
      "loss: 0.603517 [ 1600/ 5994]\n",
      "loss: 0.385135 [ 3200/ 5994]\n",
      "loss: 0.950544 [ 4800/ 5994]\n",
      "Training Loss: 0.7020, Training Accuracy: 79.5295%\n",
      "Test Loss: 1.5186, Test Accuracy: 58.4398%\n",
      "Epoch 273/500-------------------\n",
      "loss: 0.997272 [    0/ 5994]\n",
      "loss: 0.641481 [ 1600/ 5994]\n",
      "loss: 0.596410 [ 3200/ 5994]\n",
      "loss: 0.534391 [ 4800/ 5994]\n",
      "Training Loss: 0.6867, Training Accuracy: 80.4471%\n",
      "Test Loss: 1.5067, Test Accuracy: 58.5606%\n",
      "Epoch 274/500-------------------\n",
      "loss: 0.771181 [    0/ 5994]\n",
      "loss: 0.577517 [ 1600/ 5994]\n",
      "loss: 0.457874 [ 3200/ 5994]\n",
      "loss: 0.736086 [ 4800/ 5994]\n",
      "Training Loss: 0.6879, Training Accuracy: 80.1969%\n",
      "Test Loss: 1.5024, Test Accuracy: 58.8712%\n",
      "Epoch 275/500-------------------\n",
      "loss: 0.723164 [    0/ 5994]\n",
      "loss: 0.481502 [ 1600/ 5994]\n",
      "loss: 0.520908 [ 3200/ 5994]\n",
      "loss: 0.639218 [ 4800/ 5994]\n",
      "Training Loss: 0.6953, Training Accuracy: 79.5629%\n",
      "Test Loss: 1.5108, Test Accuracy: 59.0784%\n",
      "Epoch 276/500-------------------\n",
      "loss: 0.217957 [    0/ 5994]\n",
      "loss: 0.597926 [ 1600/ 5994]\n",
      "loss: 0.888379 [ 3200/ 5994]\n",
      "loss: 0.736963 [ 4800/ 5994]\n",
      "Training Loss: 0.6910, Training Accuracy: 79.5963%\n",
      "Test Loss: 1.5105, Test Accuracy: 58.6814%\n",
      "Epoch 277/500-------------------\n",
      "loss: 0.578528 [    0/ 5994]\n",
      "loss: 0.708207 [ 1600/ 5994]\n",
      "loss: 0.532519 [ 3200/ 5994]\n",
      "loss: 1.051240 [ 4800/ 5994]\n",
      "Training Loss: 0.6850, Training Accuracy: 80.1969%\n",
      "Test Loss: 1.4990, Test Accuracy: 59.3200%\n",
      "Epoch 278/500-------------------\n",
      "loss: 1.258374 [    0/ 5994]\n",
      "loss: 0.725297 [ 1600/ 5994]\n",
      "loss: 0.718799 [ 3200/ 5994]\n",
      "loss: 0.814525 [ 4800/ 5994]\n",
      "Training Loss: 0.6855, Training Accuracy: 80.2469%\n",
      "Test Loss: 1.5030, Test Accuracy: 59.2337%\n",
      "Epoch 279/500-------------------\n",
      "loss: 0.450932 [    0/ 5994]\n",
      "loss: 0.651146 [ 1600/ 5994]\n",
      "loss: 0.546510 [ 3200/ 5994]\n",
      "loss: 0.776354 [ 4800/ 5994]\n",
      "Training Loss: 0.6895, Training Accuracy: 80.0300%\n",
      "Test Loss: 1.5076, Test Accuracy: 58.7159%\n",
      "Epoch 280/500-------------------\n",
      "loss: 0.376362 [    0/ 5994]\n",
      "loss: 1.119827 [ 1600/ 5994]\n",
      "loss: 0.810730 [ 3200/ 5994]\n",
      "loss: 0.749678 [ 4800/ 5994]\n",
      "Training Loss: 0.6921, Training Accuracy: 79.4962%\n",
      "Test Loss: 1.5125, Test Accuracy: 59.3027%\n",
      "Epoch 281/500-------------------\n",
      "loss: 0.865344 [    0/ 5994]\n",
      "loss: 0.748642 [ 1600/ 5994]\n",
      "loss: 0.677217 [ 3200/ 5994]\n",
      "loss: 0.483180 [ 4800/ 5994]\n",
      "Training Loss: 0.6873, Training Accuracy: 80.1802%\n",
      "Test Loss: 1.5116, Test Accuracy: 59.1129%\n",
      "Epoch 282/500-------------------\n",
      "loss: 0.601475 [    0/ 5994]\n",
      "loss: 0.676354 [ 1600/ 5994]\n",
      "loss: 0.739251 [ 3200/ 5994]\n",
      "loss: 0.241765 [ 4800/ 5994]\n",
      "Training Loss: 0.6885, Training Accuracy: 79.8298%\n",
      "Test Loss: 1.5123, Test Accuracy: 58.9230%\n",
      "Epoch 283/500-------------------\n",
      "loss: 0.635705 [    0/ 5994]\n",
      "loss: 0.850984 [ 1600/ 5994]\n",
      "loss: 0.596808 [ 3200/ 5994]\n",
      "loss: 0.958449 [ 4800/ 5994]\n",
      "Training Loss: 0.6855, Training Accuracy: 79.7965%\n",
      "Test Loss: 1.5045, Test Accuracy: 59.2509%\n",
      "Epoch 284/500-------------------\n",
      "loss: 0.306644 [    0/ 5994]\n",
      "loss: 1.032384 [ 1600/ 5994]\n",
      "loss: 0.461960 [ 3200/ 5994]\n",
      "loss: 0.671904 [ 4800/ 5994]\n",
      "Training Loss: 0.6771, Training Accuracy: 80.6807%\n",
      "Test Loss: 1.5033, Test Accuracy: 59.2164%\n",
      "Epoch 285/500-------------------\n",
      "loss: 0.377243 [    0/ 5994]\n",
      "loss: 0.503979 [ 1600/ 5994]\n",
      "loss: 0.518888 [ 3200/ 5994]\n",
      "loss: 0.451947 [ 4800/ 5994]\n",
      "Training Loss: 0.6767, Training Accuracy: 80.4304%\n",
      "Test Loss: 1.5051, Test Accuracy: 59.3718%\n",
      "Epoch 286/500-------------------\n",
      "loss: 0.831033 [    0/ 5994]\n",
      "loss: 0.655954 [ 1600/ 5994]\n",
      "loss: 0.375415 [ 3200/ 5994]\n",
      "loss: 0.493889 [ 4800/ 5994]\n",
      "Training Loss: 0.6806, Training Accuracy: 80.3971%\n",
      "Test Loss: 1.5097, Test Accuracy: 59.6134%\n",
      "Epoch 287/500-------------------\n",
      "loss: 0.486242 [    0/ 5994]\n",
      "loss: 0.888590 [ 1600/ 5994]\n",
      "loss: 0.579440 [ 3200/ 5994]\n",
      "loss: 0.635047 [ 4800/ 5994]\n",
      "Training Loss: 0.6838, Training Accuracy: 80.0300%\n",
      "Test Loss: 1.5169, Test Accuracy: 58.1464%\n",
      "Epoch 288/500-------------------\n",
      "loss: 0.810379 [    0/ 5994]\n",
      "loss: 0.675864 [ 1600/ 5994]\n",
      "loss: 0.682318 [ 3200/ 5994]\n",
      "loss: 0.547824 [ 4800/ 5994]\n",
      "Training Loss: 0.6779, Training Accuracy: 80.5472%\n",
      "Test Loss: 1.5076, Test Accuracy: 59.0438%\n",
      "Epoch 289/500-------------------\n",
      "loss: 0.756558 [    0/ 5994]\n",
      "loss: 0.613900 [ 1600/ 5994]\n",
      "loss: 0.857304 [ 3200/ 5994]\n",
      "loss: 0.555679 [ 4800/ 5994]\n",
      "Training Loss: 0.6823, Training Accuracy: 80.1301%\n",
      "Test Loss: 1.5132, Test Accuracy: 58.4570%\n",
      "Epoch 290/500-------------------\n",
      "loss: 0.534933 [    0/ 5994]\n",
      "loss: 0.626402 [ 1600/ 5994]\n",
      "loss: 0.937350 [ 3200/ 5994]\n",
      "loss: 0.766751 [ 4800/ 5994]\n",
      "Training Loss: 0.6704, Training Accuracy: 80.9309%\n",
      "Test Loss: 1.5005, Test Accuracy: 59.4408%\n",
      "Epoch 291/500-------------------\n",
      "loss: 0.148685 [    0/ 5994]\n",
      "loss: 1.117485 [ 1600/ 5994]\n",
      "loss: 0.267477 [ 3200/ 5994]\n",
      "loss: 0.756735 [ 4800/ 5994]\n",
      "Training Loss: 0.6805, Training Accuracy: 80.0801%\n",
      "Test Loss: 1.5047, Test Accuracy: 59.2855%\n",
      "Epoch 292/500-------------------\n",
      "loss: 0.442701 [    0/ 5994]\n",
      "loss: 0.813953 [ 1600/ 5994]\n",
      "loss: 0.607505 [ 3200/ 5994]\n",
      "loss: 0.789037 [ 4800/ 5994]\n",
      "Training Loss: 0.6845, Training Accuracy: 80.0467%\n",
      "Test Loss: 1.5150, Test Accuracy: 58.3880%\n",
      "Epoch 293/500-------------------\n",
      "loss: 1.120834 [    0/ 5994]\n",
      "loss: 0.408825 [ 1600/ 5994]\n",
      "loss: 0.616719 [ 3200/ 5994]\n",
      "loss: 0.787725 [ 4800/ 5994]\n",
      "Training Loss: 0.6730, Training Accuracy: 80.3971%\n",
      "Test Loss: 1.5057, Test Accuracy: 59.1819%\n",
      "Epoch 294/500-------------------\n",
      "loss: 0.774309 [    0/ 5994]\n",
      "loss: 0.621698 [ 1600/ 5994]\n",
      "loss: 0.618171 [ 3200/ 5994]\n",
      "loss: 0.924590 [ 4800/ 5994]\n",
      "Training Loss: 0.6772, Training Accuracy: 80.3804%\n",
      "Test Loss: 1.5112, Test Accuracy: 58.9921%\n",
      "Epoch 295/500-------------------\n",
      "loss: 0.832797 [    0/ 5994]\n",
      "loss: 0.789879 [ 1600/ 5994]\n",
      "loss: 0.942247 [ 3200/ 5994]\n",
      "loss: 0.782061 [ 4800/ 5994]\n",
      "Training Loss: 0.6773, Training Accuracy: 80.1969%\n",
      "Test Loss: 1.5066, Test Accuracy: 59.1992%\n",
      "Epoch 296/500-------------------\n",
      "loss: 0.688427 [    0/ 5994]\n",
      "loss: 0.460292 [ 1600/ 5994]\n",
      "loss: 0.758788 [ 3200/ 5994]\n",
      "loss: 0.525421 [ 4800/ 5994]\n",
      "Training Loss: 0.6846, Training Accuracy: 79.9299%\n",
      "Test Loss: 1.5203, Test Accuracy: 58.5433%\n",
      "Epoch 297/500-------------------\n",
      "loss: 0.848964 [    0/ 5994]\n",
      "loss: 0.641409 [ 1600/ 5994]\n",
      "loss: 0.581135 [ 3200/ 5994]\n",
      "loss: 0.758174 [ 4800/ 5994]\n",
      "Training Loss: 0.6757, Training Accuracy: 80.4304%\n",
      "Test Loss: 1.5157, Test Accuracy: 58.7849%\n",
      "Epoch 298/500-------------------\n",
      "loss: 0.463240 [    0/ 5994]\n",
      "loss: 0.752724 [ 1600/ 5994]\n",
      "loss: 1.004863 [ 3200/ 5994]\n",
      "loss: 0.813604 [ 4800/ 5994]\n",
      "Training Loss: 0.6748, Training Accuracy: 80.1635%\n",
      "Test Loss: 1.5165, Test Accuracy: 58.6987%\n",
      "Epoch 299/500-------------------\n",
      "loss: 0.696012 [    0/ 5994]\n",
      "loss: 0.554569 [ 1600/ 5994]\n",
      "loss: 0.394418 [ 3200/ 5994]\n",
      "loss: 0.643520 [ 4800/ 5994]\n",
      "Training Loss: 0.6709, Training Accuracy: 80.5806%\n",
      "Test Loss: 1.5124, Test Accuracy: 59.2164%\n",
      "Epoch 300/500-------------------\n",
      "loss: 0.586816 [    0/ 5994]\n",
      "loss: 0.662148 [ 1600/ 5994]\n",
      "loss: 1.119223 [ 3200/ 5994]\n",
      "loss: 1.161410 [ 4800/ 5994]\n",
      "Training Loss: 0.6675, Training Accuracy: 81.0644%\n",
      "Test Loss: 1.5017, Test Accuracy: 59.6824%\n",
      "Epoch 301/500-------------------\n",
      "loss: 0.467198 [    0/ 5994]\n",
      "loss: 0.821132 [ 1600/ 5994]\n",
      "loss: 0.993354 [ 3200/ 5994]\n",
      "loss: 0.711007 [ 4800/ 5994]\n",
      "Training Loss: 0.6726, Training Accuracy: 80.4805%\n",
      "Test Loss: 1.5138, Test Accuracy: 58.5261%\n",
      "Epoch 302/500-------------------\n",
      "loss: 0.668591 [    0/ 5994]\n",
      "loss: 0.611187 [ 1600/ 5994]\n",
      "loss: 0.474934 [ 3200/ 5994]\n",
      "loss: 0.840718 [ 4800/ 5994]\n",
      "Training Loss: 0.6692, Training Accuracy: 80.6473%\n",
      "Test Loss: 1.5094, Test Accuracy: 58.8367%\n",
      "Epoch 303/500-------------------\n",
      "loss: 0.332302 [    0/ 5994]\n",
      "loss: 1.009643 [ 1600/ 5994]\n",
      "loss: 0.769983 [ 3200/ 5994]\n",
      "loss: 0.541700 [ 4800/ 5994]\n",
      "Training Loss: 0.6646, Training Accuracy: 80.7140%\n",
      "Test Loss: 1.5061, Test Accuracy: 59.3372%\n",
      "Epoch 304/500-------------------\n",
      "loss: 0.514615 [    0/ 5994]\n",
      "loss: 0.457815 [ 1600/ 5994]\n",
      "loss: 0.607746 [ 3200/ 5994]\n",
      "loss: 0.830019 [ 4800/ 5994]\n",
      "Training Loss: 0.6681, Training Accuracy: 80.6306%\n",
      "Test Loss: 1.5102, Test Accuracy: 59.0438%\n",
      "Epoch 305/500-------------------\n",
      "loss: 0.683751 [    0/ 5994]\n",
      "loss: 0.445505 [ 1600/ 5994]\n",
      "loss: 0.852489 [ 3200/ 5994]\n",
      "loss: 0.470558 [ 4800/ 5994]\n",
      "Training Loss: 0.6659, Training Accuracy: 80.5305%\n",
      "Test Loss: 1.5054, Test Accuracy: 59.1129%\n",
      "Epoch 306/500-------------------\n",
      "loss: 0.889699 [    0/ 5994]\n",
      "loss: 0.886970 [ 1600/ 5994]\n",
      "loss: 0.921260 [ 3200/ 5994]\n",
      "loss: 0.278115 [ 4800/ 5994]\n",
      "Training Loss: 0.6681, Training Accuracy: 80.6139%\n",
      "Test Loss: 1.5157, Test Accuracy: 59.3027%\n",
      "Epoch 307/500-------------------\n",
      "loss: 0.827135 [    0/ 5994]\n",
      "loss: 0.592647 [ 1600/ 5994]\n",
      "loss: 0.852919 [ 3200/ 5994]\n",
      "loss: 1.025741 [ 4800/ 5994]\n",
      "Training Loss: 0.6684, Training Accuracy: 80.9309%\n",
      "Test Loss: 1.5143, Test Accuracy: 58.7332%\n",
      "Epoch 308/500-------------------\n",
      "loss: 1.010875 [    0/ 5994]\n",
      "loss: 0.983154 [ 1600/ 5994]\n",
      "loss: 0.591718 [ 3200/ 5994]\n",
      "loss: 0.468856 [ 4800/ 5994]\n",
      "Training Loss: 0.6618, Training Accuracy: 80.7808%\n",
      "Test Loss: 1.5093, Test Accuracy: 59.4753%\n",
      "Epoch 309/500-------------------\n",
      "loss: 1.052234 [    0/ 5994]\n",
      "loss: 0.643752 [ 1600/ 5994]\n",
      "loss: 0.285026 [ 3200/ 5994]\n",
      "loss: 0.767959 [ 4800/ 5994]\n",
      "Training Loss: 0.6603, Training Accuracy: 80.9643%\n",
      "Test Loss: 1.5011, Test Accuracy: 58.8195%\n",
      "Epoch 310/500-------------------\n",
      "loss: 0.594399 [    0/ 5994]\n",
      "loss: 0.534892 [ 1600/ 5994]\n",
      "loss: 0.679472 [ 3200/ 5994]\n",
      "loss: 0.627448 [ 4800/ 5994]\n",
      "Training Loss: 0.6647, Training Accuracy: 80.5305%\n",
      "Test Loss: 1.5099, Test Accuracy: 59.3718%\n",
      "Epoch 311/500-------------------\n",
      "loss: 0.596481 [    0/ 5994]\n",
      "loss: 0.921366 [ 1600/ 5994]\n",
      "loss: 0.904426 [ 3200/ 5994]\n",
      "loss: 0.472357 [ 4800/ 5994]\n",
      "Training Loss: 0.6588, Training Accuracy: 80.8809%\n",
      "Test Loss: 1.5074, Test Accuracy: 59.1474%\n",
      "Epoch 312/500-------------------\n",
      "loss: 0.512962 [    0/ 5994]\n",
      "loss: 1.138217 [ 1600/ 5994]\n",
      "loss: 0.487295 [ 3200/ 5994]\n",
      "loss: 0.631194 [ 4800/ 5994]\n",
      "Training Loss: 0.6594, Training Accuracy: 81.1979%\n",
      "Test Loss: 1.5083, Test Accuracy: 59.3545%\n",
      "Epoch 313/500-------------------\n",
      "loss: 0.619408 [    0/ 5994]\n",
      "loss: 0.920669 [ 1600/ 5994]\n",
      "loss: 0.526807 [ 3200/ 5994]\n",
      "loss: 0.808119 [ 4800/ 5994]\n",
      "Training Loss: 0.6613, Training Accuracy: 80.7474%\n",
      "Test Loss: 1.5149, Test Accuracy: 58.6469%\n",
      "Epoch 314/500-------------------\n",
      "loss: 0.755521 [    0/ 5994]\n",
      "loss: 0.807293 [ 1600/ 5994]\n",
      "loss: 0.753108 [ 3200/ 5994]\n",
      "loss: 0.273717 [ 4800/ 5994]\n",
      "Training Loss: 0.6571, Training Accuracy: 81.0310%\n",
      "Test Loss: 1.5113, Test Accuracy: 58.8195%\n",
      "Epoch 315/500-------------------\n",
      "loss: 0.503337 [    0/ 5994]\n",
      "loss: 0.841781 [ 1600/ 5994]\n",
      "loss: 1.230041 [ 3200/ 5994]\n",
      "loss: 0.433319 [ 4800/ 5994]\n",
      "Training Loss: 0.6640, Training Accuracy: 80.6306%\n",
      "Test Loss: 1.5159, Test Accuracy: 59.0266%\n",
      "Epoch 316/500-------------------\n",
      "loss: 0.378519 [    0/ 5994]\n",
      "loss: 0.659516 [ 1600/ 5994]\n",
      "loss: 0.392014 [ 3200/ 5994]\n",
      "loss: 0.639019 [ 4800/ 5994]\n",
      "Training Loss: 0.6674, Training Accuracy: 80.0801%\n",
      "Test Loss: 1.5262, Test Accuracy: 58.5261%\n",
      "Epoch 317/500-------------------\n",
      "loss: 0.708432 [    0/ 5994]\n",
      "loss: 0.541223 [ 1600/ 5994]\n",
      "loss: 0.679680 [ 3200/ 5994]\n",
      "loss: 0.545862 [ 4800/ 5994]\n",
      "Training Loss: 0.6588, Training Accuracy: 80.8475%\n",
      "Test Loss: 1.5160, Test Accuracy: 58.6469%\n",
      "Epoch 318/500-------------------\n",
      "loss: 0.750762 [    0/ 5994]\n",
      "loss: 0.635074 [ 1600/ 5994]\n",
      "loss: 0.592329 [ 3200/ 5994]\n",
      "loss: 0.257175 [ 4800/ 5994]\n",
      "Training Loss: 0.6532, Training Accuracy: 81.7651%\n",
      "Test Loss: 1.5087, Test Accuracy: 59.1992%\n",
      "Epoch 319/500-------------------\n",
      "loss: 0.495372 [    0/ 5994]\n",
      "loss: 0.533134 [ 1600/ 5994]\n",
      "loss: 1.340925 [ 3200/ 5994]\n",
      "loss: 0.379792 [ 4800/ 5994]\n",
      "Training Loss: 0.6548, Training Accuracy: 81.1645%\n",
      "Test Loss: 1.5143, Test Accuracy: 59.3027%\n",
      "Epoch 320/500-------------------\n",
      "loss: 0.917829 [    0/ 5994]\n",
      "loss: 0.724632 [ 1600/ 5994]\n",
      "loss: 0.778256 [ 3200/ 5994]\n",
      "loss: 0.851684 [ 4800/ 5994]\n",
      "Training Loss: 0.6558, Training Accuracy: 81.1311%\n",
      "Test Loss: 1.5169, Test Accuracy: 59.3027%\n",
      "Epoch 321/500-------------------\n",
      "loss: 0.686301 [    0/ 5994]\n",
      "loss: 0.888737 [ 1600/ 5994]\n",
      "loss: 0.811481 [ 3200/ 5994]\n",
      "loss: 0.659651 [ 4800/ 5994]\n",
      "Training Loss: 0.6598, Training Accuracy: 80.9476%\n",
      "Test Loss: 1.5214, Test Accuracy: 58.8885%\n",
      "Epoch 322/500-------------------\n",
      "loss: 0.483463 [    0/ 5994]\n",
      "loss: 0.787967 [ 1600/ 5994]\n",
      "loss: 0.731359 [ 3200/ 5994]\n",
      "loss: 0.610064 [ 4800/ 5994]\n",
      "Training Loss: 0.6533, Training Accuracy: 81.1478%\n",
      "Test Loss: 1.5137, Test Accuracy: 58.9921%\n",
      "Epoch 323/500-------------------\n",
      "loss: 0.810734 [    0/ 5994]\n",
      "loss: 0.493443 [ 1600/ 5994]\n",
      "loss: 0.324009 [ 3200/ 5994]\n",
      "loss: 0.860593 [ 4800/ 5994]\n",
      "Training Loss: 0.6549, Training Accuracy: 81.0143%\n",
      "Test Loss: 1.5175, Test Accuracy: 58.7159%\n",
      "Epoch 324/500-------------------\n",
      "loss: 0.529257 [    0/ 5994]\n",
      "loss: 1.109175 [ 1600/ 5994]\n",
      "loss: 0.472551 [ 3200/ 5994]\n",
      "loss: 0.669933 [ 4800/ 5994]\n",
      "Training Loss: 0.6607, Training Accuracy: 80.6139%\n",
      "Test Loss: 1.5261, Test Accuracy: 58.7332%\n",
      "Epoch 325/500-------------------\n",
      "loss: 0.721013 [    0/ 5994]\n",
      "loss: 1.039332 [ 1600/ 5994]\n",
      "loss: 0.824094 [ 3200/ 5994]\n",
      "loss: 0.573321 [ 4800/ 5994]\n",
      "Training Loss: 0.6545, Training Accuracy: 81.3814%\n",
      "Test Loss: 1.5149, Test Accuracy: 59.2337%\n",
      "Epoch 326/500-------------------\n",
      "loss: 0.810019 [    0/ 5994]\n",
      "loss: 0.955270 [ 1600/ 5994]\n",
      "loss: 0.962485 [ 3200/ 5994]\n",
      "loss: 1.433979 [ 4800/ 5994]\n",
      "Training Loss: 0.6570, Training Accuracy: 80.9810%\n",
      "Test Loss: 1.5252, Test Accuracy: 59.2337%\n",
      "Epoch 327/500-------------------\n",
      "loss: 1.303477 [    0/ 5994]\n",
      "loss: 0.427292 [ 1600/ 5994]\n",
      "loss: 0.438743 [ 3200/ 5994]\n",
      "loss: 0.377021 [ 4800/ 5994]\n",
      "Training Loss: 0.6550, Training Accuracy: 80.8141%\n",
      "Test Loss: 1.5198, Test Accuracy: 59.0266%\n",
      "Epoch 328/500-------------------\n",
      "loss: 0.466184 [    0/ 5994]\n",
      "loss: 0.696736 [ 1600/ 5994]\n",
      "loss: 0.349907 [ 3200/ 5994]\n",
      "loss: 0.646536 [ 4800/ 5994]\n",
      "Training Loss: 0.6548, Training Accuracy: 80.7975%\n",
      "Test Loss: 1.5244, Test Accuracy: 59.3545%\n",
      "Epoch 329/500-------------------\n",
      "loss: 0.659221 [    0/ 5994]\n",
      "loss: 0.587532 [ 1600/ 5994]\n",
      "loss: 0.756096 [ 3200/ 5994]\n",
      "loss: 0.534940 [ 4800/ 5994]\n",
      "Training Loss: 0.6496, Training Accuracy: 81.1478%\n",
      "Test Loss: 1.5161, Test Accuracy: 58.8540%\n",
      "Epoch 330/500-------------------\n",
      "loss: 0.785492 [    0/ 5994]\n",
      "loss: 0.964367 [ 1600/ 5994]\n",
      "loss: 1.092521 [ 3200/ 5994]\n",
      "loss: 0.782259 [ 4800/ 5994]\n",
      "Training Loss: 0.6539, Training Accuracy: 80.5806%\n",
      "Test Loss: 1.5222, Test Accuracy: 58.9403%\n",
      "Epoch 331/500-------------------\n",
      "loss: 0.428836 [    0/ 5994]\n",
      "loss: 0.881800 [ 1600/ 5994]\n",
      "loss: 0.544229 [ 3200/ 5994]\n",
      "loss: 0.692820 [ 4800/ 5994]\n",
      "Training Loss: 0.6525, Training Accuracy: 81.2145%\n",
      "Test Loss: 1.5225, Test Accuracy: 58.8022%\n",
      "Epoch 332/500-------------------\n",
      "loss: 0.456802 [    0/ 5994]\n",
      "loss: 0.453159 [ 1600/ 5994]\n",
      "loss: 0.248528 [ 3200/ 5994]\n",
      "loss: 0.312125 [ 4800/ 5994]\n",
      "Training Loss: 0.6430, Training Accuracy: 81.3981%\n",
      "Test Loss: 1.5090, Test Accuracy: 58.7849%\n",
      "Epoch 333/500-------------------\n",
      "loss: 0.667951 [    0/ 5994]\n",
      "loss: 0.906574 [ 1600/ 5994]\n",
      "loss: 0.743219 [ 3200/ 5994]\n",
      "loss: 0.774699 [ 4800/ 5994]\n",
      "Training Loss: 0.6496, Training Accuracy: 81.2479%\n",
      "Test Loss: 1.5210, Test Accuracy: 59.2682%\n",
      "Epoch 334/500-------------------\n",
      "loss: 0.496988 [    0/ 5994]\n",
      "loss: 0.553212 [ 1600/ 5994]\n",
      "loss: 0.390050 [ 3200/ 5994]\n",
      "loss: 0.473597 [ 4800/ 5994]\n",
      "Training Loss: 0.6448, Training Accuracy: 81.5649%\n",
      "Test Loss: 1.5151, Test Accuracy: 59.3372%\n",
      "Epoch 335/500-------------------\n",
      "loss: 0.291450 [    0/ 5994]\n",
      "loss: 0.720302 [ 1600/ 5994]\n",
      "loss: 0.334853 [ 3200/ 5994]\n",
      "loss: 0.735145 [ 4800/ 5994]\n",
      "Training Loss: 0.6452, Training Accuracy: 81.5649%\n",
      "Test Loss: 1.5122, Test Accuracy: 59.1819%\n",
      "Epoch 336/500-------------------\n",
      "loss: 0.227272 [    0/ 5994]\n",
      "loss: 0.530262 [ 1600/ 5994]\n",
      "loss: 1.143328 [ 3200/ 5994]\n",
      "loss: 1.036922 [ 4800/ 5994]\n",
      "Training Loss: 0.6418, Training Accuracy: 81.7484%\n",
      "Test Loss: 1.5124, Test Accuracy: 59.4235%\n",
      "Epoch 337/500-------------------\n",
      "loss: 0.642296 [    0/ 5994]\n",
      "loss: 0.819281 [ 1600/ 5994]\n",
      "loss: 0.631088 [ 3200/ 5994]\n",
      "loss: 0.298154 [ 4800/ 5994]\n",
      "Training Loss: 0.6422, Training Accuracy: 81.5482%\n",
      "Test Loss: 1.5206, Test Accuracy: 58.8540%\n",
      "Epoch 338/500-------------------\n",
      "loss: 0.743935 [    0/ 5994]\n",
      "loss: 0.755144 [ 1600/ 5994]\n",
      "loss: 0.602491 [ 3200/ 5994]\n",
      "loss: 0.289912 [ 4800/ 5994]\n",
      "Training Loss: 0.6446, Training Accuracy: 80.9309%\n",
      "Test Loss: 1.5202, Test Accuracy: 59.1819%\n",
      "Epoch 339/500-------------------\n",
      "loss: 1.000706 [    0/ 5994]\n",
      "loss: 0.735760 [ 1600/ 5994]\n",
      "loss: 0.604436 [ 3200/ 5994]\n",
      "loss: 0.774146 [ 4800/ 5994]\n",
      "Training Loss: 0.6511, Training Accuracy: 80.9142%\n",
      "Test Loss: 1.5326, Test Accuracy: 58.9921%\n",
      "Epoch 340/500-------------------\n",
      "loss: 0.470556 [    0/ 5994]\n",
      "loss: 0.693276 [ 1600/ 5994]\n",
      "loss: 0.689102 [ 3200/ 5994]\n",
      "loss: 0.412210 [ 4800/ 5994]\n",
      "Training Loss: 0.6430, Training Accuracy: 81.3647%\n",
      "Test Loss: 1.5158, Test Accuracy: 59.3372%\n",
      "Epoch 341/500-------------------\n",
      "loss: 0.490796 [    0/ 5994]\n",
      "loss: 0.828658 [ 1600/ 5994]\n",
      "loss: 0.719465 [ 3200/ 5994]\n",
      "loss: 0.540067 [ 4800/ 5994]\n",
      "Training Loss: 0.6427, Training Accuracy: 82.0988%\n",
      "Test Loss: 1.5238, Test Accuracy: 59.0784%\n",
      "Epoch 342/500-------------------\n",
      "loss: 0.531280 [    0/ 5994]\n",
      "loss: 0.882930 [ 1600/ 5994]\n",
      "loss: 0.689910 [ 3200/ 5994]\n",
      "loss: 0.435409 [ 4800/ 5994]\n",
      "Training Loss: 0.6436, Training Accuracy: 81.4982%\n",
      "Test Loss: 1.5282, Test Accuracy: 59.1647%\n",
      "Epoch 343/500-------------------\n",
      "loss: 0.465486 [    0/ 5994]\n",
      "loss: 0.937413 [ 1600/ 5994]\n",
      "loss: 0.451648 [ 3200/ 5994]\n",
      "loss: 0.692417 [ 4800/ 5994]\n",
      "Training Loss: 0.6403, Training Accuracy: 81.5148%\n",
      "Test Loss: 1.5163, Test Accuracy: 59.1992%\n",
      "Epoch 344/500-------------------\n",
      "loss: 0.345934 [    0/ 5994]\n",
      "loss: 0.859813 [ 1600/ 5994]\n",
      "loss: 0.854859 [ 3200/ 5994]\n",
      "loss: 0.773709 [ 4800/ 5994]\n",
      "Training Loss: 0.6420, Training Accuracy: 80.8642%\n",
      "Test Loss: 1.5190, Test Accuracy: 58.6469%\n",
      "Epoch 345/500-------------------\n",
      "loss: 0.585384 [    0/ 5994]\n",
      "loss: 0.574463 [ 1600/ 5994]\n",
      "loss: 0.864229 [ 3200/ 5994]\n",
      "loss: 0.675234 [ 4800/ 5994]\n",
      "Training Loss: 0.6388, Training Accuracy: 81.9653%\n",
      "Test Loss: 1.5186, Test Accuracy: 59.1129%\n",
      "Epoch 346/500-------------------\n",
      "loss: 0.603619 [    0/ 5994]\n",
      "loss: 0.357600 [ 1600/ 5994]\n",
      "loss: 0.462327 [ 3200/ 5994]\n",
      "loss: 0.658153 [ 4800/ 5994]\n",
      "Training Loss: 0.6387, Training Accuracy: 81.5649%\n",
      "Test Loss: 1.5178, Test Accuracy: 59.1647%\n",
      "Epoch 347/500-------------------\n",
      "loss: 0.419846 [    0/ 5994]\n",
      "loss: 0.551970 [ 1600/ 5994]\n",
      "loss: 0.559102 [ 3200/ 5994]\n",
      "loss: 0.599144 [ 4800/ 5994]\n",
      "Training Loss: 0.6410, Training Accuracy: 81.6316%\n",
      "Test Loss: 1.5216, Test Accuracy: 59.0611%\n",
      "Epoch 348/500-------------------\n",
      "loss: 0.678093 [    0/ 5994]\n",
      "loss: 0.578937 [ 1600/ 5994]\n",
      "loss: 0.859312 [ 3200/ 5994]\n",
      "loss: 0.703348 [ 4800/ 5994]\n",
      "Training Loss: 0.6395, Training Accuracy: 81.3647%\n",
      "Test Loss: 1.5259, Test Accuracy: 58.7159%\n",
      "Epoch 349/500-------------------\n",
      "loss: 0.397854 [    0/ 5994]\n",
      "loss: 0.635404 [ 1600/ 5994]\n",
      "loss: 0.529741 [ 3200/ 5994]\n",
      "loss: 0.810406 [ 4800/ 5994]\n",
      "Training Loss: 0.6361, Training Accuracy: 81.6483%\n",
      "Test Loss: 1.5197, Test Accuracy: 58.9748%\n",
      "Epoch 350/500-------------------\n",
      "loss: 0.856432 [    0/ 5994]\n",
      "loss: 0.807198 [ 1600/ 5994]\n",
      "loss: 1.033862 [ 3200/ 5994]\n",
      "loss: 0.850808 [ 4800/ 5994]\n",
      "Training Loss: 0.6427, Training Accuracy: 81.4314%\n",
      "Test Loss: 1.5238, Test Accuracy: 58.6641%\n",
      "Epoch 351/500-------------------\n",
      "loss: 0.412787 [    0/ 5994]\n",
      "loss: 0.614833 [ 1600/ 5994]\n",
      "loss: 0.359912 [ 3200/ 5994]\n",
      "loss: 0.878401 [ 4800/ 5994]\n",
      "Training Loss: 0.6399, Training Accuracy: 81.4481%\n",
      "Test Loss: 1.5233, Test Accuracy: 58.8712%\n",
      "Epoch 352/500-------------------\n",
      "loss: 0.600590 [    0/ 5994]\n",
      "loss: 0.583328 [ 1600/ 5994]\n",
      "loss: 0.873292 [ 3200/ 5994]\n",
      "loss: 0.588099 [ 4800/ 5994]\n",
      "Training Loss: 0.6357, Training Accuracy: 81.9486%\n",
      "Test Loss: 1.5206, Test Accuracy: 58.9575%\n",
      "Epoch 353/500-------------------\n",
      "loss: 0.514554 [    0/ 5994]\n",
      "loss: 0.848894 [ 1600/ 5994]\n",
      "loss: 0.645370 [ 3200/ 5994]\n",
      "loss: 0.557093 [ 4800/ 5994]\n",
      "Training Loss: 0.6409, Training Accuracy: 81.2479%\n",
      "Test Loss: 1.5302, Test Accuracy: 58.5606%\n",
      "Epoch 354/500-------------------\n",
      "loss: 0.279119 [    0/ 5994]\n",
      "loss: 0.486521 [ 1600/ 5994]\n",
      "loss: 0.513074 [ 3200/ 5994]\n",
      "loss: 0.673864 [ 4800/ 5994]\n",
      "Training Loss: 0.6354, Training Accuracy: 81.5482%\n",
      "Test Loss: 1.5268, Test Accuracy: 58.9230%\n",
      "Epoch 355/500-------------------\n",
      "loss: 0.610613 [    0/ 5994]\n",
      "loss: 0.470218 [ 1600/ 5994]\n",
      "loss: 0.645394 [ 3200/ 5994]\n",
      "loss: 0.797307 [ 4800/ 5994]\n",
      "Training Loss: 0.6381, Training Accuracy: 81.3146%\n",
      "Test Loss: 1.5260, Test Accuracy: 59.5616%\n",
      "Epoch 356/500-------------------\n",
      "loss: 0.619954 [    0/ 5994]\n",
      "loss: 0.504688 [ 1600/ 5994]\n",
      "loss: 0.752105 [ 3200/ 5994]\n",
      "loss: 0.329677 [ 4800/ 5994]\n",
      "Training Loss: 0.6300, Training Accuracy: 82.0153%\n",
      "Test Loss: 1.5213, Test Accuracy: 59.0956%\n",
      "Epoch 357/500-------------------\n",
      "loss: 0.697260 [    0/ 5994]\n",
      "loss: 0.955374 [ 1600/ 5994]\n",
      "loss: 0.487526 [ 3200/ 5994]\n",
      "loss: 0.514542 [ 4800/ 5994]\n",
      "Training Loss: 0.6318, Training Accuracy: 81.9152%\n",
      "Test Loss: 1.5241, Test Accuracy: 59.1474%\n",
      "Epoch 358/500-------------------\n",
      "loss: 0.619885 [    0/ 5994]\n",
      "loss: 0.343753 [ 1600/ 5994]\n",
      "loss: 0.506386 [ 3200/ 5994]\n",
      "loss: 0.892427 [ 4800/ 5994]\n",
      "Training Loss: 0.6250, Training Accuracy: 82.6660%\n",
      "Test Loss: 1.5225, Test Accuracy: 59.2164%\n",
      "Epoch 359/500-------------------\n",
      "loss: 0.400624 [    0/ 5994]\n",
      "loss: 0.803021 [ 1600/ 5994]\n",
      "loss: 0.604653 [ 3200/ 5994]\n",
      "loss: 0.560399 [ 4800/ 5994]\n",
      "Training Loss: 0.6263, Training Accuracy: 82.2322%\n",
      "Test Loss: 1.5239, Test Accuracy: 58.7849%\n",
      "Epoch 360/500-------------------\n",
      "loss: 0.415259 [    0/ 5994]\n",
      "loss: 0.949636 [ 1600/ 5994]\n",
      "loss: 0.389996 [ 3200/ 5994]\n",
      "loss: 0.884683 [ 4800/ 5994]\n",
      "Training Loss: 0.6289, Training Accuracy: 82.2155%\n",
      "Test Loss: 1.5267, Test Accuracy: 59.0611%\n",
      "Epoch 361/500-------------------\n",
      "loss: 0.934023 [    0/ 5994]\n",
      "loss: 0.734257 [ 1600/ 5994]\n",
      "loss: 0.629364 [ 3200/ 5994]\n",
      "loss: 0.403273 [ 4800/ 5994]\n",
      "Training Loss: 0.6330, Training Accuracy: 81.5148%\n",
      "Test Loss: 1.5336, Test Accuracy: 58.9575%\n",
      "Epoch 362/500-------------------\n",
      "loss: 0.797703 [    0/ 5994]\n",
      "loss: 0.950576 [ 1600/ 5994]\n",
      "loss: 0.609760 [ 3200/ 5994]\n",
      "loss: 0.558565 [ 4800/ 5994]\n",
      "Training Loss: 0.6332, Training Accuracy: 81.8986%\n",
      "Test Loss: 1.5352, Test Accuracy: 58.5951%\n",
      "Epoch 363/500-------------------\n",
      "loss: 0.549747 [    0/ 5994]\n",
      "loss: 0.454292 [ 1600/ 5994]\n",
      "loss: 1.054975 [ 3200/ 5994]\n",
      "loss: 0.410756 [ 4800/ 5994]\n",
      "Training Loss: 0.6314, Training Accuracy: 81.9987%\n",
      "Test Loss: 1.5293, Test Accuracy: 58.6296%\n",
      "Epoch 364/500-------------------\n",
      "loss: 0.653456 [    0/ 5994]\n",
      "loss: 0.677656 [ 1600/ 5994]\n",
      "loss: 0.479269 [ 3200/ 5994]\n",
      "loss: 0.376438 [ 4800/ 5994]\n",
      "Training Loss: 0.6292, Training Accuracy: 81.6984%\n",
      "Test Loss: 1.5274, Test Accuracy: 59.4926%\n",
      "Epoch 365/500-------------------\n",
      "loss: 0.429016 [    0/ 5994]\n",
      "loss: 0.600981 [ 1600/ 5994]\n",
      "loss: 0.595279 [ 3200/ 5994]\n",
      "loss: 1.146261 [ 4800/ 5994]\n",
      "Training Loss: 0.6254, Training Accuracy: 81.8986%\n",
      "Test Loss: 1.5207, Test Accuracy: 59.4063%\n",
      "Epoch 366/500-------------------\n",
      "loss: 0.482513 [    0/ 5994]\n",
      "loss: 1.041896 [ 1600/ 5994]\n",
      "loss: 0.428168 [ 3200/ 5994]\n",
      "loss: 0.380083 [ 4800/ 5994]\n",
      "Training Loss: 0.6252, Training Accuracy: 81.9987%\n",
      "Test Loss: 1.5202, Test Accuracy: 58.6814%\n",
      "Epoch 367/500-------------------\n",
      "loss: 0.255346 [    0/ 5994]\n",
      "loss: 0.582674 [ 1600/ 5994]\n",
      "loss: 0.598148 [ 3200/ 5994]\n",
      "loss: 0.650712 [ 4800/ 5994]\n",
      "Training Loss: 0.6244, Training Accuracy: 82.1989%\n",
      "Test Loss: 1.5256, Test Accuracy: 59.2855%\n",
      "Epoch 368/500-------------------\n",
      "loss: 0.375016 [    0/ 5994]\n",
      "loss: 0.833210 [ 1600/ 5994]\n",
      "loss: 0.606904 [ 3200/ 5994]\n",
      "loss: 0.468466 [ 4800/ 5994]\n",
      "Training Loss: 0.6250, Training Accuracy: 82.0153%\n",
      "Test Loss: 1.5262, Test Accuracy: 59.1647%\n",
      "Epoch 369/500-------------------\n",
      "loss: 0.625299 [    0/ 5994]\n",
      "loss: 0.998231 [ 1600/ 5994]\n",
      "loss: 0.668522 [ 3200/ 5994]\n",
      "loss: 0.553592 [ 4800/ 5994]\n",
      "Training Loss: 0.6240, Training Accuracy: 82.1655%\n",
      "Test Loss: 1.5270, Test Accuracy: 59.5616%\n",
      "Epoch 370/500-------------------\n",
      "loss: 0.583663 [    0/ 5994]\n",
      "loss: 0.506192 [ 1600/ 5994]\n",
      "loss: 0.686896 [ 3200/ 5994]\n",
      "loss: 0.787026 [ 4800/ 5994]\n",
      "Training Loss: 0.6256, Training Accuracy: 81.9486%\n",
      "Test Loss: 1.5221, Test Accuracy: 59.4063%\n",
      "Epoch 371/500-------------------\n",
      "loss: 0.747250 [    0/ 5994]\n",
      "loss: 0.612880 [ 1600/ 5994]\n",
      "loss: 0.907839 [ 3200/ 5994]\n",
      "loss: 0.947637 [ 4800/ 5994]\n",
      "Training Loss: 0.6253, Training Accuracy: 82.0487%\n",
      "Test Loss: 1.5234, Test Accuracy: 59.4753%\n",
      "Epoch 372/500-------------------\n",
      "loss: 0.843048 [    0/ 5994]\n",
      "loss: 0.479219 [ 1600/ 5994]\n",
      "loss: 0.746040 [ 3200/ 5994]\n",
      "loss: 0.333038 [ 4800/ 5994]\n",
      "Training Loss: 0.6208, Training Accuracy: 82.0153%\n",
      "Test Loss: 1.5222, Test Accuracy: 59.0956%\n",
      "Epoch 373/500-------------------\n",
      "loss: 0.363807 [    0/ 5994]\n",
      "loss: 1.153552 [ 1600/ 5994]\n",
      "loss: 0.651558 [ 3200/ 5994]\n",
      "loss: 0.744619 [ 4800/ 5994]\n",
      "Training Loss: 0.6176, Training Accuracy: 82.5659%\n",
      "Test Loss: 1.5194, Test Accuracy: 59.3027%\n",
      "Epoch 374/500-------------------\n",
      "loss: 0.741396 [    0/ 5994]\n",
      "loss: 0.229967 [ 1600/ 5994]\n",
      "loss: 0.462443 [ 3200/ 5994]\n",
      "loss: 0.849515 [ 4800/ 5994]\n",
      "Training Loss: 0.6204, Training Accuracy: 82.4825%\n",
      "Test Loss: 1.5286, Test Accuracy: 58.9058%\n",
      "Epoch 375/500-------------------\n",
      "loss: 0.837595 [    0/ 5994]\n",
      "loss: 0.676906 [ 1600/ 5994]\n",
      "loss: 0.630107 [ 3200/ 5994]\n",
      "loss: 0.639109 [ 4800/ 5994]\n",
      "Training Loss: 0.6236, Training Accuracy: 82.0153%\n",
      "Test Loss: 1.5354, Test Accuracy: 59.3200%\n",
      "Epoch 376/500-------------------\n",
      "loss: 0.310060 [    0/ 5994]\n",
      "loss: 0.670709 [ 1600/ 5994]\n",
      "loss: 0.883087 [ 3200/ 5994]\n",
      "loss: 0.708050 [ 4800/ 5994]\n",
      "Training Loss: 0.6201, Training Accuracy: 82.1822%\n",
      "Test Loss: 1.5258, Test Accuracy: 59.1129%\n",
      "Epoch 377/500-------------------\n",
      "loss: 0.641643 [    0/ 5994]\n",
      "loss: 0.697792 [ 1600/ 5994]\n",
      "loss: 0.532195 [ 3200/ 5994]\n",
      "loss: 0.650242 [ 4800/ 5994]\n",
      "Training Loss: 0.6179, Training Accuracy: 82.5826%\n",
      "Test Loss: 1.5252, Test Accuracy: 59.5616%\n",
      "Epoch 378/500-------------------\n",
      "loss: 1.273013 [    0/ 5994]\n",
      "loss: 0.391645 [ 1600/ 5994]\n",
      "loss: 0.549652 [ 3200/ 5994]\n",
      "loss: 0.161493 [ 4800/ 5994]\n",
      "Training Loss: 0.6193, Training Accuracy: 81.9319%\n",
      "Test Loss: 1.5258, Test Accuracy: 58.8367%\n",
      "Epoch 379/500-------------------\n",
      "loss: 0.511380 [    0/ 5994]\n",
      "loss: 0.363009 [ 1600/ 5994]\n",
      "loss: 0.653860 [ 3200/ 5994]\n",
      "loss: 0.416655 [ 4800/ 5994]\n",
      "Training Loss: 0.6185, Training Accuracy: 82.4324%\n",
      "Test Loss: 1.5273, Test Accuracy: 59.1301%\n",
      "Epoch 380/500-------------------\n",
      "loss: 0.466921 [    0/ 5994]\n",
      "loss: 0.634798 [ 1600/ 5994]\n",
      "loss: 0.504732 [ 3200/ 5994]\n",
      "loss: 0.740454 [ 4800/ 5994]\n",
      "Training Loss: 0.6166, Training Accuracy: 82.3490%\n",
      "Test Loss: 1.5265, Test Accuracy: 59.1819%\n",
      "Epoch 381/500-------------------\n",
      "loss: 0.624902 [    0/ 5994]\n",
      "loss: 1.013880 [ 1600/ 5994]\n",
      "loss: 0.739039 [ 3200/ 5994]\n",
      "loss: 0.831836 [ 4800/ 5994]\n",
      "Training Loss: 0.6174, Training Accuracy: 82.4491%\n",
      "Test Loss: 1.5251, Test Accuracy: 59.0438%\n",
      "Epoch 382/500-------------------\n",
      "loss: 0.571197 [    0/ 5994]\n",
      "loss: 0.868694 [ 1600/ 5994]\n",
      "loss: 0.727037 [ 3200/ 5994]\n",
      "loss: 1.157539 [ 4800/ 5994]\n",
      "Training Loss: 0.6148, Training Accuracy: 82.6326%\n",
      "Test Loss: 1.5240, Test Accuracy: 58.9058%\n",
      "Epoch 383/500-------------------\n",
      "loss: 0.756821 [    0/ 5994]\n",
      "loss: 0.521621 [ 1600/ 5994]\n",
      "loss: 0.682850 [ 3200/ 5994]\n",
      "loss: 0.575050 [ 4800/ 5994]\n",
      "Training Loss: 0.6233, Training Accuracy: 81.7985%\n",
      "Test Loss: 1.5391, Test Accuracy: 59.0784%\n",
      "Epoch 384/500-------------------\n",
      "loss: 0.721809 [    0/ 5994]\n",
      "loss: 0.543349 [ 1600/ 5994]\n",
      "loss: 0.604919 [ 3200/ 5994]\n",
      "loss: 0.604024 [ 4800/ 5994]\n",
      "Training Loss: 0.6120, Training Accuracy: 82.3991%\n",
      "Test Loss: 1.5288, Test Accuracy: 58.8367%\n",
      "Epoch 385/500-------------------\n",
      "loss: 0.483811 [    0/ 5994]\n",
      "loss: 0.816282 [ 1600/ 5994]\n",
      "loss: 0.994720 [ 3200/ 5994]\n",
      "loss: 0.610277 [ 4800/ 5994]\n",
      "Training Loss: 0.6131, Training Accuracy: 82.5659%\n",
      "Test Loss: 1.5298, Test Accuracy: 58.8885%\n",
      "Epoch 386/500-------------------\n",
      "loss: 0.612303 [    0/ 5994]\n",
      "loss: 0.678647 [ 1600/ 5994]\n",
      "loss: 0.709198 [ 3200/ 5994]\n",
      "loss: 0.502911 [ 4800/ 5994]\n",
      "Training Loss: 0.6111, Training Accuracy: 82.8662%\n",
      "Test Loss: 1.5250, Test Accuracy: 59.0093%\n",
      "Epoch 387/500-------------------\n",
      "loss: 0.631896 [    0/ 5994]\n",
      "loss: 0.592730 [ 1600/ 5994]\n",
      "loss: 0.450610 [ 3200/ 5994]\n",
      "loss: 0.572660 [ 4800/ 5994]\n",
      "Training Loss: 0.6148, Training Accuracy: 82.2823%\n",
      "Test Loss: 1.5353, Test Accuracy: 58.5778%\n",
      "Epoch 388/500-------------------\n",
      "loss: 0.337681 [    0/ 5994]\n",
      "loss: 0.810486 [ 1600/ 5994]\n",
      "loss: 0.750598 [ 3200/ 5994]\n",
      "loss: 0.604414 [ 4800/ 5994]\n",
      "Training Loss: 0.6140, Training Accuracy: 82.1488%\n",
      "Test Loss: 1.5319, Test Accuracy: 58.8540%\n",
      "Epoch 389/500-------------------\n",
      "loss: 0.583155 [    0/ 5994]\n",
      "loss: 0.712853 [ 1600/ 5994]\n",
      "loss: 0.605343 [ 3200/ 5994]\n",
      "loss: 0.421355 [ 4800/ 5994]\n",
      "Training Loss: 0.6106, Training Accuracy: 82.4324%\n",
      "Test Loss: 1.5304, Test Accuracy: 59.3890%\n",
      "Epoch 390/500-------------------\n",
      "loss: 0.666184 [    0/ 5994]\n",
      "loss: 0.833932 [ 1600/ 5994]\n",
      "loss: 0.465621 [ 3200/ 5994]\n",
      "loss: 0.832575 [ 4800/ 5994]\n",
      "Training Loss: 0.6108, Training Accuracy: 82.5492%\n",
      "Test Loss: 1.5310, Test Accuracy: 58.9230%\n",
      "Epoch 391/500-------------------\n",
      "loss: 0.605368 [    0/ 5994]\n",
      "loss: 0.447513 [ 1600/ 5994]\n",
      "loss: 0.429673 [ 3200/ 5994]\n",
      "loss: 0.184802 [ 4800/ 5994]\n",
      "Training Loss: 0.6118, Training Accuracy: 82.4992%\n",
      "Test Loss: 1.5361, Test Accuracy: 59.2855%\n",
      "Epoch 392/500-------------------\n",
      "loss: 0.733632 [    0/ 5994]\n",
      "loss: 0.431444 [ 1600/ 5994]\n",
      "loss: 0.459338 [ 3200/ 5994]\n",
      "loss: 0.936226 [ 4800/ 5994]\n",
      "Training Loss: 0.6120, Training Accuracy: 82.3323%\n",
      "Test Loss: 1.5298, Test Accuracy: 58.9058%\n",
      "Epoch 393/500-------------------\n",
      "loss: 0.944397 [    0/ 5994]\n",
      "loss: 0.448774 [ 1600/ 5994]\n",
      "loss: 0.584105 [ 3200/ 5994]\n",
      "loss: 0.516894 [ 4800/ 5994]\n",
      "Training Loss: 0.6095, Training Accuracy: 82.9329%\n",
      "Test Loss: 1.5287, Test Accuracy: 58.8712%\n",
      "Epoch 394/500-------------------\n",
      "loss: 0.867293 [    0/ 5994]\n",
      "loss: 0.659489 [ 1600/ 5994]\n",
      "loss: 0.715539 [ 3200/ 5994]\n",
      "loss: 0.676230 [ 4800/ 5994]\n",
      "Training Loss: 0.6117, Training Accuracy: 82.5325%\n",
      "Test Loss: 1.5325, Test Accuracy: 58.9748%\n",
      "Epoch 395/500-------------------\n",
      "loss: 0.540612 [    0/ 5994]\n",
      "loss: 0.412869 [ 1600/ 5994]\n",
      "loss: 0.563968 [ 3200/ 5994]\n",
      "loss: 0.400305 [ 4800/ 5994]\n",
      "Training Loss: 0.6091, Training Accuracy: 82.0320%\n",
      "Test Loss: 1.5320, Test Accuracy: 58.9403%\n",
      "Epoch 396/500-------------------\n",
      "loss: 0.518817 [    0/ 5994]\n",
      "loss: 1.030588 [ 1600/ 5994]\n",
      "loss: 0.355664 [ 3200/ 5994]\n",
      "loss: 0.441450 [ 4800/ 5994]\n",
      "Training Loss: 0.6053, Training Accuracy: 82.7661%\n",
      "Test Loss: 1.5276, Test Accuracy: 58.9058%\n",
      "Epoch 397/500-------------------\n",
      "loss: 0.714471 [    0/ 5994]\n",
      "loss: 0.533017 [ 1600/ 5994]\n",
      "loss: 0.718408 [ 3200/ 5994]\n",
      "loss: 0.644732 [ 4800/ 5994]\n",
      "Training Loss: 0.6072, Training Accuracy: 82.6159%\n",
      "Test Loss: 1.5248, Test Accuracy: 58.7849%\n",
      "Epoch 398/500-------------------\n",
      "loss: 0.996563 [    0/ 5994]\n",
      "loss: 0.666876 [ 1600/ 5994]\n",
      "loss: 0.471043 [ 3200/ 5994]\n",
      "loss: 0.239383 [ 4800/ 5994]\n",
      "Training Loss: 0.6079, Training Accuracy: 82.9830%\n",
      "Test Loss: 1.5321, Test Accuracy: 58.9403%\n",
      "Epoch 399/500-------------------\n",
      "loss: 0.228420 [    0/ 5994]\n",
      "loss: 0.874585 [ 1600/ 5994]\n",
      "loss: 0.387902 [ 3200/ 5994]\n",
      "loss: 0.902921 [ 4800/ 5994]\n",
      "Training Loss: 0.6066, Training Accuracy: 82.6493%\n",
      "Test Loss: 1.5321, Test Accuracy: 59.0956%\n",
      "Epoch 400/500-------------------\n",
      "loss: 0.730407 [    0/ 5994]\n",
      "loss: 0.460679 [ 1600/ 5994]\n",
      "loss: 0.424650 [ 3200/ 5994]\n",
      "loss: 0.509417 [ 4800/ 5994]\n",
      "Training Loss: 0.6158, Training Accuracy: 82.2489%\n",
      "Test Loss: 1.5466, Test Accuracy: 59.1992%\n",
      "Epoch 401/500-------------------\n",
      "loss: 0.656112 [    0/ 5994]\n",
      "loss: 0.825512 [ 1600/ 5994]\n",
      "loss: 0.689052 [ 3200/ 5994]\n",
      "loss: 0.439981 [ 4800/ 5994]\n",
      "Training Loss: 0.6063, Training Accuracy: 82.9997%\n",
      "Test Loss: 1.5342, Test Accuracy: 59.2164%\n",
      "Epoch 402/500-------------------\n",
      "loss: 0.592676 [    0/ 5994]\n",
      "loss: 0.379675 [ 1600/ 5994]\n",
      "loss: 0.581880 [ 3200/ 5994]\n",
      "loss: 0.584985 [ 4800/ 5994]\n",
      "Training Loss: 0.6031, Training Accuracy: 83.0163%\n",
      "Test Loss: 1.5352, Test Accuracy: 58.9575%\n",
      "Epoch 403/500-------------------\n",
      "loss: 0.850990 [    0/ 5994]\n",
      "loss: 0.843347 [ 1600/ 5994]\n",
      "loss: 0.703401 [ 3200/ 5994]\n",
      "loss: 0.898295 [ 4800/ 5994]\n",
      "Training Loss: 0.6069, Training Accuracy: 82.8161%\n",
      "Test Loss: 1.5378, Test Accuracy: 58.9230%\n",
      "Epoch 404/500-------------------\n",
      "loss: 0.630203 [    0/ 5994]\n",
      "loss: 0.917134 [ 1600/ 5994]\n",
      "loss: 0.769128 [ 3200/ 5994]\n",
      "loss: 0.724465 [ 4800/ 5994]\n",
      "Training Loss: 0.6047, Training Accuracy: 82.7494%\n",
      "Test Loss: 1.5359, Test Accuracy: 59.1301%\n",
      "Epoch 405/500-------------------\n",
      "loss: 0.616144 [    0/ 5994]\n",
      "loss: 0.453770 [ 1600/ 5994]\n",
      "loss: 0.733553 [ 3200/ 5994]\n",
      "loss: 0.498875 [ 4800/ 5994]\n",
      "Training Loss: 0.5995, Training Accuracy: 82.8161%\n",
      "Test Loss: 1.5295, Test Accuracy: 59.3718%\n",
      "Epoch 406/500-------------------\n",
      "loss: 0.517507 [    0/ 5994]\n",
      "loss: 0.439672 [ 1600/ 5994]\n",
      "loss: 0.212518 [ 3200/ 5994]\n",
      "loss: 0.374104 [ 4800/ 5994]\n",
      "Training Loss: 0.6000, Training Accuracy: 83.0998%\n",
      "Test Loss: 1.5290, Test Accuracy: 59.5444%\n",
      "Epoch 407/500-------------------\n",
      "loss: 0.978491 [    0/ 5994]\n",
      "loss: 1.010319 [ 1600/ 5994]\n",
      "loss: 1.045935 [ 3200/ 5994]\n",
      "loss: 0.375548 [ 4800/ 5994]\n",
      "Training Loss: 0.5973, Training Accuracy: 83.4501%\n",
      "Test Loss: 1.5287, Test Accuracy: 59.3372%\n",
      "Epoch 408/500-------------------\n",
      "loss: 0.969916 [    0/ 5994]\n",
      "loss: 0.332607 [ 1600/ 5994]\n",
      "loss: 0.658698 [ 3200/ 5994]\n",
      "loss: 0.666907 [ 4800/ 5994]\n",
      "Training Loss: 0.6004, Training Accuracy: 82.8161%\n",
      "Test Loss: 1.5308, Test Accuracy: 59.3718%\n",
      "Epoch 409/500-------------------\n",
      "loss: 0.579804 [    0/ 5994]\n",
      "loss: 0.505993 [ 1600/ 5994]\n",
      "loss: 0.875248 [ 3200/ 5994]\n",
      "loss: 0.895213 [ 4800/ 5994]\n",
      "Training Loss: 0.6076, Training Accuracy: 82.6493%\n",
      "Test Loss: 1.5457, Test Accuracy: 58.8540%\n",
      "Epoch 410/500-------------------\n",
      "loss: 0.306926 [    0/ 5994]\n",
      "loss: 0.554794 [ 1600/ 5994]\n",
      "loss: 0.711837 [ 3200/ 5994]\n",
      "loss: 0.864631 [ 4800/ 5994]\n",
      "Training Loss: 0.5974, Training Accuracy: 83.2165%\n",
      "Test Loss: 1.5336, Test Accuracy: 59.6134%\n",
      "Epoch 411/500-------------------\n",
      "loss: 0.390145 [    0/ 5994]\n",
      "loss: 0.596170 [ 1600/ 5994]\n",
      "loss: 0.706409 [ 3200/ 5994]\n",
      "loss: 0.747602 [ 4800/ 5994]\n",
      "Training Loss: 0.5976, Training Accuracy: 82.8328%\n",
      "Test Loss: 1.5353, Test Accuracy: 59.2337%\n",
      "Epoch 412/500-------------------\n",
      "loss: 0.448797 [    0/ 5994]\n",
      "loss: 0.458338 [ 1600/ 5994]\n",
      "loss: 0.443608 [ 3200/ 5994]\n",
      "loss: 0.569980 [ 4800/ 5994]\n",
      "Training Loss: 0.5982, Training Accuracy: 82.7494%\n",
      "Test Loss: 1.5401, Test Accuracy: 58.4915%\n",
      "Epoch 413/500-------------------\n",
      "loss: 0.602886 [    0/ 5994]\n",
      "loss: 0.372653 [ 1600/ 5994]\n",
      "loss: 0.604529 [ 3200/ 5994]\n",
      "loss: 0.649917 [ 4800/ 5994]\n",
      "Training Loss: 0.6000, Training Accuracy: 83.2165%\n",
      "Test Loss: 1.5347, Test Accuracy: 59.3545%\n",
      "Epoch 414/500-------------------\n",
      "loss: 0.602211 [    0/ 5994]\n",
      "loss: 0.565107 [ 1600/ 5994]\n",
      "loss: 0.911380 [ 3200/ 5994]\n",
      "loss: 0.434782 [ 4800/ 5994]\n",
      "Training Loss: 0.5986, Training Accuracy: 82.6994%\n",
      "Test Loss: 1.5351, Test Accuracy: 59.0784%\n",
      "Epoch 415/500-------------------\n",
      "loss: 0.775544 [    0/ 5994]\n",
      "loss: 0.557565 [ 1600/ 5994]\n",
      "loss: 0.386475 [ 3200/ 5994]\n",
      "loss: 0.789928 [ 4800/ 5994]\n",
      "Training Loss: 0.5966, Training Accuracy: 82.9997%\n",
      "Test Loss: 1.5326, Test Accuracy: 58.6987%\n",
      "Epoch 416/500-------------------\n",
      "loss: 0.454796 [    0/ 5994]\n",
      "loss: 0.779185 [ 1600/ 5994]\n",
      "loss: 0.708793 [ 3200/ 5994]\n",
      "loss: 0.767296 [ 4800/ 5994]\n",
      "Training Loss: 0.5977, Training Accuracy: 82.8328%\n",
      "Test Loss: 1.5384, Test Accuracy: 59.0611%\n",
      "Epoch 417/500-------------------\n",
      "loss: 0.366709 [    0/ 5994]\n",
      "loss: 0.276436 [ 1600/ 5994]\n",
      "loss: 0.464140 [ 3200/ 5994]\n",
      "loss: 0.433452 [ 4800/ 5994]\n",
      "Training Loss: 0.5957, Training Accuracy: 82.8829%\n",
      "Test Loss: 1.5347, Test Accuracy: 59.0611%\n",
      "Epoch 418/500-------------------\n",
      "loss: 0.455455 [    0/ 5994]\n",
      "loss: 0.570417 [ 1600/ 5994]\n",
      "loss: 0.506738 [ 3200/ 5994]\n",
      "loss: 0.725353 [ 4800/ 5994]\n",
      "Training Loss: 0.5958, Training Accuracy: 83.3333%\n",
      "Test Loss: 1.5393, Test Accuracy: 58.8885%\n",
      "Epoch 419/500-------------------\n",
      "loss: 0.696585 [    0/ 5994]\n",
      "loss: 0.535276 [ 1600/ 5994]\n",
      "loss: 0.813670 [ 3200/ 5994]\n",
      "loss: 0.494711 [ 4800/ 5994]\n",
      "Training Loss: 0.5979, Training Accuracy: 83.2332%\n",
      "Test Loss: 1.5366, Test Accuracy: 59.0266%\n",
      "Epoch 420/500-------------------\n",
      "loss: 0.372674 [    0/ 5994]\n",
      "loss: 0.496867 [ 1600/ 5994]\n",
      "loss: 1.163111 [ 3200/ 5994]\n",
      "loss: 0.409688 [ 4800/ 5994]\n",
      "Training Loss: 0.6053, Training Accuracy: 82.3323%\n",
      "Test Loss: 1.5500, Test Accuracy: 58.6814%\n",
      "Epoch 421/500-------------------\n",
      "loss: 0.868279 [    0/ 5994]\n",
      "loss: 0.834803 [ 1600/ 5994]\n",
      "loss: 0.444256 [ 3200/ 5994]\n",
      "loss: 0.140408 [ 4800/ 5994]\n",
      "Training Loss: 0.5977, Training Accuracy: 82.8495%\n",
      "Test Loss: 1.5426, Test Accuracy: 59.3372%\n",
      "Epoch 422/500-------------------\n",
      "loss: 0.566603 [    0/ 5994]\n",
      "loss: 0.435714 [ 1600/ 5994]\n",
      "loss: 0.545668 [ 3200/ 5994]\n",
      "loss: 0.454573 [ 4800/ 5994]\n",
      "Training Loss: 0.5989, Training Accuracy: 83.0330%\n",
      "Test Loss: 1.5410, Test Accuracy: 59.2337%\n",
      "Epoch 423/500-------------------\n",
      "loss: 1.113808 [    0/ 5994]\n",
      "loss: 0.627321 [ 1600/ 5994]\n",
      "loss: 0.749671 [ 3200/ 5994]\n",
      "loss: 0.389833 [ 4800/ 5994]\n",
      "Training Loss: 0.5946, Training Accuracy: 82.7828%\n",
      "Test Loss: 1.5350, Test Accuracy: 59.0956%\n",
      "Epoch 424/500-------------------\n",
      "loss: 0.326313 [    0/ 5994]\n",
      "loss: 0.950966 [ 1600/ 5994]\n",
      "loss: 0.779650 [ 3200/ 5994]\n",
      "loss: 1.194731 [ 4800/ 5994]\n",
      "Training Loss: 0.5900, Training Accuracy: 83.2332%\n",
      "Test Loss: 1.5301, Test Accuracy: 59.9586%\n",
      "Saving model to sequential_attributes_to_class.pth with accuracy 59.9586%\n",
      "Epoch 425/500-------------------\n",
      "loss: 0.333059 [    0/ 5994]\n",
      "loss: 0.199226 [ 1600/ 5994]\n",
      "loss: 0.663053 [ 3200/ 5994]\n",
      "loss: 0.892630 [ 4800/ 5994]\n",
      "Training Loss: 0.5946, Training Accuracy: 82.9830%\n",
      "Test Loss: 1.5413, Test Accuracy: 58.9921%\n",
      "Epoch 426/500-------------------\n",
      "loss: 0.665626 [    0/ 5994]\n",
      "loss: 0.636074 [ 1600/ 5994]\n",
      "loss: 0.775498 [ 3200/ 5994]\n",
      "loss: 0.595025 [ 4800/ 5994]\n",
      "Training Loss: 0.5892, Training Accuracy: 83.4668%\n",
      "Test Loss: 1.5327, Test Accuracy: 59.1129%\n",
      "Epoch 427/500-------------------\n",
      "loss: 0.767697 [    0/ 5994]\n",
      "loss: 0.613887 [ 1600/ 5994]\n",
      "loss: 0.556210 [ 3200/ 5994]\n",
      "loss: 0.946130 [ 4800/ 5994]\n",
      "Training Loss: 0.5927, Training Accuracy: 82.9329%\n",
      "Test Loss: 1.5397, Test Accuracy: 58.8540%\n",
      "Epoch 428/500-------------------\n",
      "loss: 0.494086 [    0/ 5994]\n",
      "loss: 0.915149 [ 1600/ 5994]\n",
      "loss: 0.677736 [ 3200/ 5994]\n",
      "loss: 0.882469 [ 4800/ 5994]\n",
      "Training Loss: 0.5971, Training Accuracy: 82.6994%\n",
      "Test Loss: 1.5410, Test Accuracy: 58.7332%\n",
      "Epoch 429/500-------------------\n",
      "loss: 0.858123 [    0/ 5994]\n",
      "loss: 0.660859 [ 1600/ 5994]\n",
      "loss: 0.577547 [ 3200/ 5994]\n",
      "loss: 0.687082 [ 4800/ 5994]\n",
      "Training Loss: 0.5928, Training Accuracy: 83.2499%\n",
      "Test Loss: 1.5395, Test Accuracy: 59.4063%\n",
      "Epoch 430/500-------------------\n",
      "loss: 0.390275 [    0/ 5994]\n",
      "loss: 0.367534 [ 1600/ 5994]\n",
      "loss: 0.675047 [ 3200/ 5994]\n",
      "loss: 0.511103 [ 4800/ 5994]\n",
      "Training Loss: 0.5981, Training Accuracy: 82.7661%\n",
      "Test Loss: 1.5462, Test Accuracy: 58.9748%\n",
      "Epoch 431/500-------------------\n",
      "loss: 0.576583 [    0/ 5994]\n",
      "loss: 0.722554 [ 1600/ 5994]\n",
      "loss: 0.595007 [ 3200/ 5994]\n",
      "loss: 0.665001 [ 4800/ 5994]\n",
      "Training Loss: 0.5908, Training Accuracy: 83.6503%\n",
      "Test Loss: 1.5427, Test Accuracy: 59.1819%\n",
      "Epoch 432/500-------------------\n",
      "loss: 0.685303 [    0/ 5994]\n",
      "loss: 0.598509 [ 1600/ 5994]\n",
      "loss: 0.766080 [ 3200/ 5994]\n",
      "loss: 0.571991 [ 4800/ 5994]\n",
      "Training Loss: 0.5871, Training Accuracy: 83.5169%\n",
      "Test Loss: 1.5405, Test Accuracy: 59.1647%\n",
      "Epoch 433/500-------------------\n",
      "loss: 0.652212 [    0/ 5994]\n",
      "loss: 0.808806 [ 1600/ 5994]\n",
      "loss: 0.503181 [ 3200/ 5994]\n",
      "loss: 0.589153 [ 4800/ 5994]\n",
      "Training Loss: 0.5909, Training Accuracy: 83.3500%\n",
      "Test Loss: 1.5395, Test Accuracy: 58.7504%\n",
      "Epoch 434/500-------------------\n",
      "loss: 0.549782 [    0/ 5994]\n",
      "loss: 0.526076 [ 1600/ 5994]\n",
      "loss: 0.591239 [ 3200/ 5994]\n",
      "loss: 0.681418 [ 4800/ 5994]\n",
      "Training Loss: 0.5893, Training Accuracy: 83.6503%\n",
      "Test Loss: 1.5407, Test Accuracy: 59.1301%\n",
      "Epoch 435/500-------------------\n",
      "loss: 1.017920 [    0/ 5994]\n",
      "loss: 0.857761 [ 1600/ 5994]\n",
      "loss: 0.626211 [ 3200/ 5994]\n",
      "loss: 0.279193 [ 4800/ 5994]\n",
      "Training Loss: 0.5858, Training Accuracy: 83.4501%\n",
      "Test Loss: 1.5421, Test Accuracy: 59.2855%\n",
      "Epoch 436/500-------------------\n",
      "loss: 0.606678 [    0/ 5994]\n",
      "loss: 0.426219 [ 1600/ 5994]\n",
      "loss: 0.708224 [ 3200/ 5994]\n",
      "loss: 0.649083 [ 4800/ 5994]\n",
      "Training Loss: 0.5905, Training Accuracy: 83.1331%\n",
      "Test Loss: 1.5456, Test Accuracy: 58.9403%\n",
      "Epoch 437/500-------------------\n",
      "loss: 0.715259 [    0/ 5994]\n",
      "loss: 0.624340 [ 1600/ 5994]\n",
      "loss: 0.645170 [ 3200/ 5994]\n",
      "loss: 0.717699 [ 4800/ 5994]\n",
      "Training Loss: 0.5850, Training Accuracy: 83.4668%\n",
      "Test Loss: 1.5375, Test Accuracy: 59.1992%\n",
      "Epoch 438/500-------------------\n",
      "loss: 0.719464 [    0/ 5994]\n",
      "loss: 0.874844 [ 1600/ 5994]\n",
      "loss: 0.606919 [ 3200/ 5994]\n",
      "loss: 0.454096 [ 4800/ 5994]\n",
      "Training Loss: 0.5841, Training Accuracy: 83.5169%\n",
      "Test Loss: 1.5415, Test Accuracy: 59.1647%\n",
      "Epoch 439/500-------------------\n",
      "loss: 0.574236 [    0/ 5994]\n",
      "loss: 0.544260 [ 1600/ 5994]\n",
      "loss: 0.653914 [ 3200/ 5994]\n",
      "loss: 0.377139 [ 4800/ 5994]\n",
      "Training Loss: 0.5920, Training Accuracy: 83.1999%\n",
      "Test Loss: 1.5478, Test Accuracy: 58.5951%\n",
      "Epoch 440/500-------------------\n",
      "loss: 0.314706 [    0/ 5994]\n",
      "loss: 0.669338 [ 1600/ 5994]\n",
      "loss: 0.701295 [ 3200/ 5994]\n",
      "loss: 0.620009 [ 4800/ 5994]\n",
      "Training Loss: 0.5831, Training Accuracy: 83.7004%\n",
      "Test Loss: 1.5408, Test Accuracy: 59.1819%\n",
      "Epoch 441/500-------------------\n",
      "loss: 0.975220 [    0/ 5994]\n",
      "loss: 0.751233 [ 1600/ 5994]\n",
      "loss: 0.676605 [ 3200/ 5994]\n",
      "loss: 0.547492 [ 4800/ 5994]\n",
      "Training Loss: 0.5870, Training Accuracy: 83.5169%\n",
      "Test Loss: 1.5402, Test Accuracy: 59.1474%\n",
      "Epoch 442/500-------------------\n",
      "loss: 0.492949 [    0/ 5994]\n",
      "loss: 0.747569 [ 1600/ 5994]\n",
      "loss: 0.388285 [ 3200/ 5994]\n",
      "loss: 0.768369 [ 4800/ 5994]\n",
      "Training Loss: 0.5847, Training Accuracy: 83.3166%\n",
      "Test Loss: 1.5478, Test Accuracy: 58.9921%\n",
      "Epoch 443/500-------------------\n",
      "loss: 0.775091 [    0/ 5994]\n",
      "loss: 0.877357 [ 1600/ 5994]\n",
      "loss: 0.576344 [ 3200/ 5994]\n",
      "loss: 0.719633 [ 4800/ 5994]\n",
      "Training Loss: 0.5813, Training Accuracy: 83.8172%\n",
      "Test Loss: 1.5431, Test Accuracy: 59.1647%\n",
      "Epoch 444/500-------------------\n",
      "loss: 0.968981 [    0/ 5994]\n",
      "loss: 0.704840 [ 1600/ 5994]\n",
      "loss: 0.681994 [ 3200/ 5994]\n",
      "loss: 0.568399 [ 4800/ 5994]\n",
      "Training Loss: 0.5878, Training Accuracy: 83.4501%\n",
      "Test Loss: 1.5478, Test Accuracy: 58.9230%\n",
      "Epoch 445/500-------------------\n",
      "loss: 0.596422 [    0/ 5994]\n",
      "loss: 0.499967 [ 1600/ 5994]\n",
      "loss: 0.628326 [ 3200/ 5994]\n",
      "loss: 0.378095 [ 4800/ 5994]\n",
      "Training Loss: 0.5868, Training Accuracy: 83.3500%\n",
      "Test Loss: 1.5512, Test Accuracy: 59.1819%\n",
      "Epoch 446/500-------------------\n",
      "loss: 0.591318 [    0/ 5994]\n",
      "loss: 0.657604 [ 1600/ 5994]\n",
      "loss: 0.627817 [ 3200/ 5994]\n",
      "loss: 0.538128 [ 4800/ 5994]\n",
      "Training Loss: 0.5881, Training Accuracy: 83.5335%\n",
      "Test Loss: 1.5424, Test Accuracy: 59.2164%\n",
      "Epoch 447/500-------------------\n",
      "loss: 0.703212 [    0/ 5994]\n",
      "loss: 0.625385 [ 1600/ 5994]\n",
      "loss: 0.535207 [ 3200/ 5994]\n",
      "loss: 0.770525 [ 4800/ 5994]\n",
      "Training Loss: 0.5908, Training Accuracy: 83.1331%\n",
      "Test Loss: 1.5574, Test Accuracy: 59.2509%\n",
      "Epoch 448/500-------------------\n",
      "loss: 0.788619 [    0/ 5994]\n",
      "loss: 0.683159 [ 1600/ 5994]\n",
      "loss: 0.386767 [ 3200/ 5994]\n",
      "loss: 0.975424 [ 4800/ 5994]\n",
      "Training Loss: 0.5840, Training Accuracy: 83.2833%\n",
      "Test Loss: 1.5509, Test Accuracy: 58.9921%\n",
      "Epoch 449/500-------------------\n",
      "loss: 0.438644 [    0/ 5994]\n",
      "loss: 0.810289 [ 1600/ 5994]\n",
      "loss: 0.818804 [ 3200/ 5994]\n",
      "loss: 1.078100 [ 4800/ 5994]\n",
      "Training Loss: 0.5872, Training Accuracy: 83.3667%\n",
      "Test Loss: 1.5584, Test Accuracy: 58.9403%\n",
      "Epoch 450/500-------------------\n",
      "loss: 0.457136 [    0/ 5994]\n",
      "loss: 0.583552 [ 1600/ 5994]\n",
      "loss: 0.412885 [ 3200/ 5994]\n",
      "loss: 0.919967 [ 4800/ 5994]\n",
      "Training Loss: 0.5827, Training Accuracy: 83.3333%\n",
      "Test Loss: 1.5457, Test Accuracy: 59.4581%\n",
      "Epoch 451/500-------------------\n",
      "loss: 0.464415 [    0/ 5994]\n",
      "loss: 0.715221 [ 1600/ 5994]\n",
      "loss: 0.794567 [ 3200/ 5994]\n",
      "loss: 0.423924 [ 4800/ 5994]\n",
      "Training Loss: 0.5828, Training Accuracy: 83.4835%\n",
      "Test Loss: 1.5466, Test Accuracy: 58.6987%\n",
      "Epoch 452/500-------------------\n",
      "loss: 0.573493 [    0/ 5994]\n",
      "loss: 0.720583 [ 1600/ 5994]\n",
      "loss: 0.538101 [ 3200/ 5994]\n",
      "loss: 0.390743 [ 4800/ 5994]\n",
      "Training Loss: 0.5800, Training Accuracy: 83.9339%\n",
      "Test Loss: 1.5494, Test Accuracy: 59.1129%\n",
      "Epoch 453/500-------------------\n",
      "loss: 0.629654 [    0/ 5994]\n",
      "loss: 0.689559 [ 1600/ 5994]\n",
      "loss: 0.555915 [ 3200/ 5994]\n",
      "loss: 0.278907 [ 4800/ 5994]\n",
      "Training Loss: 0.5773, Training Accuracy: 83.5502%\n",
      "Test Loss: 1.5441, Test Accuracy: 59.3027%\n",
      "Epoch 454/500-------------------\n",
      "loss: 0.779915 [    0/ 5994]\n",
      "loss: 0.964986 [ 1600/ 5994]\n",
      "loss: 0.641972 [ 3200/ 5994]\n",
      "loss: 1.096280 [ 4800/ 5994]\n",
      "Training Loss: 0.5790, Training Accuracy: 84.0174%\n",
      "Test Loss: 1.5486, Test Accuracy: 59.2682%\n",
      "Epoch 455/500-------------------\n",
      "loss: 0.620511 [    0/ 5994]\n",
      "loss: 0.447101 [ 1600/ 5994]\n",
      "loss: 0.557484 [ 3200/ 5994]\n",
      "loss: 0.646301 [ 4800/ 5994]\n",
      "Training Loss: 0.5818, Training Accuracy: 83.4668%\n",
      "Test Loss: 1.5473, Test Accuracy: 59.1647%\n",
      "Epoch 456/500-------------------\n",
      "loss: 0.309556 [    0/ 5994]\n",
      "loss: 0.597056 [ 1600/ 5994]\n",
      "loss: 0.814648 [ 3200/ 5994]\n",
      "loss: 0.801884 [ 4800/ 5994]\n",
      "Training Loss: 0.5799, Training Accuracy: 83.2332%\n",
      "Test Loss: 1.5506, Test Accuracy: 58.8885%\n",
      "Epoch 457/500-------------------\n",
      "loss: 0.691947 [    0/ 5994]\n",
      "loss: 0.595143 [ 1600/ 5994]\n",
      "loss: 0.144033 [ 3200/ 5994]\n",
      "loss: 0.653844 [ 4800/ 5994]\n",
      "Training Loss: 0.5799, Training Accuracy: 83.6670%\n",
      "Test Loss: 1.5500, Test Accuracy: 59.0611%\n",
      "Epoch 458/500-------------------\n",
      "loss: 0.644620 [    0/ 5994]\n",
      "loss: 0.310652 [ 1600/ 5994]\n",
      "loss: 0.457841 [ 3200/ 5994]\n",
      "loss: 0.506130 [ 4800/ 5994]\n",
      "Training Loss: 0.5777, Training Accuracy: 84.1175%\n",
      "Test Loss: 1.5488, Test Accuracy: 59.3372%\n",
      "Epoch 459/500-------------------\n",
      "loss: 0.301752 [    0/ 5994]\n",
      "loss: 0.509692 [ 1600/ 5994]\n",
      "loss: 0.639717 [ 3200/ 5994]\n",
      "loss: 0.734968 [ 4800/ 5994]\n",
      "Training Loss: 0.5804, Training Accuracy: 83.5836%\n",
      "Test Loss: 1.5522, Test Accuracy: 58.9575%\n",
      "Epoch 460/500-------------------\n",
      "loss: 0.512982 [    0/ 5994]\n",
      "loss: 0.529552 [ 1600/ 5994]\n",
      "loss: 0.791263 [ 3200/ 5994]\n",
      "loss: 0.843214 [ 4800/ 5994]\n",
      "Training Loss: 0.5750, Training Accuracy: 83.5002%\n",
      "Test Loss: 1.5462, Test Accuracy: 59.0438%\n",
      "Epoch 461/500-------------------\n",
      "loss: 0.410430 [    0/ 5994]\n",
      "loss: 0.436797 [ 1600/ 5994]\n",
      "loss: 0.584928 [ 3200/ 5994]\n",
      "loss: 0.493441 [ 4800/ 5994]\n",
      "Training Loss: 0.5678, Training Accuracy: 84.2009%\n",
      "Test Loss: 1.5418, Test Accuracy: 59.3890%\n",
      "Epoch 462/500-------------------\n",
      "loss: 0.497007 [    0/ 5994]\n",
      "loss: 0.542261 [ 1600/ 5994]\n",
      "loss: 0.857868 [ 3200/ 5994]\n",
      "loss: 0.517288 [ 4800/ 5994]\n",
      "Training Loss: 0.5761, Training Accuracy: 83.4668%\n",
      "Test Loss: 1.5423, Test Accuracy: 59.0956%\n",
      "Epoch 463/500-------------------\n",
      "loss: 0.677623 [    0/ 5994]\n",
      "loss: 0.737411 [ 1600/ 5994]\n",
      "loss: 0.417405 [ 3200/ 5994]\n",
      "loss: 0.817970 [ 4800/ 5994]\n",
      "Training Loss: 0.5700, Training Accuracy: 84.2342%\n",
      "Test Loss: 1.5392, Test Accuracy: 59.3372%\n",
      "Epoch 464/500-------------------\n",
      "loss: 0.584307 [    0/ 5994]\n",
      "loss: 0.485487 [ 1600/ 5994]\n",
      "loss: 0.508150 [ 3200/ 5994]\n",
      "loss: 0.527345 [ 4800/ 5994]\n",
      "Training Loss: 0.5743, Training Accuracy: 84.0340%\n",
      "Test Loss: 1.5437, Test Accuracy: 59.9586%\n",
      "Epoch 465/500-------------------\n",
      "loss: 0.568174 [    0/ 5994]\n",
      "loss: 0.409615 [ 1600/ 5994]\n",
      "loss: 0.448998 [ 3200/ 5994]\n",
      "loss: 0.283264 [ 4800/ 5994]\n",
      "Training Loss: 0.5711, Training Accuracy: 83.7337%\n",
      "Test Loss: 1.5458, Test Accuracy: 59.1992%\n",
      "Epoch 466/500-------------------\n",
      "loss: 0.310078 [    0/ 5994]\n",
      "loss: 0.209954 [ 1600/ 5994]\n",
      "loss: 0.979401 [ 3200/ 5994]\n",
      "loss: 0.838928 [ 4800/ 5994]\n",
      "Training Loss: 0.5737, Training Accuracy: 83.3500%\n",
      "Test Loss: 1.5489, Test Accuracy: 58.5606%\n",
      "Epoch 467/500-------------------\n",
      "loss: 1.274052 [    0/ 5994]\n",
      "loss: 1.370499 [ 1600/ 5994]\n",
      "loss: 0.670788 [ 3200/ 5994]\n",
      "loss: 0.643386 [ 4800/ 5994]\n",
      "Training Loss: 0.5711, Training Accuracy: 84.1341%\n",
      "Test Loss: 1.5452, Test Accuracy: 59.6652%\n",
      "Epoch 468/500-------------------\n",
      "loss: 0.310415 [    0/ 5994]\n",
      "loss: 0.422743 [ 1600/ 5994]\n",
      "loss: 0.702678 [ 3200/ 5994]\n",
      "loss: 0.610237 [ 4800/ 5994]\n",
      "Training Loss: 0.5712, Training Accuracy: 84.0174%\n",
      "Test Loss: 1.5454, Test Accuracy: 59.6479%\n",
      "Epoch 469/500-------------------\n",
      "loss: 0.502853 [    0/ 5994]\n",
      "loss: 0.595909 [ 1600/ 5994]\n",
      "loss: 0.548427 [ 3200/ 5994]\n",
      "loss: 0.593363 [ 4800/ 5994]\n",
      "Training Loss: 0.5755, Training Accuracy: 83.4668%\n",
      "Test Loss: 1.5502, Test Accuracy: 59.2509%\n",
      "Epoch 470/500-------------------\n",
      "loss: 0.467305 [    0/ 5994]\n",
      "loss: 0.679001 [ 1600/ 5994]\n",
      "loss: 0.653286 [ 3200/ 5994]\n",
      "loss: 0.690124 [ 4800/ 5994]\n",
      "Training Loss: 0.5703, Training Accuracy: 83.8672%\n",
      "Test Loss: 1.5485, Test Accuracy: 58.8367%\n",
      "Epoch 471/500-------------------\n",
      "loss: 0.489784 [    0/ 5994]\n",
      "loss: 0.841448 [ 1600/ 5994]\n",
      "loss: 0.279507 [ 3200/ 5994]\n",
      "loss: 0.665991 [ 4800/ 5994]\n",
      "Training Loss: 0.5752, Training Accuracy: 83.7337%\n",
      "Test Loss: 1.5554, Test Accuracy: 58.9403%\n",
      "Epoch 472/500-------------------\n",
      "loss: 0.725202 [    0/ 5994]\n",
      "loss: 0.717485 [ 1600/ 5994]\n",
      "loss: 0.877843 [ 3200/ 5994]\n",
      "loss: 0.805255 [ 4800/ 5994]\n",
      "Training Loss: 0.5750, Training Accuracy: 83.3166%\n",
      "Test Loss: 1.5592, Test Accuracy: 58.9403%\n",
      "Epoch 473/500-------------------\n",
      "loss: 0.377168 [    0/ 5994]\n",
      "loss: 0.628171 [ 1600/ 5994]\n",
      "loss: 0.802199 [ 3200/ 5994]\n",
      "loss: 0.250722 [ 4800/ 5994]\n",
      "Training Loss: 0.5681, Training Accuracy: 84.0841%\n",
      "Test Loss: 1.5540, Test Accuracy: 58.9748%\n",
      "Epoch 474/500-------------------\n",
      "loss: 0.437775 [    0/ 5994]\n",
      "loss: 0.253173 [ 1600/ 5994]\n",
      "loss: 0.631329 [ 3200/ 5994]\n",
      "loss: 0.449198 [ 4800/ 5994]\n",
      "Training Loss: 0.5722, Training Accuracy: 83.5335%\n",
      "Test Loss: 1.5538, Test Accuracy: 59.2509%\n",
      "Epoch 475/500-------------------\n",
      "loss: 0.916416 [    0/ 5994]\n",
      "loss: 0.350267 [ 1600/ 5994]\n",
      "loss: 0.468359 [ 3200/ 5994]\n",
      "loss: 1.117791 [ 4800/ 5994]\n",
      "Training Loss: 0.5739, Training Accuracy: 83.5669%\n",
      "Test Loss: 1.5594, Test Accuracy: 58.6296%\n",
      "Epoch 476/500-------------------\n",
      "loss: 0.696568 [    0/ 5994]\n",
      "loss: 0.850566 [ 1600/ 5994]\n",
      "loss: 0.420752 [ 3200/ 5994]\n",
      "loss: 0.560207 [ 4800/ 5994]\n",
      "Training Loss: 0.5714, Training Accuracy: 83.8172%\n",
      "Test Loss: 1.5582, Test Accuracy: 58.7332%\n",
      "Epoch 477/500-------------------\n",
      "loss: 0.484643 [    0/ 5994]\n",
      "loss: 0.579648 [ 1600/ 5994]\n",
      "loss: 0.767560 [ 3200/ 5994]\n",
      "loss: 0.495927 [ 4800/ 5994]\n",
      "Training Loss: 0.5682, Training Accuracy: 84.1008%\n",
      "Test Loss: 1.5469, Test Accuracy: 58.9575%\n",
      "Epoch 478/500-------------------\n",
      "loss: 0.602531 [    0/ 5994]\n",
      "loss: 0.785924 [ 1600/ 5994]\n",
      "loss: 0.530936 [ 3200/ 5994]\n",
      "loss: 0.803185 [ 4800/ 5994]\n",
      "Training Loss: 0.5717, Training Accuracy: 83.3000%\n",
      "Test Loss: 1.5605, Test Accuracy: 58.7849%\n",
      "Epoch 479/500-------------------\n",
      "loss: 0.660410 [    0/ 5994]\n",
      "loss: 0.677546 [ 1600/ 5994]\n",
      "loss: 0.391575 [ 3200/ 5994]\n",
      "loss: 0.696382 [ 4800/ 5994]\n",
      "Training Loss: 0.5706, Training Accuracy: 83.7671%\n",
      "Test Loss: 1.5548, Test Accuracy: 59.3027%\n",
      "Epoch 480/500-------------------\n",
      "loss: 0.466277 [    0/ 5994]\n",
      "loss: 0.517392 [ 1600/ 5994]\n",
      "loss: 0.927130 [ 3200/ 5994]\n",
      "loss: 0.738455 [ 4800/ 5994]\n",
      "Training Loss: 0.5675, Training Accuracy: 84.0507%\n",
      "Test Loss: 1.5508, Test Accuracy: 59.7342%\n",
      "Epoch 481/500-------------------\n",
      "loss: 0.546448 [    0/ 5994]\n",
      "loss: 0.579870 [ 1600/ 5994]\n",
      "loss: 0.532495 [ 3200/ 5994]\n",
      "loss: 0.944600 [ 4800/ 5994]\n",
      "Training Loss: 0.5697, Training Accuracy: 83.5169%\n",
      "Test Loss: 1.5568, Test Accuracy: 59.0611%\n",
      "Epoch 482/500-------------------\n",
      "loss: 0.269013 [    0/ 5994]\n",
      "loss: 0.665539 [ 1600/ 5994]\n",
      "loss: 0.948618 [ 3200/ 5994]\n",
      "loss: 1.014818 [ 4800/ 5994]\n",
      "Training Loss: 0.5650, Training Accuracy: 83.8338%\n",
      "Test Loss: 1.5498, Test Accuracy: 59.7515%\n",
      "Epoch 483/500-------------------\n",
      "loss: 0.384882 [    0/ 5994]\n",
      "loss: 0.617505 [ 1600/ 5994]\n",
      "loss: 0.767365 [ 3200/ 5994]\n",
      "loss: 0.543666 [ 4800/ 5994]\n",
      "Training Loss: 0.5629, Training Accuracy: 84.6680%\n",
      "Test Loss: 1.5505, Test Accuracy: 59.3372%\n",
      "Epoch 484/500-------------------\n",
      "loss: 0.612230 [    0/ 5994]\n",
      "loss: 0.503484 [ 1600/ 5994]\n",
      "loss: 0.636506 [ 3200/ 5994]\n",
      "loss: 0.675804 [ 4800/ 5994]\n",
      "Training Loss: 0.5621, Training Accuracy: 84.3343%\n",
      "Test Loss: 1.5485, Test Accuracy: 59.2337%\n",
      "Epoch 485/500-------------------\n",
      "loss: 0.919693 [    0/ 5994]\n",
      "loss: 0.587751 [ 1600/ 5994]\n",
      "loss: 0.458541 [ 3200/ 5994]\n",
      "loss: 0.329544 [ 4800/ 5994]\n",
      "Training Loss: 0.5652, Training Accuracy: 84.1008%\n",
      "Test Loss: 1.5541, Test Accuracy: 59.0093%\n",
      "Epoch 486/500-------------------\n",
      "loss: 0.677836 [    0/ 5994]\n",
      "loss: 0.362809 [ 1600/ 5994]\n",
      "loss: 0.649049 [ 3200/ 5994]\n",
      "loss: 0.447940 [ 4800/ 5994]\n",
      "Training Loss: 0.5672, Training Accuracy: 83.5836%\n",
      "Test Loss: 1.5602, Test Accuracy: 59.3200%\n",
      "Epoch 487/500-------------------\n",
      "loss: 0.331925 [    0/ 5994]\n",
      "loss: 0.456131 [ 1600/ 5994]\n",
      "loss: 0.456674 [ 3200/ 5994]\n",
      "loss: 1.018260 [ 4800/ 5994]\n",
      "Training Loss: 0.5639, Training Accuracy: 83.9673%\n",
      "Test Loss: 1.5504, Test Accuracy: 59.3545%\n",
      "Epoch 488/500-------------------\n",
      "loss: 0.292605 [    0/ 5994]\n",
      "loss: 0.853089 [ 1600/ 5994]\n",
      "loss: 0.490177 [ 3200/ 5994]\n",
      "loss: 0.768220 [ 4800/ 5994]\n",
      "Training Loss: 0.5643, Training Accuracy: 84.1341%\n",
      "Test Loss: 1.5552, Test Accuracy: 59.1129%\n",
      "Epoch 489/500-------------------\n",
      "loss: 0.522312 [    0/ 5994]\n",
      "loss: 0.699585 [ 1600/ 5994]\n",
      "loss: 0.320507 [ 3200/ 5994]\n",
      "loss: 0.677570 [ 4800/ 5994]\n",
      "Training Loss: 0.5615, Training Accuracy: 84.1175%\n",
      "Test Loss: 1.5543, Test Accuracy: 59.2509%\n",
      "Epoch 490/500-------------------\n",
      "loss: 0.259219 [    0/ 5994]\n",
      "loss: 0.483867 [ 1600/ 5994]\n",
      "loss: 0.588616 [ 3200/ 5994]\n",
      "loss: 0.717569 [ 4800/ 5994]\n",
      "Training Loss: 0.5639, Training Accuracy: 84.0674%\n",
      "Test Loss: 1.5597, Test Accuracy: 59.2337%\n",
      "Epoch 491/500-------------------\n",
      "loss: 0.366598 [    0/ 5994]\n",
      "loss: 0.609367 [ 1600/ 5994]\n",
      "loss: 0.675063 [ 3200/ 5994]\n",
      "loss: 0.376036 [ 4800/ 5994]\n",
      "Training Loss: 0.5598, Training Accuracy: 83.7337%\n",
      "Test Loss: 1.5521, Test Accuracy: 59.5616%\n",
      "Epoch 492/500-------------------\n",
      "loss: 0.298432 [    0/ 5994]\n",
      "loss: 0.262897 [ 1600/ 5994]\n",
      "loss: 0.299768 [ 3200/ 5994]\n",
      "loss: 0.579538 [ 4800/ 5994]\n",
      "Training Loss: 0.5572, Training Accuracy: 84.3844%\n",
      "Test Loss: 1.5492, Test Accuracy: 59.2164%\n",
      "Epoch 493/500-------------------\n",
      "loss: 0.479977 [    0/ 5994]\n",
      "loss: 0.758326 [ 1600/ 5994]\n",
      "loss: 0.577991 [ 3200/ 5994]\n",
      "loss: 0.671239 [ 4800/ 5994]\n",
      "Training Loss: 0.5622, Training Accuracy: 84.3510%\n",
      "Test Loss: 1.5550, Test Accuracy: 59.6307%\n",
      "Epoch 494/500-------------------\n",
      "loss: 0.465081 [    0/ 5994]\n",
      "loss: 0.631173 [ 1600/ 5994]\n",
      "loss: 0.445405 [ 3200/ 5994]\n",
      "loss: 1.027299 [ 4800/ 5994]\n",
      "Training Loss: 0.5627, Training Accuracy: 84.2009%\n",
      "Test Loss: 1.5564, Test Accuracy: 59.4235%\n",
      "Epoch 495/500-------------------\n",
      "loss: 0.461509 [    0/ 5994]\n",
      "loss: 0.830991 [ 1600/ 5994]\n",
      "loss: 0.718480 [ 3200/ 5994]\n",
      "loss: 1.005838 [ 4800/ 5994]\n",
      "Training Loss: 0.5581, Training Accuracy: 84.2176%\n",
      "Test Loss: 1.5511, Test Accuracy: 59.0784%\n",
      "Epoch 496/500-------------------\n",
      "loss: 0.434637 [    0/ 5994]\n",
      "loss: 0.824155 [ 1600/ 5994]\n",
      "loss: 0.434528 [ 3200/ 5994]\n",
      "loss: 0.598783 [ 4800/ 5994]\n",
      "Training Loss: 0.5595, Training Accuracy: 84.0841%\n",
      "Test Loss: 1.5538, Test Accuracy: 59.5789%\n",
      "Epoch 497/500-------------------\n",
      "loss: 0.993988 [    0/ 5994]\n",
      "loss: 0.618003 [ 1600/ 5994]\n",
      "loss: 0.719993 [ 3200/ 5994]\n",
      "loss: 0.607314 [ 4800/ 5994]\n",
      "Training Loss: 0.5610, Training Accuracy: 84.0174%\n",
      "Test Loss: 1.5558, Test Accuracy: 59.2164%\n",
      "Epoch 498/500-------------------\n",
      "loss: 0.746794 [    0/ 5994]\n",
      "loss: 0.526007 [ 1600/ 5994]\n",
      "loss: 0.777901 [ 3200/ 5994]\n",
      "loss: 0.519920 [ 4800/ 5994]\n",
      "Training Loss: 0.5574, Training Accuracy: 84.3677%\n",
      "Test Loss: 1.5550, Test Accuracy: 59.5271%\n",
      "Epoch 499/500-------------------\n",
      "loss: 0.512353 [    0/ 5994]\n",
      "loss: 0.692139 [ 1600/ 5994]\n",
      "loss: 0.563720 [ 3200/ 5994]\n",
      "loss: 0.683567 [ 4800/ 5994]\n",
      "Training Loss: 0.5600, Training Accuracy: 84.0674%\n",
      "Test Loss: 1.5498, Test Accuracy: 59.1474%\n",
      "Epoch 500/500-------------------\n",
      "loss: 0.473217 [    0/ 5994]\n",
      "loss: 0.604274 [ 1600/ 5994]\n",
      "loss: 0.529244 [ 3200/ 5994]\n",
      "loss: 0.287941 [ 4800/ 5994]\n",
      "Training Loss: 0.5596, Training Accuracy: 84.5012%\n",
      "Test Loss: 1.5628, Test Accuracy: 58.9230%\n",
      "Best Test Accuracy: 59.9586%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-0.3324, -2.8829,  0.4667,  ..., -1.2041, -0.8012, -1.7086],\n",
       "                      [-0.3720, -1.6699, -0.2044,  ...,  0.4357, -0.3627, -2.8148],\n",
       "                      [-0.5330, -2.3994, -0.4541,  ..., -1.2451, -0.5242, -1.8711],\n",
       "                      ...,\n",
       "                      [-0.1129,  3.2309, -0.0998,  ...,  2.2661,  2.1056, -4.3045],\n",
       "                      [ 1.1753,  0.6442,  0.1710,  ...,  3.1050,  1.2644, -2.9183],\n",
       "                      [-0.1710,  0.3591, -0.1896,  ..., -0.2040, -2.5275,  2.2067]],\n",
       "                     device='cuda:0')),\n",
       "             ('0.bias',\n",
       "              tensor([-1.2289e-02,  1.3305e+00, -2.5209e+00,  1.4965e+00,  1.5482e+00,\n",
       "                       1.7857e+00,  3.9253e-01,  1.5506e+00,  3.3860e+00, -2.5045e-02,\n",
       "                       1.0220e+00,  5.2778e-01,  6.9424e-01,  7.0044e-01, -8.3225e-01,\n",
       "                       8.3236e-01,  6.7667e-01,  2.8322e+00, -2.1689e+00, -2.3142e+00,\n",
       "                      -1.1426e+00,  4.2774e+00,  1.0714e+00,  2.5567e+00,  3.2644e+00,\n",
       "                      -2.3133e+00, -1.0072e+00, -2.4596e-01, -3.8423e+00, -3.5222e-01,\n",
       "                       2.1688e+00,  1.3816e+00, -5.5807e-02,  2.0985e-01, -2.0475e+00,\n",
       "                       8.0377e-01, -7.6256e-01,  1.9717e+00, -2.9656e-01,  3.2280e+00,\n",
       "                       9.9352e-01, -1.6515e+00,  5.6549e-01, -4.7872e-01,  2.1555e+00,\n",
       "                      -1.6201e+00, -8.0123e-01,  1.5069e+00,  1.3932e+00, -6.3564e-01,\n",
       "                       2.2549e+00,  2.9767e+00,  2.5790e+00,  1.9427e+00,  5.5311e-01,\n",
       "                      -1.4236e+00, -4.0849e-02, -2.4828e-01,  5.6082e-01,  1.0007e-01,\n",
       "                      -1.5407e+00, -1.1731e+00, -3.5762e-02, -2.3621e+00,  1.5753e+00,\n",
       "                      -1.8884e+00,  1.2932e+00,  7.3648e-01,  4.2880e-01,  3.3522e+00,\n",
       "                       1.3800e+00,  1.5895e+00,  1.1690e+00,  2.8155e+00, -4.4713e-01,\n",
       "                      -4.4093e-01, -1.9598e+00, -2.3107e+00,  1.6437e+00,  2.6060e-01,\n",
       "                       8.4535e-01,  3.0802e+00,  1.0165e+00,  1.8477e+00, -6.5322e-01,\n",
       "                       6.7600e-01,  8.1363e-01,  1.1001e+00, -2.6874e+00,  5.7886e-01,\n",
       "                      -1.2687e+00,  7.5726e-01,  9.2634e-01, -2.3968e+00, -7.0677e-01,\n",
       "                      -3.6290e-02, -5.7337e-01, -3.8407e-01, -1.2634e+00,  2.1722e+00,\n",
       "                      -2.7694e-01,  3.2331e-01,  4.1990e-01, -1.0812e+00,  5.4482e+00,\n",
       "                       1.4577e+00,  5.9460e-01,  1.4562e+00, -1.9386e+00, -1.9676e-01,\n",
       "                      -1.9020e+00,  9.7586e-01,  2.5773e+00, -2.7316e+00, -2.9127e-01,\n",
       "                      -1.0972e+00, -3.6057e+00, -1.4399e+00, -1.7299e+00,  2.6362e+00,\n",
       "                       7.7384e-02,  2.7068e-01, -6.1214e-01,  6.4547e-02, -3.1580e+00,\n",
       "                       8.0004e-01, -1.1823e+00,  5.2315e+00, -2.0183e+00, -2.9164e+00,\n",
       "                       1.7976e+00, -1.1513e+00, -7.7850e-01,  8.2239e-01,  1.5614e-01,\n",
       "                      -1.3288e+00,  4.3665e+00,  1.5202e+00, -4.9842e-03,  2.0814e-01,\n",
       "                      -3.1001e-01, -1.7770e+00,  1.0551e+00,  2.8513e-01, -1.1197e-03,\n",
       "                      -6.5352e-01, -1.1893e+00, -1.5509e+00,  1.5074e+00,  7.5722e-01,\n",
       "                       3.7492e-01, -3.2561e+00, -2.2339e+00, -2.0231e+00, -3.3980e+00,\n",
       "                       1.7286e+00, -1.4653e+00, -1.6298e+00, -9.9150e-01, -5.8345e-01,\n",
       "                       1.4514e+00, -1.3002e+00,  8.7699e-01,  8.2764e-01, -7.5572e-01,\n",
       "                       4.1432e-01, -1.0019e+00, -1.7875e-01, -2.6432e+00,  1.3303e-01,\n",
       "                       2.8391e+00, -1.5812e+00, -1.6381e+00, -4.3730e-01,  2.6655e-01,\n",
       "                       7.8718e-01, -3.8559e-01,  1.7832e+00, -2.3935e-01, -4.1260e-01,\n",
       "                      -3.5453e+00,  3.1722e-02,  3.1331e-01,  3.3193e-01, -2.4755e+00,\n",
       "                       2.8429e-01,  2.0812e+00, -7.7530e-01,  6.3360e-01, -5.4114e-01,\n",
       "                      -9.1040e-01, -2.2517e+00, -8.9697e-01,  7.3391e-03, -4.1236e-01,\n",
       "                      -3.7846e+00, -1.8720e+00, -4.8837e+00, -2.2919e+00, -2.8859e+00],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.concept_bottleneck.train import TrainFn, TestFn, run_epochs, MODEL_PATH\n",
    "from src.concept_bottleneck.inference import (\n",
    "    load_image_to_attributes_model,\n",
    "    INDEPENDENT_IMAGE_TO_ATTRIBUTES_MODEL_NAME,\n",
    "    SEQUENTIAL_ATTRIBUTES_TO_CLASS_MODEL_NAME,\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
    "\n",
    "trained_image_to_attributes_model = load_image_to_attributes_model(\n",
    "    INDEPENDENT_IMAGE_TO_ATTRIBUTES_MODEL_NAME, device\n",
    ")\n",
    "\n",
    "train_fn: TrainFn = lambda model: train(\n",
    "    model,\n",
    "    training_dataloader,\n",
    "    trained_image_to_attributes_model,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    ")\n",
    "test_fn: TestFn = lambda model, dataloader: test(\n",
    "    model, dataloader, trained_image_to_attributes_model, loss_fn, device\n",
    ")\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "\n",
    "def on_better_accuracy(model: torch.nn.Module, accuracy: float):\n",
    "    print(\n",
    "        f\"Saving model to {SEQUENTIAL_ATTRIBUTES_TO_CLASS_MODEL_NAME} with accuracy {100 * accuracy:>0.4f}%\"\n",
    "    )\n",
    "    torch.save(\n",
    "        model.state_dict(), MODEL_PATH / SEQUENTIAL_ATTRIBUTES_TO_CLASS_MODEL_NAME\n",
    "    )\n",
    "\n",
    "\n",
    "run_epochs(\n",
    "    epochs,\n",
    "    model,\n",
    "    train_fn,\n",
    "    test_fn,\n",
    "    training_dataloader,\n",
    "    test_dataloader,\n",
    "    on_better_accuracy,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d4040fe446a930194e7f49e706fe5ca82fc3ae21142ec3efeed3554a6698e7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
