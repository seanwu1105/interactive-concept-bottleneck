{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.concept_bottleneck.dataset import (\n",
    "    CUB200AttributesToClass,\n",
    "    NUM_ATTRIBUTES,\n",
    "    NUM_CLASSES,\n",
    ")\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "training_data = CUB200AttributesToClass(train=True)\n",
    "test_data = CUB200AttributesToClass(train=False)\n",
    "\n",
    "training_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.ops import MLP\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = MLP(\n",
    "    in_channels=NUM_ATTRIBUTES,\n",
    "    hidden_channels=[256, NUM_CLASSES],\n",
    "    dropout=0.5,\n",
    "    inplace=False,\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.typing as npt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: DataLoader[tuple[npt.NDArray[np.float32], np.int_]],\n",
    "    loss_fn: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: str,\n",
    "):\n",
    "    model.train()\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: DataLoader[tuple[npt.NDArray[np.float32], np.int_]],\n",
    "    loss_fn: torch.nn.Module,\n",
    "    device: str,\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            test_loss += loss_fn(logits, y).item()\n",
    "            correct += (logits.argmax(dim=1) == y).sum().item()\n",
    "\n",
    "    test_loss /= len(dataloader)\n",
    "    accuracy = correct / len(dataloader.dataset)  # type: ignore\n",
    "\n",
    "    return test_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500-------------------\n",
      "Training Loss: 5.2945, Training Accuracy: 0.5506%\n",
      "Test Loss: 5.2945, Test Accuracy: 0.5005%\n",
      "Epoch 2/500-------------------\n",
      "Training Loss: 5.2866, Training Accuracy: 0.7674%\n",
      "Test Loss: 5.2879, Test Accuracy: 0.7767%\n",
      "Epoch 3/500-------------------\n",
      "Training Loss: 5.2793, Training Accuracy: 1.1845%\n",
      "Test Loss: 5.2816, Test Accuracy: 1.2081%\n",
      "Epoch 4/500-------------------\n",
      "Training Loss: 5.2719, Training Accuracy: 1.6517%\n",
      "Test Loss: 5.2754, Test Accuracy: 1.5878%\n",
      "Epoch 5/500-------------------\n",
      "Training Loss: 5.2643, Training Accuracy: 2.0020%\n",
      "Test Loss: 5.2689, Test Accuracy: 1.8122%\n",
      "Epoch 6/500-------------------\n",
      "Training Loss: 5.2565, Training Accuracy: 2.7861%\n",
      "Test Loss: 5.2623, Test Accuracy: 2.2610%\n",
      "Epoch 7/500-------------------\n",
      "Training Loss: 5.2480, Training Accuracy: 3.2366%\n",
      "Test Loss: 5.2552, Test Accuracy: 2.6407%\n",
      "Epoch 8/500-------------------\n",
      "Training Loss: 5.2387, Training Accuracy: 3.8872%\n",
      "Test Loss: 5.2470, Test Accuracy: 3.1757%\n",
      "Epoch 9/500-------------------\n",
      "Training Loss: 5.2283, Training Accuracy: 5.0050%\n",
      "Test Loss: 5.2379, Test Accuracy: 3.9351%\n",
      "Epoch 10/500-------------------\n",
      "Training Loss: 5.2170, Training Accuracy: 5.9226%\n",
      "Test Loss: 5.2280, Test Accuracy: 4.9016%\n",
      "Epoch 11/500-------------------\n",
      "Training Loss: 5.2048, Training Accuracy: 6.8068%\n",
      "Test Loss: 5.2169, Test Accuracy: 5.6093%\n",
      "Epoch 12/500-------------------\n",
      "Training Loss: 5.1919, Training Accuracy: 8.1248%\n",
      "Test Loss: 5.2055, Test Accuracy: 6.5758%\n",
      "Epoch 13/500-------------------\n",
      "Training Loss: 5.1778, Training Accuracy: 9.1258%\n",
      "Test Loss: 5.1928, Test Accuracy: 7.5423%\n",
      "Epoch 14/500-------------------\n",
      "Training Loss: 5.1630, Training Accuracy: 9.8265%\n",
      "Test Loss: 5.1795, Test Accuracy: 8.0428%\n",
      "Epoch 15/500-------------------\n",
      "Training Loss: 5.1462, Training Accuracy: 10.8775%\n",
      "Test Loss: 5.1636, Test Accuracy: 9.2682%\n",
      "Epoch 16/500-------------------\n",
      "Training Loss: 5.1290, Training Accuracy: 11.7284%\n",
      "Test Loss: 5.1481, Test Accuracy: 9.8550%\n",
      "Epoch 17/500-------------------\n",
      "Training Loss: 5.1103, Training Accuracy: 12.7127%\n",
      "Test Loss: 5.1310, Test Accuracy: 10.4591%\n",
      "Epoch 18/500-------------------\n",
      "Training Loss: 5.0905, Training Accuracy: 14.0474%\n",
      "Test Loss: 5.1129, Test Accuracy: 11.4774%\n",
      "Epoch 19/500-------------------\n",
      "Training Loss: 5.0681, Training Accuracy: 14.2643%\n",
      "Test Loss: 5.0924, Test Accuracy: 11.8226%\n",
      "Epoch 20/500-------------------\n",
      "Training Loss: 5.0448, Training Accuracy: 14.7481%\n",
      "Test Loss: 5.0708, Test Accuracy: 12.0987%\n",
      "Epoch 21/500-------------------\n",
      "Training Loss: 5.0229, Training Accuracy: 15.6657%\n",
      "Test Loss: 5.0510, Test Accuracy: 12.2541%\n",
      "Epoch 22/500-------------------\n",
      "Training Loss: 4.9990, Training Accuracy: 16.7167%\n",
      "Test Loss: 5.0288, Test Accuracy: 12.6165%\n",
      "Epoch 23/500-------------------\n",
      "Training Loss: 4.9736, Training Accuracy: 17.8846%\n",
      "Test Loss: 5.0053, Test Accuracy: 13.6521%\n",
      "Epoch 24/500-------------------\n",
      "Training Loss: 4.9453, Training Accuracy: 18.1515%\n",
      "Test Loss: 4.9795, Test Accuracy: 13.9109%\n",
      "Epoch 25/500-------------------\n",
      "Training Loss: 4.9189, Training Accuracy: 18.7354%\n",
      "Test Loss: 4.9546, Test Accuracy: 14.4805%\n",
      "Epoch 26/500-------------------\n",
      "Training Loss: 4.8919, Training Accuracy: 19.7531%\n",
      "Test Loss: 4.9293, Test Accuracy: 14.9465%\n",
      "Epoch 27/500-------------------\n",
      "Training Loss: 4.8634, Training Accuracy: 20.3871%\n",
      "Test Loss: 4.9029, Test Accuracy: 16.0166%\n",
      "Epoch 28/500-------------------\n",
      "Training Loss: 4.8347, Training Accuracy: 21.7551%\n",
      "Test Loss: 4.8765, Test Accuracy: 16.6379%\n",
      "Epoch 29/500-------------------\n",
      "Training Loss: 4.8060, Training Accuracy: 22.2723%\n",
      "Test Loss: 4.8500, Test Accuracy: 17.0694%\n",
      "Epoch 30/500-------------------\n",
      "Training Loss: 4.7797, Training Accuracy: 23.9072%\n",
      "Test Loss: 4.8261, Test Accuracy: 18.4329%\n",
      "Epoch 31/500-------------------\n",
      "Training Loss: 4.7505, Training Accuracy: 24.6580%\n",
      "Test Loss: 4.7991, Test Accuracy: 19.0024%\n",
      "Epoch 32/500-------------------\n",
      "Training Loss: 4.7226, Training Accuracy: 24.3076%\n",
      "Test Loss: 4.7728, Test Accuracy: 18.3638%\n",
      "Epoch 33/500-------------------\n",
      "Training Loss: 4.6957, Training Accuracy: 24.8415%\n",
      "Test Loss: 4.7486, Test Accuracy: 19.3821%\n",
      "Epoch 34/500-------------------\n",
      "Training Loss: 4.6702, Training Accuracy: 26.5766%\n",
      "Test Loss: 4.7252, Test Accuracy: 20.7283%\n",
      "Epoch 35/500-------------------\n",
      "Training Loss: 4.6458, Training Accuracy: 28.2282%\n",
      "Test Loss: 4.7030, Test Accuracy: 21.5913%\n",
      "Epoch 36/500-------------------\n",
      "Training Loss: 4.6197, Training Accuracy: 28.9623%\n",
      "Test Loss: 4.6794, Test Accuracy: 22.0573%\n",
      "Epoch 37/500-------------------\n",
      "Training Loss: 4.5960, Training Accuracy: 29.7130%\n",
      "Test Loss: 4.6579, Test Accuracy: 23.1274%\n",
      "Epoch 38/500-------------------\n",
      "Training Loss: 4.5713, Training Accuracy: 30.0968%\n",
      "Test Loss: 4.6354, Test Accuracy: 22.9030%\n",
      "Epoch 39/500-------------------\n",
      "Training Loss: 4.5461, Training Accuracy: 31.5649%\n",
      "Test Loss: 4.6123, Test Accuracy: 23.8695%\n",
      "Epoch 40/500-------------------\n",
      "Training Loss: 4.5214, Training Accuracy: 32.3824%\n",
      "Test Loss: 4.5896, Test Accuracy: 24.1974%\n",
      "Epoch 41/500-------------------\n",
      "Training Loss: 4.4975, Training Accuracy: 31.6149%\n",
      "Test Loss: 4.5677, Test Accuracy: 24.2320%\n",
      "Epoch 42/500-------------------\n",
      "Training Loss: 4.4747, Training Accuracy: 33.1164%\n",
      "Test Loss: 4.5473, Test Accuracy: 25.2675%\n",
      "Epoch 43/500-------------------\n",
      "Training Loss: 4.4509, Training Accuracy: 33.5502%\n",
      "Test Loss: 4.5265, Test Accuracy: 25.6990%\n",
      "Epoch 44/500-------------------\n",
      "Training Loss: 4.4293, Training Accuracy: 33.3667%\n",
      "Test Loss: 4.5073, Test Accuracy: 25.5437%\n",
      "Epoch 45/500-------------------\n",
      "Training Loss: 4.4060, Training Accuracy: 34.2509%\n",
      "Test Loss: 4.4859, Test Accuracy: 26.1132%\n",
      "Epoch 46/500-------------------\n",
      "Training Loss: 4.3857, Training Accuracy: 34.4344%\n",
      "Test Loss: 4.4679, Test Accuracy: 26.0614%\n",
      "Epoch 47/500-------------------\n",
      "Training Loss: 4.3656, Training Accuracy: 35.3687%\n",
      "Test Loss: 4.4502, Test Accuracy: 26.9589%\n",
      "Epoch 48/500-------------------\n",
      "Training Loss: 4.3433, Training Accuracy: 35.6690%\n",
      "Test Loss: 4.4300, Test Accuracy: 27.5975%\n",
      "Epoch 49/500-------------------\n",
      "Training Loss: 4.3231, Training Accuracy: 36.4364%\n",
      "Test Loss: 4.4123, Test Accuracy: 27.6320%\n",
      "Epoch 50/500-------------------\n",
      "Training Loss: 4.3028, Training Accuracy: 36.3697%\n",
      "Test Loss: 4.3941, Test Accuracy: 27.8564%\n",
      "Epoch 51/500-------------------\n",
      "Training Loss: 4.2839, Training Accuracy: 37.6376%\n",
      "Test Loss: 4.3774, Test Accuracy: 29.0300%\n",
      "Epoch 52/500-------------------\n",
      "Training Loss: 4.2620, Training Accuracy: 38.3050%\n",
      "Test Loss: 4.3577, Test Accuracy: 29.5651%\n",
      "Epoch 53/500-------------------\n",
      "Training Loss: 4.2421, Training Accuracy: 38.7221%\n",
      "Test Loss: 4.3396, Test Accuracy: 30.1691%\n",
      "Epoch 54/500-------------------\n",
      "Training Loss: 4.2233, Training Accuracy: 39.4061%\n",
      "Test Loss: 4.3234, Test Accuracy: 30.0311%\n",
      "Epoch 55/500-------------------\n",
      "Training Loss: 4.2027, Training Accuracy: 39.0724%\n",
      "Test Loss: 4.3050, Test Accuracy: 30.1519%\n",
      "Epoch 56/500-------------------\n",
      "Training Loss: 4.1845, Training Accuracy: 39.2226%\n",
      "Test Loss: 4.2898, Test Accuracy: 30.8423%\n",
      "Epoch 57/500-------------------\n",
      "Training Loss: 4.1680, Training Accuracy: 40.9076%\n",
      "Test Loss: 4.2745, Test Accuracy: 31.6189%\n",
      "Epoch 58/500-------------------\n",
      "Training Loss: 4.1497, Training Accuracy: 41.0410%\n",
      "Test Loss: 4.2591, Test Accuracy: 31.8605%\n",
      "Epoch 59/500-------------------\n",
      "Training Loss: 4.1304, Training Accuracy: 41.2412%\n",
      "Test Loss: 4.2427, Test Accuracy: 31.3428%\n",
      "Epoch 60/500-------------------\n",
      "Training Loss: 4.1102, Training Accuracy: 41.8085%\n",
      "Test Loss: 4.2248, Test Accuracy: 31.9123%\n",
      "Epoch 61/500-------------------\n",
      "Training Loss: 4.0941, Training Accuracy: 42.3257%\n",
      "Test Loss: 4.2105, Test Accuracy: 32.3438%\n",
      "Epoch 62/500-------------------\n",
      "Training Loss: 4.0794, Training Accuracy: 42.0921%\n",
      "Test Loss: 4.1976, Test Accuracy: 31.9296%\n",
      "Epoch 63/500-------------------\n",
      "Training Loss: 4.0626, Training Accuracy: 43.0597%\n",
      "Test Loss: 4.1830, Test Accuracy: 32.8616%\n",
      "Epoch 64/500-------------------\n",
      "Training Loss: 4.0479, Training Accuracy: 43.9273%\n",
      "Test Loss: 4.1699, Test Accuracy: 33.3276%\n",
      "Epoch 65/500-------------------\n",
      "Training Loss: 4.0276, Training Accuracy: 43.6770%\n",
      "Test Loss: 4.1526, Test Accuracy: 33.2931%\n",
      "Epoch 66/500-------------------\n",
      "Training Loss: 4.0110, Training Accuracy: 44.0274%\n",
      "Test Loss: 4.1374, Test Accuracy: 33.7245%\n",
      "Epoch 67/500-------------------\n",
      "Training Loss: 3.9931, Training Accuracy: 44.6113%\n",
      "Test Loss: 4.1224, Test Accuracy: 33.2758%\n",
      "Epoch 68/500-------------------\n",
      "Training Loss: 3.9780, Training Accuracy: 44.6947%\n",
      "Test Loss: 4.1096, Test Accuracy: 33.6555%\n",
      "Epoch 69/500-------------------\n",
      "Training Loss: 3.9621, Training Accuracy: 45.3453%\n",
      "Test Loss: 4.0952, Test Accuracy: 34.1215%\n",
      "Epoch 70/500-------------------\n",
      "Training Loss: 3.9471, Training Accuracy: 45.0951%\n",
      "Test Loss: 4.0820, Test Accuracy: 34.6393%\n",
      "Epoch 71/500-------------------\n",
      "Training Loss: 3.9336, Training Accuracy: 45.5956%\n",
      "Test Loss: 4.0707, Test Accuracy: 35.1398%\n",
      "Epoch 72/500-------------------\n",
      "Training Loss: 3.9182, Training Accuracy: 46.4298%\n",
      "Test Loss: 4.0578, Test Accuracy: 34.8119%\n",
      "Epoch 73/500-------------------\n",
      "Training Loss: 3.9033, Training Accuracy: 46.3797%\n",
      "Test Loss: 4.0460, Test Accuracy: 34.7256%\n",
      "Epoch 74/500-------------------\n",
      "Training Loss: 3.8891, Training Accuracy: 46.3964%\n",
      "Test Loss: 4.0336, Test Accuracy: 35.5022%\n",
      "Epoch 75/500-------------------\n",
      "Training Loss: 3.8749, Training Accuracy: 46.5632%\n",
      "Test Loss: 4.0220, Test Accuracy: 34.9845%\n",
      "Epoch 76/500-------------------\n",
      "Training Loss: 3.8585, Training Accuracy: 47.3473%\n",
      "Test Loss: 4.0073, Test Accuracy: 35.5368%\n",
      "Epoch 77/500-------------------\n",
      "Training Loss: 3.8449, Training Accuracy: 47.6310%\n",
      "Test Loss: 3.9956, Test Accuracy: 35.6231%\n",
      "Epoch 78/500-------------------\n",
      "Training Loss: 3.8353, Training Accuracy: 47.9146%\n",
      "Test Loss: 3.9877, Test Accuracy: 35.8647%\n",
      "Epoch 79/500-------------------\n",
      "Training Loss: 3.8213, Training Accuracy: 48.3150%\n",
      "Test Loss: 3.9760, Test Accuracy: 35.9682%\n",
      "Epoch 80/500-------------------\n",
      "Training Loss: 3.8075, Training Accuracy: 48.7321%\n",
      "Test Loss: 3.9646, Test Accuracy: 36.4860%\n",
      "Epoch 81/500-------------------\n",
      "Training Loss: 3.7950, Training Accuracy: 48.9656%\n",
      "Test Loss: 3.9543, Test Accuracy: 36.6759%\n",
      "Epoch 82/500-------------------\n",
      "Training Loss: 3.7797, Training Accuracy: 48.9990%\n",
      "Test Loss: 3.9413, Test Accuracy: 36.8485%\n",
      "Epoch 83/500-------------------\n",
      "Training Loss: 3.7693, Training Accuracy: 49.5495%\n",
      "Test Loss: 3.9320, Test Accuracy: 36.7276%\n",
      "Epoch 84/500-------------------\n",
      "Training Loss: 3.7540, Training Accuracy: 49.5495%\n",
      "Test Loss: 3.9192, Test Accuracy: 36.8830%\n",
      "Epoch 85/500-------------------\n",
      "Training Loss: 3.7391, Training Accuracy: 49.8498%\n",
      "Test Loss: 3.9066, Test Accuracy: 37.4525%\n",
      "Epoch 86/500-------------------\n",
      "Training Loss: 3.7275, Training Accuracy: 49.8165%\n",
      "Test Loss: 3.8965, Test Accuracy: 36.8830%\n",
      "Epoch 87/500-------------------\n",
      "Training Loss: 3.7157, Training Accuracy: 50.3504%\n",
      "Test Loss: 3.8865, Test Accuracy: 37.2972%\n",
      "Epoch 88/500-------------------\n",
      "Training Loss: 3.7031, Training Accuracy: 50.4338%\n",
      "Test Loss: 3.8756, Test Accuracy: 37.3490%\n",
      "Epoch 89/500-------------------\n",
      "Training Loss: 3.6903, Training Accuracy: 51.0010%\n",
      "Test Loss: 3.8652, Test Accuracy: 37.6424%\n",
      "Epoch 90/500-------------------\n",
      "Training Loss: 3.6765, Training Accuracy: 51.0677%\n",
      "Test Loss: 3.8536, Test Accuracy: 37.9531%\n",
      "Epoch 91/500-------------------\n",
      "Training Loss: 3.6666, Training Accuracy: 51.2179%\n",
      "Test Loss: 3.8455, Test Accuracy: 37.9013%\n",
      "Epoch 92/500-------------------\n",
      "Training Loss: 3.6534, Training Accuracy: 51.3013%\n",
      "Test Loss: 3.8340, Test Accuracy: 38.1947%\n",
      "Epoch 93/500-------------------\n",
      "Training Loss: 3.6413, Training Accuracy: 51.7518%\n",
      "Test Loss: 3.8247, Test Accuracy: 38.0566%\n",
      "Epoch 94/500-------------------\n",
      "Training Loss: 3.6336, Training Accuracy: 52.1855%\n",
      "Test Loss: 3.8179, Test Accuracy: 38.8851%\n",
      "Epoch 95/500-------------------\n",
      "Training Loss: 3.6202, Training Accuracy: 52.7194%\n",
      "Test Loss: 3.8071, Test Accuracy: 39.0231%\n",
      "Epoch 96/500-------------------\n",
      "Training Loss: 3.6089, Training Accuracy: 52.5359%\n",
      "Test Loss: 3.7980, Test Accuracy: 38.9713%\n",
      "Epoch 97/500-------------------\n",
      "Training Loss: 3.5956, Training Accuracy: 53.2032%\n",
      "Test Loss: 3.7867, Test Accuracy: 38.7297%\n",
      "Epoch 98/500-------------------\n",
      "Training Loss: 3.5868, Training Accuracy: 53.2533%\n",
      "Test Loss: 3.7794, Test Accuracy: 38.9541%\n",
      "Epoch 99/500-------------------\n",
      "Training Loss: 3.5706, Training Accuracy: 53.1698%\n",
      "Test Loss: 3.7659, Test Accuracy: 39.1267%\n",
      "Epoch 100/500-------------------\n",
      "Training Loss: 3.5607, Training Accuracy: 53.4535%\n",
      "Test Loss: 3.7581, Test Accuracy: 39.1785%\n",
      "Epoch 101/500-------------------\n",
      "Training Loss: 3.5517, Training Accuracy: 53.9206%\n",
      "Test Loss: 3.7505, Test Accuracy: 39.3165%\n",
      "Epoch 102/500-------------------\n",
      "Training Loss: 3.5391, Training Accuracy: 53.8205%\n",
      "Test Loss: 3.7404, Test Accuracy: 39.2475%\n",
      "Epoch 103/500-------------------\n",
      "Training Loss: 3.5313, Training Accuracy: 53.9039%\n",
      "Test Loss: 3.7341, Test Accuracy: 39.5064%\n",
      "Epoch 104/500-------------------\n",
      "Training Loss: 3.5192, Training Accuracy: 54.0040%\n",
      "Test Loss: 3.7241, Test Accuracy: 39.5754%\n",
      "Epoch 105/500-------------------\n",
      "Training Loss: 3.5056, Training Accuracy: 54.1542%\n",
      "Test Loss: 3.7127, Test Accuracy: 39.6790%\n",
      "Epoch 106/500-------------------\n",
      "Training Loss: 3.4961, Training Accuracy: 54.7047%\n",
      "Test Loss: 3.7063, Test Accuracy: 39.7998%\n",
      "Epoch 107/500-------------------\n",
      "Training Loss: 3.4841, Training Accuracy: 54.4878%\n",
      "Test Loss: 3.6971, Test Accuracy: 39.7480%\n",
      "Epoch 108/500-------------------\n",
      "Training Loss: 3.4741, Training Accuracy: 55.1385%\n",
      "Test Loss: 3.6887, Test Accuracy: 39.8516%\n",
      "Epoch 109/500-------------------\n",
      "Training Loss: 3.4648, Training Accuracy: 55.1051%\n",
      "Test Loss: 3.6806, Test Accuracy: 39.7308%\n",
      "Epoch 110/500-------------------\n",
      "Training Loss: 3.4537, Training Accuracy: 55.6223%\n",
      "Test Loss: 3.6719, Test Accuracy: 39.8688%\n",
      "Epoch 111/500-------------------\n",
      "Training Loss: 3.4483, Training Accuracy: 55.8392%\n",
      "Test Loss: 3.6684, Test Accuracy: 40.1450%\n",
      "Epoch 112/500-------------------\n",
      "Training Loss: 3.4436, Training Accuracy: 55.4888%\n",
      "Test Loss: 3.6642, Test Accuracy: 40.0932%\n",
      "Epoch 113/500-------------------\n",
      "Training Loss: 3.4357, Training Accuracy: 55.8725%\n",
      "Test Loss: 3.6577, Test Accuracy: 40.1450%\n",
      "Epoch 114/500-------------------\n",
      "Training Loss: 3.4225, Training Accuracy: 56.5399%\n",
      "Test Loss: 3.6470, Test Accuracy: 40.6282%\n",
      "Epoch 115/500-------------------\n",
      "Training Loss: 3.4104, Training Accuracy: 56.2396%\n",
      "Test Loss: 3.6365, Test Accuracy: 40.7145%\n",
      "Epoch 116/500-------------------\n",
      "Training Loss: 3.4033, Training Accuracy: 56.9236%\n",
      "Test Loss: 3.6317, Test Accuracy: 40.7145%\n",
      "Epoch 117/500-------------------\n",
      "Training Loss: 3.3914, Training Accuracy: 56.7901%\n",
      "Test Loss: 3.6220, Test Accuracy: 40.6282%\n",
      "Epoch 118/500-------------------\n",
      "Training Loss: 3.3821, Training Accuracy: 56.8068%\n",
      "Test Loss: 3.6141, Test Accuracy: 41.1633%\n",
      "Epoch 119/500-------------------\n",
      "Training Loss: 3.3721, Training Accuracy: 56.9236%\n",
      "Test Loss: 3.6061, Test Accuracy: 41.1978%\n",
      "Epoch 120/500-------------------\n",
      "Training Loss: 3.3621, Training Accuracy: 57.1572%\n",
      "Test Loss: 3.5983, Test Accuracy: 41.1633%\n",
      "Epoch 121/500-------------------\n",
      "Training Loss: 3.3550, Training Accuracy: 57.0737%\n",
      "Test Loss: 3.5927, Test Accuracy: 40.9216%\n",
      "Epoch 122/500-------------------\n",
      "Training Loss: 3.3455, Training Accuracy: 57.1405%\n",
      "Test Loss: 3.5856, Test Accuracy: 41.0425%\n",
      "Epoch 123/500-------------------\n",
      "Training Loss: 3.3346, Training Accuracy: 57.7244%\n",
      "Test Loss: 3.5768, Test Accuracy: 41.0079%\n",
      "Epoch 124/500-------------------\n",
      "Training Loss: 3.3223, Training Accuracy: 57.8579%\n",
      "Test Loss: 3.5673, Test Accuracy: 41.4567%\n",
      "Epoch 125/500-------------------\n",
      "Training Loss: 3.3150, Training Accuracy: 57.9246%\n",
      "Test Loss: 3.5618, Test Accuracy: 41.2841%\n",
      "Epoch 126/500-------------------\n",
      "Training Loss: 3.3047, Training Accuracy: 57.7911%\n",
      "Test Loss: 3.5531, Test Accuracy: 41.1115%\n",
      "Epoch 127/500-------------------\n",
      "Training Loss: 3.2984, Training Accuracy: 57.3740%\n",
      "Test Loss: 3.5476, Test Accuracy: 41.2151%\n",
      "Epoch 128/500-------------------\n",
      "Training Loss: 3.2951, Training Accuracy: 57.6243%\n",
      "Test Loss: 3.5455, Test Accuracy: 41.6120%\n",
      "Epoch 129/500-------------------\n",
      "Training Loss: 3.2842, Training Accuracy: 57.7244%\n",
      "Test Loss: 3.5373, Test Accuracy: 42.0262%\n",
      "Epoch 130/500-------------------\n",
      "Training Loss: 3.2739, Training Accuracy: 58.2416%\n",
      "Test Loss: 3.5289, Test Accuracy: 41.9054%\n",
      "Epoch 131/500-------------------\n",
      "Training Loss: 3.2684, Training Accuracy: 58.7754%\n",
      "Test Loss: 3.5252, Test Accuracy: 42.1643%\n",
      "Epoch 132/500-------------------\n",
      "Training Loss: 3.2604, Training Accuracy: 59.0591%\n",
      "Test Loss: 3.5191, Test Accuracy: 41.9399%\n",
      "Epoch 133/500-------------------\n",
      "Training Loss: 3.2503, Training Accuracy: 58.9423%\n",
      "Test Loss: 3.5112, Test Accuracy: 42.1470%\n",
      "Epoch 134/500-------------------\n",
      "Training Loss: 3.2471, Training Accuracy: 58.7588%\n",
      "Test Loss: 3.5092, Test Accuracy: 42.1988%\n",
      "Epoch 135/500-------------------\n",
      "Training Loss: 3.2392, Training Accuracy: 59.1258%\n",
      "Test Loss: 3.5026, Test Accuracy: 42.4232%\n",
      "Epoch 136/500-------------------\n",
      "Training Loss: 3.2303, Training Accuracy: 59.3760%\n",
      "Test Loss: 3.4966, Test Accuracy: 42.6993%\n",
      "Epoch 137/500-------------------\n",
      "Training Loss: 3.2275, Training Accuracy: 59.4261%\n",
      "Test Loss: 3.4949, Test Accuracy: 42.8029%\n",
      "Epoch 138/500-------------------\n",
      "Training Loss: 3.2179, Training Accuracy: 59.8098%\n",
      "Test Loss: 3.4871, Test Accuracy: 42.7339%\n",
      "Epoch 139/500-------------------\n",
      "Training Loss: 3.2109, Training Accuracy: 59.5429%\n",
      "Test Loss: 3.4826, Test Accuracy: 42.8547%\n",
      "Epoch 140/500-------------------\n",
      "Training Loss: 3.1990, Training Accuracy: 59.7264%\n",
      "Test Loss: 3.4731, Test Accuracy: 42.5785%\n",
      "Epoch 141/500-------------------\n",
      "Training Loss: 3.1880, Training Accuracy: 59.5929%\n",
      "Test Loss: 3.4646, Test Accuracy: 42.8202%\n",
      "Epoch 142/500-------------------\n",
      "Training Loss: 3.1855, Training Accuracy: 59.6096%\n",
      "Test Loss: 3.4629, Test Accuracy: 42.0780%\n",
      "Epoch 143/500-------------------\n",
      "Training Loss: 3.1707, Training Accuracy: 59.9266%\n",
      "Test Loss: 3.4505, Test Accuracy: 42.5613%\n",
      "Epoch 144/500-------------------\n",
      "Training Loss: 3.1668, Training Accuracy: 60.4605%\n",
      "Test Loss: 3.4488, Test Accuracy: 42.3024%\n",
      "Epoch 145/500-------------------\n",
      "Training Loss: 3.1586, Training Accuracy: 60.2102%\n",
      "Test Loss: 3.4421, Test Accuracy: 42.6303%\n",
      "Epoch 146/500-------------------\n",
      "Training Loss: 3.1521, Training Accuracy: 60.6607%\n",
      "Test Loss: 3.4365, Test Accuracy: 42.7166%\n",
      "Epoch 147/500-------------------\n",
      "Training Loss: 3.1422, Training Accuracy: 60.2936%\n",
      "Test Loss: 3.4294, Test Accuracy: 42.9582%\n",
      "Epoch 148/500-------------------\n",
      "Training Loss: 3.1347, Training Accuracy: 60.0934%\n",
      "Test Loss: 3.4241, Test Accuracy: 43.1481%\n",
      "Epoch 149/500-------------------\n",
      "Training Loss: 3.1255, Training Accuracy: 60.6607%\n",
      "Test Loss: 3.4166, Test Accuracy: 43.1653%\n",
      "Epoch 150/500-------------------\n",
      "Training Loss: 3.1225, Training Accuracy: 60.4104%\n",
      "Test Loss: 3.4155, Test Accuracy: 42.9928%\n",
      "Epoch 151/500-------------------\n",
      "Training Loss: 3.1178, Training Accuracy: 61.0944%\n",
      "Test Loss: 3.4116, Test Accuracy: 42.7684%\n",
      "Epoch 152/500-------------------\n",
      "Training Loss: 3.1098, Training Accuracy: 60.8609%\n",
      "Test Loss: 3.4063, Test Accuracy: 42.6821%\n",
      "Epoch 153/500-------------------\n",
      "Training Loss: 3.1054, Training Accuracy: 60.9276%\n",
      "Test Loss: 3.4034, Test Accuracy: 42.9755%\n",
      "Epoch 154/500-------------------\n",
      "Training Loss: 3.0953, Training Accuracy: 61.3947%\n",
      "Test Loss: 3.3954, Test Accuracy: 43.4415%\n",
      "Epoch 155/500-------------------\n",
      "Training Loss: 3.0941, Training Accuracy: 61.4615%\n",
      "Test Loss: 3.3944, Test Accuracy: 43.3725%\n",
      "Epoch 156/500-------------------\n",
      "Training Loss: 3.0864, Training Accuracy: 61.3447%\n",
      "Test Loss: 3.3883, Test Accuracy: 42.9237%\n",
      "Epoch 157/500-------------------\n",
      "Training Loss: 3.0773, Training Accuracy: 61.4281%\n",
      "Test Loss: 3.3822, Test Accuracy: 43.1999%\n",
      "Epoch 158/500-------------------\n",
      "Training Loss: 3.0639, Training Accuracy: 61.6950%\n",
      "Test Loss: 3.3711, Test Accuracy: 43.2516%\n",
      "Epoch 159/500-------------------\n",
      "Training Loss: 3.0624, Training Accuracy: 61.8452%\n",
      "Test Loss: 3.3708, Test Accuracy: 43.8039%\n",
      "Epoch 160/500-------------------\n",
      "Training Loss: 3.0591, Training Accuracy: 61.8118%\n",
      "Test Loss: 3.3678, Test Accuracy: 44.0628%\n",
      "Epoch 161/500-------------------\n",
      "Training Loss: 3.0560, Training Accuracy: 61.9620%\n",
      "Test Loss: 3.3670, Test Accuracy: 43.7004%\n",
      "Epoch 162/500-------------------\n",
      "Training Loss: 3.0508, Training Accuracy: 62.2456%\n",
      "Test Loss: 3.3637, Test Accuracy: 43.5968%\n",
      "Epoch 163/500-------------------\n",
      "Training Loss: 3.0416, Training Accuracy: 62.0287%\n",
      "Test Loss: 3.3566, Test Accuracy: 43.3552%\n",
      "Epoch 164/500-------------------\n",
      "Training Loss: 3.0320, Training Accuracy: 62.0954%\n",
      "Test Loss: 3.3490, Test Accuracy: 43.5278%\n",
      "Epoch 165/500-------------------\n",
      "Training Loss: 3.0272, Training Accuracy: 62.5626%\n",
      "Test Loss: 3.3460, Test Accuracy: 43.4242%\n",
      "Epoch 166/500-------------------\n",
      "Training Loss: 3.0222, Training Accuracy: 62.3624%\n",
      "Test Loss: 3.3425, Test Accuracy: 43.7176%\n",
      "Epoch 167/500-------------------\n",
      "Training Loss: 3.0179, Training Accuracy: 62.1955%\n",
      "Test Loss: 3.3387, Test Accuracy: 43.9247%\n",
      "Epoch 168/500-------------------\n",
      "Training Loss: 3.0088, Training Accuracy: 62.6293%\n",
      "Test Loss: 3.3322, Test Accuracy: 43.7004%\n",
      "Epoch 169/500-------------------\n",
      "Training Loss: 3.0021, Training Accuracy: 62.8462%\n",
      "Test Loss: 3.3274, Test Accuracy: 43.9765%\n",
      "Epoch 170/500-------------------\n",
      "Training Loss: 2.9992, Training Accuracy: 62.9129%\n",
      "Test Loss: 3.3257, Test Accuracy: 43.9765%\n",
      "Epoch 171/500-------------------\n",
      "Training Loss: 2.9932, Training Accuracy: 62.9129%\n",
      "Test Loss: 3.3213, Test Accuracy: 43.8385%\n",
      "Epoch 172/500-------------------\n",
      "Training Loss: 2.9857, Training Accuracy: 62.9129%\n",
      "Test Loss: 3.3153, Test Accuracy: 44.0110%\n",
      "Epoch 173/500-------------------\n",
      "Training Loss: 2.9822, Training Accuracy: 62.9129%\n",
      "Test Loss: 3.3143, Test Accuracy: 44.2009%\n",
      "Epoch 174/500-------------------\n",
      "Training Loss: 2.9774, Training Accuracy: 63.0797%\n",
      "Test Loss: 3.3104, Test Accuracy: 44.3562%\n",
      "Epoch 175/500-------------------\n",
      "Training Loss: 2.9652, Training Accuracy: 63.2299%\n",
      "Test Loss: 3.3010, Test Accuracy: 44.2872%\n",
      "Epoch 176/500-------------------\n",
      "Training Loss: 2.9582, Training Accuracy: 63.4968%\n",
      "Test Loss: 3.2969, Test Accuracy: 44.3907%\n",
      "Epoch 177/500-------------------\n",
      "Training Loss: 2.9552, Training Accuracy: 63.4468%\n",
      "Test Loss: 3.2936, Test Accuracy: 44.3045%\n",
      "Epoch 178/500-------------------\n",
      "Training Loss: 2.9484, Training Accuracy: 63.3967%\n",
      "Test Loss: 3.2894, Test Accuracy: 44.4253%\n",
      "Epoch 179/500-------------------\n",
      "Training Loss: 2.9405, Training Accuracy: 63.4134%\n",
      "Test Loss: 3.2837, Test Accuracy: 44.0973%\n",
      "Epoch 180/500-------------------\n",
      "Training Loss: 2.9385, Training Accuracy: 63.2966%\n",
      "Test Loss: 3.2826, Test Accuracy: 44.1146%\n",
      "Epoch 181/500-------------------\n",
      "Training Loss: 2.9356, Training Accuracy: 63.7638%\n",
      "Test Loss: 3.2811, Test Accuracy: 43.9420%\n",
      "Epoch 182/500-------------------\n",
      "Training Loss: 2.9237, Training Accuracy: 63.8138%\n",
      "Test Loss: 3.2713, Test Accuracy: 44.6151%\n",
      "Epoch 183/500-------------------\n",
      "Training Loss: 2.9167, Training Accuracy: 64.2643%\n",
      "Test Loss: 3.2661, Test Accuracy: 44.3045%\n",
      "Epoch 184/500-------------------\n",
      "Training Loss: 2.9111, Training Accuracy: 64.2309%\n",
      "Test Loss: 3.2622, Test Accuracy: 43.8557%\n",
      "Epoch 185/500-------------------\n",
      "Training Loss: 2.9009, Training Accuracy: 64.1975%\n",
      "Test Loss: 3.2548, Test Accuracy: 44.4253%\n",
      "Epoch 186/500-------------------\n",
      "Training Loss: 2.8981, Training Accuracy: 64.4144%\n",
      "Test Loss: 3.2542, Test Accuracy: 44.2354%\n",
      "Epoch 187/500-------------------\n",
      "Training Loss: 2.8912, Training Accuracy: 64.2643%\n",
      "Test Loss: 3.2488, Test Accuracy: 44.4080%\n",
      "Epoch 188/500-------------------\n",
      "Training Loss: 2.8862, Training Accuracy: 64.4978%\n",
      "Test Loss: 3.2450, Test Accuracy: 44.5633%\n",
      "Epoch 189/500-------------------\n",
      "Training Loss: 2.8898, Training Accuracy: 64.2976%\n",
      "Test Loss: 3.2482, Test Accuracy: 44.3907%\n",
      "Epoch 190/500-------------------\n",
      "Training Loss: 2.8809, Training Accuracy: 64.6647%\n",
      "Test Loss: 3.2413, Test Accuracy: 44.1319%\n",
      "Epoch 191/500-------------------\n",
      "Training Loss: 2.8758, Training Accuracy: 64.5145%\n",
      "Test Loss: 3.2381, Test Accuracy: 44.2009%\n",
      "Epoch 192/500-------------------\n",
      "Training Loss: 2.8731, Training Accuracy: 64.5646%\n",
      "Test Loss: 3.2374, Test Accuracy: 44.4425%\n",
      "Epoch 193/500-------------------\n",
      "Training Loss: 2.8650, Training Accuracy: 64.5145%\n",
      "Test Loss: 3.2312, Test Accuracy: 44.3390%\n",
      "Epoch 194/500-------------------\n",
      "Training Loss: 2.8619, Training Accuracy: 65.0817%\n",
      "Test Loss: 3.2298, Test Accuracy: 44.5288%\n",
      "Epoch 195/500-------------------\n",
      "Training Loss: 2.8567, Training Accuracy: 64.9983%\n",
      "Test Loss: 3.2271, Test Accuracy: 44.5461%\n",
      "Epoch 196/500-------------------\n",
      "Training Loss: 2.8506, Training Accuracy: 65.2486%\n",
      "Test Loss: 3.2215, Test Accuracy: 44.4770%\n",
      "Epoch 197/500-------------------\n",
      "Training Loss: 2.8488, Training Accuracy: 65.2152%\n",
      "Test Loss: 3.2224, Test Accuracy: 44.5806%\n",
      "Epoch 198/500-------------------\n",
      "Training Loss: 2.8423, Training Accuracy: 65.4988%\n",
      "Test Loss: 3.2167, Test Accuracy: 44.7187%\n",
      "Epoch 199/500-------------------\n",
      "Training Loss: 2.8377, Training Accuracy: 65.5822%\n",
      "Test Loss: 3.2142, Test Accuracy: 44.4943%\n",
      "Epoch 200/500-------------------\n",
      "Training Loss: 2.8269, Training Accuracy: 65.5822%\n",
      "Test Loss: 3.2060, Test Accuracy: 44.5461%\n",
      "Epoch 201/500-------------------\n",
      "Training Loss: 2.8183, Training Accuracy: 65.3654%\n",
      "Test Loss: 3.1991, Test Accuracy: 44.7705%\n",
      "Epoch 202/500-------------------\n",
      "Training Loss: 2.8196, Training Accuracy: 65.3153%\n",
      "Test Loss: 3.2012, Test Accuracy: 44.4080%\n",
      "Epoch 203/500-------------------\n",
      "Training Loss: 2.8147, Training Accuracy: 65.6156%\n",
      "Test Loss: 3.1989, Test Accuracy: 44.1664%\n",
      "Epoch 204/500-------------------\n",
      "Training Loss: 2.8077, Training Accuracy: 65.6657%\n",
      "Test Loss: 3.1941, Test Accuracy: 44.7187%\n",
      "Epoch 205/500-------------------\n",
      "Training Loss: 2.7999, Training Accuracy: 65.9326%\n",
      "Test Loss: 3.1881, Test Accuracy: 44.6324%\n",
      "Epoch 206/500-------------------\n",
      "Training Loss: 2.7992, Training Accuracy: 65.9159%\n",
      "Test Loss: 3.1872, Test Accuracy: 44.9085%\n",
      "Epoch 207/500-------------------\n",
      "Training Loss: 2.7975, Training Accuracy: 66.0494%\n",
      "Test Loss: 3.1870, Test Accuracy: 44.8222%\n",
      "Epoch 208/500-------------------\n",
      "Training Loss: 2.7873, Training Accuracy: 65.9826%\n",
      "Test Loss: 3.1796, Test Accuracy: 44.7532%\n",
      "Epoch 209/500-------------------\n",
      "Training Loss: 2.7888, Training Accuracy: 66.2663%\n",
      "Test Loss: 3.1805, Test Accuracy: 45.2019%\n",
      "Epoch 210/500-------------------\n",
      "Training Loss: 2.7822, Training Accuracy: 66.5999%\n",
      "Test Loss: 3.1758, Test Accuracy: 44.8913%\n",
      "Epoch 211/500-------------------\n",
      "Training Loss: 2.7798, Training Accuracy: 66.5332%\n",
      "Test Loss: 3.1744, Test Accuracy: 44.7532%\n",
      "Epoch 212/500-------------------\n",
      "Training Loss: 2.7716, Training Accuracy: 66.4831%\n",
      "Test Loss: 3.1697, Test Accuracy: 44.8913%\n",
      "Epoch 213/500-------------------\n",
      "Training Loss: 2.7668, Training Accuracy: 66.4831%\n",
      "Test Loss: 3.1671, Test Accuracy: 44.8567%\n",
      "Epoch 214/500-------------------\n",
      "Training Loss: 2.7601, Training Accuracy: 66.6500%\n",
      "Test Loss: 3.1629, Test Accuracy: 45.0293%\n",
      "Epoch 215/500-------------------\n",
      "Training Loss: 2.7595, Training Accuracy: 66.9169%\n",
      "Test Loss: 3.1632, Test Accuracy: 45.1502%\n",
      "Epoch 216/500-------------------\n",
      "Training Loss: 2.7523, Training Accuracy: 66.6667%\n",
      "Test Loss: 3.1573, Test Accuracy: 45.0984%\n",
      "Epoch 217/500-------------------\n",
      "Training Loss: 2.7496, Training Accuracy: 66.9169%\n",
      "Test Loss: 3.1555, Test Accuracy: 44.7705%\n",
      "Epoch 218/500-------------------\n",
      "Training Loss: 2.7429, Training Accuracy: 66.7167%\n",
      "Test Loss: 3.1517, Test Accuracy: 44.9948%\n",
      "Epoch 219/500-------------------\n",
      "Training Loss: 2.7356, Training Accuracy: 67.0838%\n",
      "Test Loss: 3.1466, Test Accuracy: 44.9776%\n",
      "Epoch 220/500-------------------\n",
      "Training Loss: 2.7310, Training Accuracy: 66.8335%\n",
      "Test Loss: 3.1431, Test Accuracy: 44.7877%\n",
      "Epoch 221/500-------------------\n",
      "Training Loss: 2.7292, Training Accuracy: 67.0337%\n",
      "Test Loss: 3.1428, Test Accuracy: 44.8222%\n",
      "Epoch 222/500-------------------\n",
      "Training Loss: 2.7235, Training Accuracy: 67.5175%\n",
      "Test Loss: 3.1385, Test Accuracy: 44.8395%\n",
      "Epoch 223/500-------------------\n",
      "Training Loss: 2.7161, Training Accuracy: 67.3340%\n",
      "Test Loss: 3.1332, Test Accuracy: 44.8913%\n",
      "Epoch 224/500-------------------\n",
      "Training Loss: 2.7147, Training Accuracy: 67.2673%\n",
      "Test Loss: 3.1316, Test Accuracy: 45.2365%\n",
      "Epoch 225/500-------------------\n",
      "Training Loss: 2.7151, Training Accuracy: 67.7845%\n",
      "Test Loss: 3.1332, Test Accuracy: 44.9948%\n",
      "Epoch 226/500-------------------\n",
      "Training Loss: 2.7079, Training Accuracy: 67.6009%\n",
      "Test Loss: 3.1292, Test Accuracy: 45.2019%\n",
      "Epoch 227/500-------------------\n",
      "Training Loss: 2.7011, Training Accuracy: 67.5676%\n",
      "Test Loss: 3.1239, Test Accuracy: 45.1329%\n",
      "Epoch 228/500-------------------\n",
      "Training Loss: 2.6970, Training Accuracy: 68.1348%\n",
      "Test Loss: 3.1209, Test Accuracy: 44.8222%\n",
      "Epoch 229/500-------------------\n",
      "Training Loss: 2.6966, Training Accuracy: 67.9847%\n",
      "Test Loss: 3.1221, Test Accuracy: 44.5633%\n",
      "Epoch 230/500-------------------\n",
      "Training Loss: 2.6920, Training Accuracy: 67.9346%\n",
      "Test Loss: 3.1187, Test Accuracy: 45.0811%\n",
      "Epoch 231/500-------------------\n",
      "Training Loss: 2.6868, Training Accuracy: 68.1849%\n",
      "Test Loss: 3.1149, Test Accuracy: 45.4090%\n",
      "Epoch 232/500-------------------\n",
      "Training Loss: 2.6801, Training Accuracy: 68.3183%\n",
      "Test Loss: 3.1097, Test Accuracy: 45.5126%\n",
      "Epoch 233/500-------------------\n",
      "Training Loss: 2.6760, Training Accuracy: 68.3851%\n",
      "Test Loss: 3.1071, Test Accuracy: 45.1156%\n",
      "Epoch 234/500-------------------\n",
      "Training Loss: 2.6707, Training Accuracy: 68.3183%\n",
      "Test Loss: 3.1030, Test Accuracy: 45.3745%\n",
      "Epoch 235/500-------------------\n",
      "Training Loss: 2.6717, Training Accuracy: 68.3350%\n",
      "Test Loss: 3.1049, Test Accuracy: 45.0466%\n",
      "Epoch 236/500-------------------\n",
      "Training Loss: 2.6648, Training Accuracy: 68.4518%\n",
      "Test Loss: 3.1009, Test Accuracy: 45.3055%\n",
      "Epoch 237/500-------------------\n",
      "Training Loss: 2.6564, Training Accuracy: 68.6019%\n",
      "Test Loss: 3.0943, Test Accuracy: 45.0639%\n",
      "Epoch 238/500-------------------\n",
      "Training Loss: 2.6545, Training Accuracy: 68.4184%\n",
      "Test Loss: 3.0933, Test Accuracy: 45.0466%\n",
      "Epoch 239/500-------------------\n",
      "Training Loss: 2.6508, Training Accuracy: 68.8021%\n",
      "Test Loss: 3.0914, Test Accuracy: 45.5126%\n",
      "Epoch 240/500-------------------\n",
      "Training Loss: 2.6469, Training Accuracy: 68.6353%\n",
      "Test Loss: 3.0883, Test Accuracy: 45.2710%\n",
      "Epoch 241/500-------------------\n",
      "Training Loss: 2.6382, Training Accuracy: 68.8522%\n",
      "Test Loss: 3.0831, Test Accuracy: 45.0121%\n",
      "Epoch 242/500-------------------\n",
      "Training Loss: 2.6329, Training Accuracy: 68.7354%\n",
      "Test Loss: 3.0799, Test Accuracy: 45.1847%\n",
      "Epoch 243/500-------------------\n",
      "Training Loss: 2.6360, Training Accuracy: 69.3193%\n",
      "Test Loss: 3.0836, Test Accuracy: 45.5816%\n",
      "Epoch 244/500-------------------\n",
      "Training Loss: 2.6243, Training Accuracy: 68.9356%\n",
      "Test Loss: 3.0745, Test Accuracy: 45.6162%\n",
      "Epoch 245/500-------------------\n",
      "Training Loss: 2.6221, Training Accuracy: 69.2359%\n",
      "Test Loss: 3.0729, Test Accuracy: 45.2882%\n",
      "Epoch 246/500-------------------\n",
      "Training Loss: 2.6201, Training Accuracy: 69.2359%\n",
      "Test Loss: 3.0729, Test Accuracy: 45.4263%\n",
      "Epoch 247/500-------------------\n",
      "Training Loss: 2.6125, Training Accuracy: 69.0190%\n",
      "Test Loss: 3.0680, Test Accuracy: 45.0811%\n",
      "Epoch 248/500-------------------\n",
      "Training Loss: 2.6123, Training Accuracy: 69.1525%\n",
      "Test Loss: 3.0683, Test Accuracy: 45.4436%\n",
      "Epoch 249/500-------------------\n",
      "Training Loss: 2.6075, Training Accuracy: 69.4528%\n",
      "Test Loss: 3.0647, Test Accuracy: 45.3400%\n",
      "Epoch 250/500-------------------\n",
      "Training Loss: 2.6050, Training Accuracy: 69.4361%\n",
      "Test Loss: 3.0634, Test Accuracy: 45.2365%\n",
      "Epoch 251/500-------------------\n",
      "Training Loss: 2.6018, Training Accuracy: 69.4194%\n",
      "Test Loss: 3.0623, Test Accuracy: 45.5126%\n",
      "Epoch 252/500-------------------\n",
      "Training Loss: 2.5952, Training Accuracy: 69.4194%\n",
      "Test Loss: 3.0574, Test Accuracy: 45.6679%\n",
      "Epoch 253/500-------------------\n",
      "Training Loss: 2.5906, Training Accuracy: 69.8699%\n",
      "Test Loss: 3.0539, Test Accuracy: 46.0131%\n",
      "Epoch 254/500-------------------\n",
      "Training Loss: 2.5913, Training Accuracy: 69.6196%\n",
      "Test Loss: 3.0547, Test Accuracy: 45.6507%\n",
      "Epoch 255/500-------------------\n",
      "Training Loss: 2.5873, Training Accuracy: 69.6029%\n",
      "Test Loss: 3.0529, Test Accuracy: 45.5471%\n",
      "Epoch 256/500-------------------\n",
      "Training Loss: 2.5774, Training Accuracy: 69.5696%\n",
      "Test Loss: 3.0450, Test Accuracy: 45.9613%\n",
      "Epoch 257/500-------------------\n",
      "Training Loss: 2.5744, Training Accuracy: 69.9533%\n",
      "Test Loss: 3.0436, Test Accuracy: 45.7887%\n",
      "Epoch 258/500-------------------\n",
      "Training Loss: 2.5698, Training Accuracy: 69.8866%\n",
      "Test Loss: 3.0409, Test Accuracy: 46.0131%\n",
      "Epoch 259/500-------------------\n",
      "Training Loss: 2.5721, Training Accuracy: 70.1535%\n",
      "Test Loss: 3.0436, Test Accuracy: 45.9268%\n",
      "Epoch 260/500-------------------\n",
      "Training Loss: 2.5692, Training Accuracy: 70.2202%\n",
      "Test Loss: 3.0423, Test Accuracy: 45.7887%\n",
      "Epoch 261/500-------------------\n",
      "Training Loss: 2.5637, Training Accuracy: 70.1368%\n",
      "Test Loss: 3.0393, Test Accuracy: 45.7715%\n",
      "Epoch 262/500-------------------\n",
      "Training Loss: 2.5566, Training Accuracy: 70.0367%\n",
      "Test Loss: 3.0332, Test Accuracy: 45.8233%\n",
      "Epoch 263/500-------------------\n",
      "Training Loss: 2.5507, Training Accuracy: 70.2703%\n",
      "Test Loss: 3.0289, Test Accuracy: 46.0304%\n",
      "Epoch 264/500-------------------\n",
      "Training Loss: 2.5486, Training Accuracy: 70.7040%\n",
      "Test Loss: 3.0279, Test Accuracy: 46.2547%\n",
      "Epoch 265/500-------------------\n",
      "Training Loss: 2.5462, Training Accuracy: 70.5372%\n",
      "Test Loss: 3.0282, Test Accuracy: 46.0822%\n",
      "Epoch 266/500-------------------\n",
      "Training Loss: 2.5456, Training Accuracy: 70.5205%\n",
      "Test Loss: 3.0279, Test Accuracy: 45.8750%\n",
      "Epoch 267/500-------------------\n",
      "Training Loss: 2.5419, Training Accuracy: 70.9543%\n",
      "Test Loss: 3.0254, Test Accuracy: 45.8750%\n",
      "Epoch 268/500-------------------\n",
      "Training Loss: 2.5374, Training Accuracy: 70.7708%\n",
      "Test Loss: 3.0229, Test Accuracy: 46.1512%\n",
      "Epoch 269/500-------------------\n",
      "Training Loss: 2.5284, Training Accuracy: 70.7875%\n",
      "Test Loss: 3.0164, Test Accuracy: 45.9268%\n",
      "Epoch 270/500-------------------\n",
      "Training Loss: 2.5228, Training Accuracy: 70.7374%\n",
      "Test Loss: 3.0127, Test Accuracy: 46.1685%\n",
      "Epoch 271/500-------------------\n",
      "Training Loss: 2.5202, Training Accuracy: 70.7708%\n",
      "Test Loss: 3.0109, Test Accuracy: 45.9441%\n",
      "Epoch 272/500-------------------\n",
      "Training Loss: 2.5203, Training Accuracy: 70.8375%\n",
      "Test Loss: 3.0120, Test Accuracy: 45.9268%\n",
      "Epoch 273/500-------------------\n",
      "Training Loss: 2.5176, Training Accuracy: 71.2212%\n",
      "Test Loss: 3.0099, Test Accuracy: 46.1339%\n",
      "Epoch 274/500-------------------\n",
      "Training Loss: 2.5101, Training Accuracy: 70.7541%\n",
      "Test Loss: 3.0052, Test Accuracy: 45.9613%\n",
      "Epoch 275/500-------------------\n",
      "Training Loss: 2.5089, Training Accuracy: 71.0043%\n",
      "Test Loss: 3.0049, Test Accuracy: 45.8405%\n",
      "Epoch 276/500-------------------\n",
      "Training Loss: 2.5047, Training Accuracy: 71.0711%\n",
      "Test Loss: 3.0031, Test Accuracy: 46.0649%\n",
      "Epoch 277/500-------------------\n",
      "Training Loss: 2.5015, Training Accuracy: 70.9877%\n",
      "Test Loss: 3.0014, Test Accuracy: 45.9959%\n",
      "Epoch 278/500-------------------\n",
      "Training Loss: 2.5011, Training Accuracy: 71.0711%\n",
      "Test Loss: 3.0015, Test Accuracy: 46.3065%\n",
      "Epoch 279/500-------------------\n",
      "Training Loss: 2.4974, Training Accuracy: 71.1044%\n",
      "Test Loss: 2.9991, Test Accuracy: 46.0131%\n",
      "Epoch 280/500-------------------\n",
      "Training Loss: 2.4924, Training Accuracy: 71.2880%\n",
      "Test Loss: 2.9953, Test Accuracy: 46.2893%\n",
      "Epoch 281/500-------------------\n",
      "Training Loss: 2.4853, Training Accuracy: 71.7050%\n",
      "Test Loss: 2.9910, Test Accuracy: 46.0649%\n",
      "Epoch 282/500-------------------\n",
      "Training Loss: 2.4840, Training Accuracy: 71.7885%\n",
      "Test Loss: 2.9901, Test Accuracy: 46.2893%\n",
      "Epoch 283/500-------------------\n",
      "Training Loss: 2.4807, Training Accuracy: 71.6216%\n",
      "Test Loss: 2.9887, Test Accuracy: 46.1339%\n",
      "Epoch 284/500-------------------\n",
      "Training Loss: 2.4751, Training Accuracy: 71.5382%\n",
      "Test Loss: 2.9855, Test Accuracy: 45.9959%\n",
      "Epoch 285/500-------------------\n",
      "Training Loss: 2.4750, Training Accuracy: 71.5549%\n",
      "Test Loss: 2.9851, Test Accuracy: 45.9959%\n",
      "Epoch 286/500-------------------\n",
      "Training Loss: 2.4690, Training Accuracy: 71.5883%\n",
      "Test Loss: 2.9808, Test Accuracy: 46.2030%\n",
      "Epoch 287/500-------------------\n",
      "Training Loss: 2.4683, Training Accuracy: 71.6216%\n",
      "Test Loss: 2.9820, Test Accuracy: 46.1339%\n",
      "Epoch 288/500-------------------\n",
      "Training Loss: 2.4649, Training Accuracy: 72.1722%\n",
      "Test Loss: 2.9805, Test Accuracy: 46.1857%\n",
      "Epoch 289/500-------------------\n",
      "Training Loss: 2.4592, Training Accuracy: 72.1221%\n",
      "Test Loss: 2.9760, Test Accuracy: 46.2720%\n",
      "Epoch 290/500-------------------\n",
      "Training Loss: 2.4598, Training Accuracy: 71.9887%\n",
      "Test Loss: 2.9764, Test Accuracy: 46.5309%\n",
      "Epoch 291/500-------------------\n",
      "Training Loss: 2.4536, Training Accuracy: 72.0721%\n",
      "Test Loss: 2.9746, Test Accuracy: 46.2720%\n",
      "Epoch 292/500-------------------\n",
      "Training Loss: 2.4549, Training Accuracy: 72.0387%\n",
      "Test Loss: 2.9767, Test Accuracy: 46.4101%\n",
      "Epoch 293/500-------------------\n",
      "Training Loss: 2.4518, Training Accuracy: 72.2055%\n",
      "Test Loss: 2.9730, Test Accuracy: 46.4964%\n",
      "Epoch 294/500-------------------\n",
      "Training Loss: 2.4455, Training Accuracy: 72.3056%\n",
      "Test Loss: 2.9693, Test Accuracy: 46.4964%\n",
      "Epoch 295/500-------------------\n",
      "Training Loss: 2.4374, Training Accuracy: 72.5058%\n",
      "Test Loss: 2.9638, Test Accuracy: 46.2202%\n",
      "Epoch 296/500-------------------\n",
      "Training Loss: 2.4377, Training Accuracy: 72.4224%\n",
      "Test Loss: 2.9649, Test Accuracy: 46.2202%\n",
      "Epoch 297/500-------------------\n",
      "Training Loss: 2.4331, Training Accuracy: 72.7728%\n",
      "Test Loss: 2.9628, Test Accuracy: 46.2030%\n",
      "Epoch 298/500-------------------\n",
      "Training Loss: 2.4270, Training Accuracy: 72.7561%\n",
      "Test Loss: 2.9590, Test Accuracy: 46.2202%\n",
      "Epoch 299/500-------------------\n",
      "Training Loss: 2.4230, Training Accuracy: 72.5225%\n",
      "Test Loss: 2.9562, Test Accuracy: 46.4619%\n",
      "Epoch 300/500-------------------\n",
      "Training Loss: 2.4232, Training Accuracy: 72.7227%\n",
      "Test Loss: 2.9562, Test Accuracy: 46.4101%\n",
      "Epoch 301/500-------------------\n",
      "Training Loss: 2.4208, Training Accuracy: 72.7227%\n",
      "Test Loss: 2.9547, Test Accuracy: 46.3928%\n",
      "Epoch 302/500-------------------\n",
      "Training Loss: 2.4197, Training Accuracy: 73.2399%\n",
      "Test Loss: 2.9549, Test Accuracy: 46.4446%\n",
      "Epoch 303/500-------------------\n",
      "Training Loss: 2.4144, Training Accuracy: 72.8228%\n",
      "Test Loss: 2.9523, Test Accuracy: 46.3065%\n",
      "Epoch 304/500-------------------\n",
      "Training Loss: 2.4076, Training Accuracy: 72.5392%\n",
      "Test Loss: 2.9470, Test Accuracy: 46.5136%\n",
      "Epoch 305/500-------------------\n",
      "Training Loss: 2.4073, Training Accuracy: 73.0063%\n",
      "Test Loss: 2.9486, Test Accuracy: 46.4791%\n",
      "Epoch 306/500-------------------\n",
      "Training Loss: 2.4011, Training Accuracy: 73.3567%\n",
      "Test Loss: 2.9443, Test Accuracy: 46.4791%\n",
      "Epoch 307/500-------------------\n",
      "Training Loss: 2.4015, Training Accuracy: 73.1732%\n",
      "Test Loss: 2.9456, Test Accuracy: 46.2030%\n",
      "Epoch 308/500-------------------\n",
      "Training Loss: 2.3946, Training Accuracy: 72.9897%\n",
      "Test Loss: 2.9407, Test Accuracy: 46.5654%\n",
      "Epoch 309/500-------------------\n",
      "Training Loss: 2.3917, Training Accuracy: 72.9897%\n",
      "Test Loss: 2.9393, Test Accuracy: 46.1512%\n",
      "Epoch 310/500-------------------\n",
      "Training Loss: 2.3876, Training Accuracy: 73.1398%\n",
      "Test Loss: 2.9361, Test Accuracy: 46.6172%\n",
      "Epoch 311/500-------------------\n",
      "Training Loss: 2.3883, Training Accuracy: 73.4234%\n",
      "Test Loss: 2.9382, Test Accuracy: 46.3065%\n",
      "Epoch 312/500-------------------\n",
      "Training Loss: 2.3834, Training Accuracy: 73.0731%\n",
      "Test Loss: 2.9338, Test Accuracy: 46.4446%\n",
      "Epoch 313/500-------------------\n",
      "Training Loss: 2.3839, Training Accuracy: 73.4902%\n",
      "Test Loss: 2.9357, Test Accuracy: 46.4791%\n",
      "Epoch 314/500-------------------\n",
      "Training Loss: 2.3770, Training Accuracy: 73.1732%\n",
      "Test Loss: 2.9320, Test Accuracy: 46.3583%\n",
      "Epoch 315/500-------------------\n",
      "Training Loss: 2.3667, Training Accuracy: 73.4902%\n",
      "Test Loss: 2.9243, Test Accuracy: 46.6690%\n",
      "Epoch 316/500-------------------\n",
      "Training Loss: 2.3740, Training Accuracy: 73.5736%\n",
      "Test Loss: 2.9307, Test Accuracy: 46.5827%\n",
      "Epoch 317/500-------------------\n",
      "Training Loss: 2.3657, Training Accuracy: 73.8572%\n",
      "Test Loss: 2.9249, Test Accuracy: 46.3756%\n",
      "Epoch 318/500-------------------\n",
      "Training Loss: 2.3618, Training Accuracy: 73.6737%\n",
      "Test Loss: 2.9237, Test Accuracy: 46.3410%\n",
      "Epoch 319/500-------------------\n",
      "Training Loss: 2.3593, Training Accuracy: 73.5402%\n",
      "Test Loss: 2.9222, Test Accuracy: 46.3756%\n",
      "Epoch 320/500-------------------\n",
      "Training Loss: 2.3635, Training Accuracy: 73.9072%\n",
      "Test Loss: 2.9261, Test Accuracy: 46.5654%\n",
      "Epoch 321/500-------------------\n",
      "Training Loss: 2.3600, Training Accuracy: 73.5736%\n",
      "Test Loss: 2.9239, Test Accuracy: 46.6344%\n",
      "Epoch 322/500-------------------\n",
      "Training Loss: 2.3506, Training Accuracy: 73.8572%\n",
      "Test Loss: 2.9172, Test Accuracy: 46.4446%\n",
      "Epoch 323/500-------------------\n",
      "Training Loss: 2.3431, Training Accuracy: 73.8405%\n",
      "Test Loss: 2.9121, Test Accuracy: 46.5654%\n",
      "Epoch 324/500-------------------\n",
      "Training Loss: 2.3453, Training Accuracy: 74.0908%\n",
      "Test Loss: 2.9136, Test Accuracy: 46.7207%\n",
      "Epoch 325/500-------------------\n",
      "Training Loss: 2.3400, Training Accuracy: 73.9406%\n",
      "Test Loss: 2.9108, Test Accuracy: 46.5827%\n",
      "Epoch 326/500-------------------\n",
      "Training Loss: 2.3382, Training Accuracy: 74.0741%\n",
      "Test Loss: 2.9096, Test Accuracy: 46.6690%\n",
      "Epoch 327/500-------------------\n",
      "Training Loss: 2.3386, Training Accuracy: 74.1909%\n",
      "Test Loss: 2.9108, Test Accuracy: 46.4101%\n",
      "Epoch 328/500-------------------\n",
      "Training Loss: 2.3357, Training Accuracy: 74.3076%\n",
      "Test Loss: 2.9102, Test Accuracy: 46.4791%\n",
      "Epoch 329/500-------------------\n",
      "Training Loss: 2.3265, Training Accuracy: 74.3410%\n",
      "Test Loss: 2.9035, Test Accuracy: 46.5827%\n",
      "Epoch 330/500-------------------\n",
      "Training Loss: 2.3282, Training Accuracy: 74.5078%\n",
      "Test Loss: 2.9051, Test Accuracy: 46.4273%\n",
      "Epoch 331/500-------------------\n",
      "Training Loss: 2.3227, Training Accuracy: 74.4745%\n",
      "Test Loss: 2.9021, Test Accuracy: 46.6862%\n",
      "Epoch 332/500-------------------\n",
      "Training Loss: 2.3198, Training Accuracy: 74.3911%\n",
      "Test Loss: 2.9012, Test Accuracy: 46.4446%\n",
      "Epoch 333/500-------------------\n",
      "Training Loss: 2.3141, Training Accuracy: 74.6914%\n",
      "Test Loss: 2.8955, Test Accuracy: 46.5482%\n",
      "Epoch 334/500-------------------\n",
      "Training Loss: 2.3065, Training Accuracy: 74.4578%\n",
      "Test Loss: 2.8920, Test Accuracy: 46.7898%\n",
      "Epoch 335/500-------------------\n",
      "Training Loss: 2.3077, Training Accuracy: 74.5245%\n",
      "Test Loss: 2.8937, Test Accuracy: 46.5827%\n",
      "Epoch 336/500-------------------\n",
      "Training Loss: 2.3023, Training Accuracy: 74.6747%\n",
      "Test Loss: 2.8899, Test Accuracy: 46.5136%\n",
      "Epoch 337/500-------------------\n",
      "Training Loss: 2.3038, Training Accuracy: 74.7080%\n",
      "Test Loss: 2.8923, Test Accuracy: 46.1339%\n",
      "Epoch 338/500-------------------\n",
      "Training Loss: 2.3044, Training Accuracy: 74.8248%\n",
      "Test Loss: 2.8926, Test Accuracy: 46.4101%\n",
      "Epoch 339/500-------------------\n",
      "Training Loss: 2.2961, Training Accuracy: 74.6246%\n",
      "Test Loss: 2.8875, Test Accuracy: 46.5999%\n",
      "Epoch 340/500-------------------\n",
      "Training Loss: 2.2968, Training Accuracy: 74.6914%\n",
      "Test Loss: 2.8894, Test Accuracy: 46.5827%\n",
      "Epoch 341/500-------------------\n",
      "Training Loss: 2.2919, Training Accuracy: 74.9416%\n",
      "Test Loss: 2.8863, Test Accuracy: 46.7380%\n",
      "Epoch 342/500-------------------\n",
      "Training Loss: 2.2842, Training Accuracy: 74.9416%\n",
      "Test Loss: 2.8818, Test Accuracy: 46.5999%\n",
      "Epoch 343/500-------------------\n",
      "Training Loss: 2.2811, Training Accuracy: 74.9416%\n",
      "Test Loss: 2.8799, Test Accuracy: 46.4619%\n",
      "Epoch 344/500-------------------\n",
      "Training Loss: 2.2815, Training Accuracy: 75.2252%\n",
      "Test Loss: 2.8795, Test Accuracy: 46.9969%\n",
      "Epoch 345/500-------------------\n",
      "Training Loss: 2.2772, Training Accuracy: 75.2252%\n",
      "Test Loss: 2.8770, Test Accuracy: 46.9451%\n",
      "Epoch 346/500-------------------\n",
      "Training Loss: 2.2750, Training Accuracy: 75.3420%\n",
      "Test Loss: 2.8755, Test Accuracy: 46.9451%\n",
      "Epoch 347/500-------------------\n",
      "Training Loss: 2.2716, Training Accuracy: 75.5422%\n",
      "Test Loss: 2.8741, Test Accuracy: 46.7898%\n",
      "Epoch 348/500-------------------\n",
      "Training Loss: 2.2676, Training Accuracy: 75.4922%\n",
      "Test Loss: 2.8714, Test Accuracy: 47.0142%\n",
      "Epoch 349/500-------------------\n",
      "Training Loss: 2.2701, Training Accuracy: 75.5756%\n",
      "Test Loss: 2.8736, Test Accuracy: 46.5482%\n",
      "Epoch 350/500-------------------\n",
      "Training Loss: 2.2669, Training Accuracy: 75.6256%\n",
      "Test Loss: 2.8719, Test Accuracy: 46.8761%\n",
      "Epoch 351/500-------------------\n",
      "Training Loss: 2.2650, Training Accuracy: 75.4254%\n",
      "Test Loss: 2.8725, Test Accuracy: 46.9796%\n",
      "Epoch 352/500-------------------\n",
      "Training Loss: 2.2648, Training Accuracy: 75.7090%\n",
      "Test Loss: 2.8731, Test Accuracy: 46.7207%\n",
      "Epoch 353/500-------------------\n",
      "Training Loss: 2.2603, Training Accuracy: 75.6924%\n",
      "Test Loss: 2.8712, Test Accuracy: 46.9279%\n",
      "Epoch 354/500-------------------\n",
      "Training Loss: 2.2566, Training Accuracy: 76.0093%\n",
      "Test Loss: 2.8689, Test Accuracy: 46.9451%\n",
      "Epoch 355/500-------------------\n",
      "Training Loss: 2.2494, Training Accuracy: 75.5756%\n",
      "Test Loss: 2.8648, Test Accuracy: 46.7553%\n",
      "Epoch 356/500-------------------\n",
      "Training Loss: 2.2451, Training Accuracy: 75.6590%\n",
      "Test Loss: 2.8607, Test Accuracy: 46.8933%\n",
      "Epoch 357/500-------------------\n",
      "Training Loss: 2.2454, Training Accuracy: 75.9092%\n",
      "Test Loss: 2.8619, Test Accuracy: 47.1867%\n",
      "Epoch 358/500-------------------\n",
      "Training Loss: 2.2460, Training Accuracy: 76.0093%\n",
      "Test Loss: 2.8628, Test Accuracy: 46.8070%\n",
      "Epoch 359/500-------------------\n",
      "Training Loss: 2.2416, Training Accuracy: 75.7424%\n",
      "Test Loss: 2.8598, Test Accuracy: 46.7380%\n",
      "Epoch 360/500-------------------\n",
      "Training Loss: 2.2369, Training Accuracy: 75.8759%\n",
      "Test Loss: 2.8563, Test Accuracy: 46.7035%\n",
      "Epoch 361/500-------------------\n",
      "Training Loss: 2.2336, Training Accuracy: 76.2763%\n",
      "Test Loss: 2.8554, Test Accuracy: 46.4964%\n",
      "Epoch 362/500-------------------\n",
      "Training Loss: 2.2285, Training Accuracy: 76.2095%\n",
      "Test Loss: 2.8518, Test Accuracy: 46.7035%\n",
      "Epoch 363/500-------------------\n",
      "Training Loss: 2.2262, Training Accuracy: 76.3931%\n",
      "Test Loss: 2.8504, Test Accuracy: 46.6690%\n",
      "Epoch 364/500-------------------\n",
      "Training Loss: 2.2263, Training Accuracy: 76.2596%\n",
      "Test Loss: 2.8504, Test Accuracy: 46.9279%\n",
      "Epoch 365/500-------------------\n",
      "Training Loss: 2.2194, Training Accuracy: 76.3430%\n",
      "Test Loss: 2.8475, Test Accuracy: 46.7207%\n",
      "Epoch 366/500-------------------\n",
      "Training Loss: 2.2164, Training Accuracy: 76.1595%\n",
      "Test Loss: 2.8460, Test Accuracy: 46.6862%\n",
      "Epoch 367/500-------------------\n",
      "Training Loss: 2.2193, Training Accuracy: 76.5599%\n",
      "Test Loss: 2.8488, Test Accuracy: 46.6690%\n",
      "Epoch 368/500-------------------\n",
      "Training Loss: 2.2105, Training Accuracy: 76.3597%\n",
      "Test Loss: 2.8428, Test Accuracy: 46.7725%\n",
      "Epoch 369/500-------------------\n",
      "Training Loss: 2.2065, Training Accuracy: 76.3764%\n",
      "Test Loss: 2.8399, Test Accuracy: 46.9624%\n",
      "Epoch 370/500-------------------\n",
      "Training Loss: 2.2098, Training Accuracy: 76.8435%\n",
      "Test Loss: 2.8436, Test Accuracy: 46.9451%\n",
      "Epoch 371/500-------------------\n",
      "Training Loss: 2.2083, Training Accuracy: 76.7267%\n",
      "Test Loss: 2.8428, Test Accuracy: 47.0142%\n",
      "Epoch 372/500-------------------\n",
      "Training Loss: 2.2036, Training Accuracy: 76.9269%\n",
      "Test Loss: 2.8396, Test Accuracy: 46.8588%\n",
      "Epoch 373/500-------------------\n",
      "Training Loss: 2.2016, Training Accuracy: 76.7434%\n",
      "Test Loss: 2.8403, Test Accuracy: 46.7898%\n",
      "Epoch 374/500-------------------\n",
      "Training Loss: 2.1978, Training Accuracy: 77.0437%\n",
      "Test Loss: 2.8370, Test Accuracy: 46.8588%\n",
      "Epoch 375/500-------------------\n",
      "Training Loss: 2.1909, Training Accuracy: 77.0437%\n",
      "Test Loss: 2.8322, Test Accuracy: 47.0314%\n",
      "Epoch 376/500-------------------\n",
      "Training Loss: 2.1890, Training Accuracy: 76.9102%\n",
      "Test Loss: 2.8320, Test Accuracy: 46.9106%\n",
      "Epoch 377/500-------------------\n",
      "Training Loss: 2.1946, Training Accuracy: 77.0604%\n",
      "Test Loss: 2.8376, Test Accuracy: 47.0314%\n",
      "Epoch 378/500-------------------\n",
      "Training Loss: 2.1908, Training Accuracy: 77.0103%\n",
      "Test Loss: 2.8348, Test Accuracy: 46.7898%\n",
      "Epoch 379/500-------------------\n",
      "Training Loss: 2.1836, Training Accuracy: 77.0103%\n",
      "Test Loss: 2.8301, Test Accuracy: 46.8933%\n",
      "Epoch 380/500-------------------\n",
      "Training Loss: 2.1832, Training Accuracy: 77.0437%\n",
      "Test Loss: 2.8308, Test Accuracy: 47.0487%\n",
      "Epoch 381/500-------------------\n",
      "Training Loss: 2.1826, Training Accuracy: 77.1772%\n",
      "Test Loss: 2.8308, Test Accuracy: 46.9796%\n",
      "Epoch 382/500-------------------\n",
      "Training Loss: 2.1809, Training Accuracy: 77.1772%\n",
      "Test Loss: 2.8297, Test Accuracy: 47.0487%\n",
      "Epoch 383/500-------------------\n",
      "Training Loss: 2.1757, Training Accuracy: 77.2272%\n",
      "Test Loss: 2.8277, Test Accuracy: 46.9624%\n",
      "Epoch 384/500-------------------\n",
      "Training Loss: 2.1727, Training Accuracy: 77.5275%\n",
      "Test Loss: 2.8249, Test Accuracy: 47.0487%\n",
      "Epoch 385/500-------------------\n",
      "Training Loss: 2.1732, Training Accuracy: 77.3106%\n",
      "Test Loss: 2.8275, Test Accuracy: 46.9969%\n",
      "Epoch 386/500-------------------\n",
      "Training Loss: 2.1680, Training Accuracy: 77.2105%\n",
      "Test Loss: 2.8239, Test Accuracy: 46.9624%\n",
      "Epoch 387/500-------------------\n",
      "Training Loss: 2.1574, Training Accuracy: 77.8111%\n",
      "Test Loss: 2.8164, Test Accuracy: 47.0314%\n",
      "Epoch 388/500-------------------\n",
      "Training Loss: 2.1592, Training Accuracy: 77.5275%\n",
      "Test Loss: 2.8188, Test Accuracy: 46.9796%\n",
      "Epoch 389/500-------------------\n",
      "Training Loss: 2.1542, Training Accuracy: 77.7444%\n",
      "Test Loss: 2.8158, Test Accuracy: 47.2385%\n",
      "Epoch 390/500-------------------\n",
      "Training Loss: 2.1515, Training Accuracy: 77.6276%\n",
      "Test Loss: 2.8149, Test Accuracy: 47.3593%\n",
      "Epoch 391/500-------------------\n",
      "Training Loss: 2.1510, Training Accuracy: 77.6443%\n",
      "Test Loss: 2.8143, Test Accuracy: 47.2040%\n",
      "Epoch 392/500-------------------\n",
      "Training Loss: 2.1475, Training Accuracy: 77.8445%\n",
      "Test Loss: 2.8115, Test Accuracy: 47.3076%\n",
      "Epoch 393/500-------------------\n",
      "Training Loss: 2.1496, Training Accuracy: 77.7277%\n",
      "Test Loss: 2.8144, Test Accuracy: 46.7898%\n",
      "Epoch 394/500-------------------\n",
      "Training Loss: 2.1435, Training Accuracy: 77.5275%\n",
      "Test Loss: 2.8109, Test Accuracy: 47.0142%\n",
      "Epoch 395/500-------------------\n",
      "Training Loss: 2.1440, Training Accuracy: 77.7277%\n",
      "Test Loss: 2.8137, Test Accuracy: 47.0832%\n",
      "Epoch 396/500-------------------\n",
      "Training Loss: 2.1382, Training Accuracy: 77.9279%\n",
      "Test Loss: 2.8089, Test Accuracy: 47.2213%\n",
      "Epoch 397/500-------------------\n",
      "Training Loss: 2.1379, Training Accuracy: 77.9279%\n",
      "Test Loss: 2.8096, Test Accuracy: 47.1350%\n",
      "Epoch 398/500-------------------\n",
      "Training Loss: 2.1369, Training Accuracy: 78.0948%\n",
      "Test Loss: 2.8086, Test Accuracy: 47.2385%\n",
      "Epoch 399/500-------------------\n",
      "Training Loss: 2.1294, Training Accuracy: 77.6944%\n",
      "Test Loss: 2.8026, Test Accuracy: 47.1867%\n",
      "Epoch 400/500-------------------\n",
      "Training Loss: 2.1260, Training Accuracy: 78.0113%\n",
      "Test Loss: 2.8026, Test Accuracy: 47.0659%\n",
      "Epoch 401/500-------------------\n",
      "Training Loss: 2.1299, Training Accuracy: 78.1114%\n",
      "Test Loss: 2.8043, Test Accuracy: 47.1350%\n",
      "Epoch 402/500-------------------\n",
      "Training Loss: 2.1245, Training Accuracy: 78.0781%\n",
      "Test Loss: 2.8011, Test Accuracy: 47.2903%\n",
      "Epoch 403/500-------------------\n",
      "Training Loss: 2.1239, Training Accuracy: 78.1615%\n",
      "Test Loss: 2.8023, Test Accuracy: 47.1522%\n",
      "Epoch 404/500-------------------\n",
      "Training Loss: 2.1184, Training Accuracy: 78.1615%\n",
      "Test Loss: 2.7986, Test Accuracy: 47.2730%\n",
      "Epoch 405/500-------------------\n",
      "Training Loss: 2.1172, Training Accuracy: 78.3617%\n",
      "Test Loss: 2.7982, Test Accuracy: 47.3766%\n",
      "Epoch 406/500-------------------\n",
      "Training Loss: 2.1163, Training Accuracy: 78.4618%\n",
      "Test Loss: 2.7987, Test Accuracy: 47.2385%\n",
      "Epoch 407/500-------------------\n",
      "Training Loss: 2.1126, Training Accuracy: 78.2950%\n",
      "Test Loss: 2.7957, Test Accuracy: 47.2213%\n",
      "Epoch 408/500-------------------\n",
      "Training Loss: 2.1068, Training Accuracy: 78.4284%\n",
      "Test Loss: 2.7911, Test Accuracy: 47.1867%\n",
      "Epoch 409/500-------------------\n",
      "Training Loss: 2.1018, Training Accuracy: 78.6286%\n",
      "Test Loss: 2.7900, Test Accuracy: 47.6527%\n",
      "Epoch 410/500-------------------\n",
      "Training Loss: 2.1009, Training Accuracy: 78.6954%\n",
      "Test Loss: 2.7899, Test Accuracy: 47.0659%\n",
      "Epoch 411/500-------------------\n",
      "Training Loss: 2.0997, Training Accuracy: 78.4284%\n",
      "Test Loss: 2.7893, Test Accuracy: 47.2558%\n",
      "Epoch 412/500-------------------\n",
      "Training Loss: 2.0968, Training Accuracy: 78.6787%\n",
      "Test Loss: 2.7875, Test Accuracy: 47.3248%\n",
      "Epoch 413/500-------------------\n",
      "Training Loss: 2.1021, Training Accuracy: 78.7287%\n",
      "Test Loss: 2.7935, Test Accuracy: 47.2558%\n",
      "Epoch 414/500-------------------\n",
      "Training Loss: 2.0955, Training Accuracy: 79.0791%\n",
      "Test Loss: 2.7874, Test Accuracy: 47.1350%\n",
      "Epoch 415/500-------------------\n",
      "Training Loss: 2.0891, Training Accuracy: 78.7955%\n",
      "Test Loss: 2.7832, Test Accuracy: 46.9796%\n",
      "Epoch 416/500-------------------\n",
      "Training Loss: 2.0921, Training Accuracy: 78.8455%\n",
      "Test Loss: 2.7864, Test Accuracy: 47.1177%\n",
      "Epoch 417/500-------------------\n",
      "Training Loss: 2.0950, Training Accuracy: 78.6453%\n",
      "Test Loss: 2.7895, Test Accuracy: 46.7553%\n",
      "Epoch 418/500-------------------\n",
      "Training Loss: 2.0885, Training Accuracy: 78.8622%\n",
      "Test Loss: 2.7858, Test Accuracy: 46.8761%\n",
      "Epoch 419/500-------------------\n",
      "Training Loss: 2.0849, Training Accuracy: 78.8455%\n",
      "Test Loss: 2.7833, Test Accuracy: 47.5147%\n",
      "Epoch 420/500-------------------\n",
      "Training Loss: 2.0802, Training Accuracy: 79.1792%\n",
      "Test Loss: 2.7808, Test Accuracy: 47.6873%\n",
      "Epoch 421/500-------------------\n",
      "Training Loss: 2.0766, Training Accuracy: 79.0624%\n",
      "Test Loss: 2.7788, Test Accuracy: 47.3248%\n",
      "Epoch 422/500-------------------\n",
      "Training Loss: 2.0726, Training Accuracy: 79.2960%\n",
      "Test Loss: 2.7752, Test Accuracy: 47.4629%\n",
      "Epoch 423/500-------------------\n",
      "Training Loss: 2.0722, Training Accuracy: 79.3794%\n",
      "Test Loss: 2.7768, Test Accuracy: 47.3939%\n",
      "Epoch 424/500-------------------\n",
      "Training Loss: 2.0669, Training Accuracy: 79.1625%\n",
      "Test Loss: 2.7739, Test Accuracy: 47.4111%\n",
      "Epoch 425/500-------------------\n",
      "Training Loss: 2.0667, Training Accuracy: 79.4628%\n",
      "Test Loss: 2.7730, Test Accuracy: 47.2213%\n",
      "Epoch 426/500-------------------\n",
      "Training Loss: 2.0626, Training Accuracy: 79.1959%\n",
      "Test Loss: 2.7723, Test Accuracy: 47.3421%\n",
      "Epoch 427/500-------------------\n",
      "Training Loss: 2.0588, Training Accuracy: 79.4461%\n",
      "Test Loss: 2.7700, Test Accuracy: 47.3076%\n",
      "Epoch 428/500-------------------\n",
      "Training Loss: 2.0573, Training Accuracy: 79.3627%\n",
      "Test Loss: 2.7703, Test Accuracy: 47.1867%\n",
      "Epoch 429/500-------------------\n",
      "Training Loss: 2.0596, Training Accuracy: 79.3627%\n",
      "Test Loss: 2.7718, Test Accuracy: 47.1350%\n",
      "Epoch 430/500-------------------\n",
      "Training Loss: 2.0539, Training Accuracy: 79.3126%\n",
      "Test Loss: 2.7684, Test Accuracy: 47.1350%\n",
      "Epoch 431/500-------------------\n",
      "Training Loss: 2.0507, Training Accuracy: 79.3627%\n",
      "Test Loss: 2.7671, Test Accuracy: 47.2730%\n",
      "Epoch 432/500-------------------\n",
      "Training Loss: 2.0506, Training Accuracy: 79.4962%\n",
      "Test Loss: 2.7669, Test Accuracy: 47.1522%\n",
      "Epoch 433/500-------------------\n",
      "Training Loss: 2.0504, Training Accuracy: 79.6129%\n",
      "Test Loss: 2.7656, Test Accuracy: 46.9624%\n",
      "Epoch 434/500-------------------\n",
      "Training Loss: 2.0451, Training Accuracy: 79.3794%\n",
      "Test Loss: 2.7619, Test Accuracy: 47.1695%\n",
      "Epoch 435/500-------------------\n",
      "Training Loss: 2.0463, Training Accuracy: 79.4127%\n",
      "Test Loss: 2.7636, Test Accuracy: 47.1177%\n",
      "Epoch 436/500-------------------\n",
      "Training Loss: 2.0453, Training Accuracy: 79.5963%\n",
      "Test Loss: 2.7640, Test Accuracy: 47.0832%\n",
      "Epoch 437/500-------------------\n",
      "Training Loss: 2.0445, Training Accuracy: 79.9132%\n",
      "Test Loss: 2.7652, Test Accuracy: 47.3939%\n",
      "Epoch 438/500-------------------\n",
      "Training Loss: 2.0400, Training Accuracy: 80.1468%\n",
      "Test Loss: 2.7625, Test Accuracy: 47.4284%\n",
      "Epoch 439/500-------------------\n",
      "Training Loss: 2.0392, Training Accuracy: 79.9466%\n",
      "Test Loss: 2.7625, Test Accuracy: 47.2558%\n",
      "Epoch 440/500-------------------\n",
      "Training Loss: 2.0305, Training Accuracy: 80.0634%\n",
      "Test Loss: 2.7569, Test Accuracy: 47.5147%\n",
      "Epoch 441/500-------------------\n",
      "Training Loss: 2.0337, Training Accuracy: 80.2469%\n",
      "Test Loss: 2.7596, Test Accuracy: 47.4629%\n",
      "Epoch 442/500-------------------\n",
      "Training Loss: 2.0233, Training Accuracy: 80.0300%\n",
      "Test Loss: 2.7531, Test Accuracy: 46.9969%\n",
      "Epoch 443/500-------------------\n",
      "Training Loss: 2.0174, Training Accuracy: 79.9132%\n",
      "Test Loss: 2.7478, Test Accuracy: 47.1177%\n",
      "Epoch 444/500-------------------\n",
      "Training Loss: 2.0127, Training Accuracy: 80.2636%\n",
      "Test Loss: 2.7460, Test Accuracy: 47.4629%\n",
      "Epoch 445/500-------------------\n",
      "Training Loss: 2.0117, Training Accuracy: 80.1301%\n",
      "Test Loss: 2.7455, Test Accuracy: 47.3421%\n",
      "Epoch 446/500-------------------\n",
      "Training Loss: 2.0073, Training Accuracy: 80.2803%\n",
      "Test Loss: 2.7450, Test Accuracy: 47.2385%\n",
      "Epoch 447/500-------------------\n",
      "Training Loss: 2.0037, Training Accuracy: 80.2803%\n",
      "Test Loss: 2.7435, Test Accuracy: 47.0832%\n",
      "Epoch 448/500-------------------\n",
      "Training Loss: 2.0035, Training Accuracy: 80.1134%\n",
      "Test Loss: 2.7414, Test Accuracy: 47.3939%\n",
      "Epoch 449/500-------------------\n",
      "Training Loss: 2.0013, Training Accuracy: 80.0133%\n",
      "Test Loss: 2.7406, Test Accuracy: 47.5147%\n",
      "Epoch 450/500-------------------\n",
      "Training Loss: 2.0069, Training Accuracy: 80.1301%\n",
      "Test Loss: 2.7459, Test Accuracy: 47.3766%\n",
      "Epoch 451/500-------------------\n",
      "Training Loss: 2.0008, Training Accuracy: 80.3470%\n",
      "Test Loss: 2.7428, Test Accuracy: 47.2558%\n",
      "Epoch 452/500-------------------\n",
      "Training Loss: 2.0032, Training Accuracy: 80.2302%\n",
      "Test Loss: 2.7446, Test Accuracy: 47.4456%\n",
      "Epoch 453/500-------------------\n",
      "Training Loss: 1.9994, Training Accuracy: 80.4137%\n",
      "Test Loss: 2.7422, Test Accuracy: 47.3593%\n",
      "Epoch 454/500-------------------\n",
      "Training Loss: 2.0014, Training Accuracy: 80.4972%\n",
      "Test Loss: 2.7447, Test Accuracy: 47.3421%\n",
      "Epoch 455/500-------------------\n",
      "Training Loss: 2.0000, Training Accuracy: 80.4805%\n",
      "Test Loss: 2.7433, Test Accuracy: 47.0832%\n",
      "Epoch 456/500-------------------\n",
      "Training Loss: 1.9913, Training Accuracy: 80.6640%\n",
      "Test Loss: 2.7374, Test Accuracy: 47.7736%\n",
      "Epoch 457/500-------------------\n",
      "Training Loss: 1.9970, Training Accuracy: 80.7307%\n",
      "Test Loss: 2.7440, Test Accuracy: 47.5837%\n",
      "Epoch 458/500-------------------\n",
      "Training Loss: 1.9867, Training Accuracy: 80.6974%\n",
      "Test Loss: 2.7353, Test Accuracy: 47.4802%\n",
      "Epoch 459/500-------------------\n",
      "Training Loss: 1.9868, Training Accuracy: 80.7975%\n",
      "Test Loss: 2.7357, Test Accuracy: 47.2558%\n",
      "Epoch 460/500-------------------\n",
      "Training Loss: 1.9874, Training Accuracy: 81.0477%\n",
      "Test Loss: 2.7382, Test Accuracy: 47.1177%\n",
      "Epoch 461/500-------------------\n",
      "Training Loss: 1.9819, Training Accuracy: 80.6640%\n",
      "Test Loss: 2.7362, Test Accuracy: 47.0832%\n",
      "Epoch 462/500-------------------\n",
      "Training Loss: 1.9754, Training Accuracy: 80.6306%\n",
      "Test Loss: 2.7308, Test Accuracy: 47.0659%\n",
      "Epoch 463/500-------------------\n",
      "Training Loss: 1.9760, Training Accuracy: 80.9810%\n",
      "Test Loss: 2.7324, Test Accuracy: 47.1350%\n",
      "Epoch 464/500-------------------\n",
      "Training Loss: 1.9794, Training Accuracy: 80.9810%\n",
      "Test Loss: 2.7349, Test Accuracy: 47.5837%\n",
      "Epoch 465/500-------------------\n",
      "Training Loss: 1.9730, Training Accuracy: 80.9643%\n",
      "Test Loss: 2.7310, Test Accuracy: 47.4111%\n",
      "Epoch 466/500-------------------\n",
      "Training Loss: 1.9752, Training Accuracy: 81.0143%\n",
      "Test Loss: 2.7330, Test Accuracy: 47.3076%\n",
      "Epoch 467/500-------------------\n",
      "Training Loss: 1.9673, Training Accuracy: 81.1144%\n",
      "Test Loss: 2.7284, Test Accuracy: 47.3421%\n",
      "Epoch 468/500-------------------\n",
      "Training Loss: 1.9748, Training Accuracy: 81.0310%\n",
      "Test Loss: 2.7354, Test Accuracy: 47.2385%\n",
      "Epoch 469/500-------------------\n",
      "Training Loss: 1.9735, Training Accuracy: 81.1812%\n",
      "Test Loss: 2.7353, Test Accuracy: 47.2903%\n",
      "Epoch 470/500-------------------\n",
      "Training Loss: 1.9672, Training Accuracy: 81.1311%\n",
      "Test Loss: 2.7309, Test Accuracy: 47.3593%\n",
      "Epoch 471/500-------------------\n",
      "Training Loss: 1.9647, Training Accuracy: 81.2813%\n",
      "Test Loss: 2.7309, Test Accuracy: 47.4974%\n",
      "Epoch 472/500-------------------\n",
      "Training Loss: 1.9651, Training Accuracy: 81.1478%\n",
      "Test Loss: 2.7323, Test Accuracy: 47.1867%\n",
      "Epoch 473/500-------------------\n",
      "Training Loss: 1.9527, Training Accuracy: 81.1144%\n",
      "Test Loss: 2.7223, Test Accuracy: 47.2730%\n",
      "Epoch 474/500-------------------\n",
      "Training Loss: 1.9516, Training Accuracy: 81.3146%\n",
      "Test Loss: 2.7219, Test Accuracy: 47.3076%\n",
      "Epoch 475/500-------------------\n",
      "Training Loss: 1.9513, Training Accuracy: 81.3146%\n",
      "Test Loss: 2.7215, Test Accuracy: 47.2385%\n",
      "Epoch 476/500-------------------\n",
      "Training Loss: 1.9496, Training Accuracy: 81.3981%\n",
      "Test Loss: 2.7225, Test Accuracy: 47.2730%\n",
      "Epoch 477/500-------------------\n",
      "Training Loss: 1.9428, Training Accuracy: 81.2980%\n",
      "Test Loss: 2.7163, Test Accuracy: 46.9969%\n",
      "Epoch 478/500-------------------\n",
      "Training Loss: 1.9480, Training Accuracy: 81.5983%\n",
      "Test Loss: 2.7205, Test Accuracy: 47.2558%\n",
      "Epoch 479/500-------------------\n",
      "Training Loss: 1.9449, Training Accuracy: 81.5148%\n",
      "Test Loss: 2.7204, Test Accuracy: 47.1867%\n",
      "Epoch 480/500-------------------\n",
      "Training Loss: 1.9432, Training Accuracy: 81.3814%\n",
      "Test Loss: 2.7186, Test Accuracy: 47.1350%\n",
      "Epoch 481/500-------------------\n",
      "Training Loss: 1.9395, Training Accuracy: 81.5983%\n",
      "Test Loss: 2.7164, Test Accuracy: 47.1522%\n",
      "Epoch 482/500-------------------\n",
      "Training Loss: 1.9405, Training Accuracy: 81.8318%\n",
      "Test Loss: 2.7183, Test Accuracy: 47.3421%\n",
      "Epoch 483/500-------------------\n",
      "Training Loss: 1.9357, Training Accuracy: 81.7317%\n",
      "Test Loss: 2.7157, Test Accuracy: 47.2213%\n",
      "Epoch 484/500-------------------\n",
      "Training Loss: 1.9367, Training Accuracy: 81.8151%\n",
      "Test Loss: 2.7172, Test Accuracy: 47.2213%\n",
      "Epoch 485/500-------------------\n",
      "Training Loss: 1.9300, Training Accuracy: 82.0320%\n",
      "Test Loss: 2.7139, Test Accuracy: 47.3076%\n",
      "Epoch 486/500-------------------\n",
      "Training Loss: 1.9266, Training Accuracy: 82.0320%\n",
      "Test Loss: 2.7111, Test Accuracy: 47.5319%\n",
      "Epoch 487/500-------------------\n",
      "Training Loss: 1.9247, Training Accuracy: 82.0153%\n",
      "Test Loss: 2.7105, Test Accuracy: 47.4111%\n",
      "Epoch 488/500-------------------\n",
      "Training Loss: 1.9236, Training Accuracy: 81.9152%\n",
      "Test Loss: 2.7096, Test Accuracy: 47.6010%\n",
      "Epoch 489/500-------------------\n",
      "Training Loss: 1.9290, Training Accuracy: 82.2155%\n",
      "Test Loss: 2.7149, Test Accuracy: 47.7045%\n",
      "Epoch 490/500-------------------\n",
      "Training Loss: 1.9256, Training Accuracy: 81.9820%\n",
      "Test Loss: 2.7129, Test Accuracy: 47.6700%\n",
      "Epoch 491/500-------------------\n",
      "Training Loss: 1.9239, Training Accuracy: 81.8485%\n",
      "Test Loss: 2.7119, Test Accuracy: 47.4629%\n",
      "Epoch 492/500-------------------\n",
      "Training Loss: 1.9146, Training Accuracy: 82.1488%\n",
      "Test Loss: 2.7065, Test Accuracy: 47.5492%\n",
      "Epoch 493/500-------------------\n",
      "Training Loss: 1.9211, Training Accuracy: 81.9653%\n",
      "Test Loss: 2.7114, Test Accuracy: 47.5664%\n",
      "Epoch 494/500-------------------\n",
      "Training Loss: 1.9212, Training Accuracy: 81.9319%\n",
      "Test Loss: 2.7113, Test Accuracy: 47.3421%\n",
      "Epoch 495/500-------------------\n",
      "Training Loss: 1.9145, Training Accuracy: 82.2990%\n",
      "Test Loss: 2.7081, Test Accuracy: 47.1522%\n",
      "Epoch 496/500-------------------\n",
      "Training Loss: 1.9126, Training Accuracy: 82.1488%\n",
      "Test Loss: 2.7069, Test Accuracy: 47.4456%\n",
      "Epoch 497/500-------------------\n",
      "Training Loss: 1.9065, Training Accuracy: 82.2656%\n",
      "Test Loss: 2.7030, Test Accuracy: 47.6355%\n",
      "Epoch 498/500-------------------\n",
      "Training Loss: 1.9003, Training Accuracy: 82.1822%\n",
      "Test Loss: 2.6989, Test Accuracy: 47.3421%\n",
      "Epoch 499/500-------------------\n",
      "Training Loss: 1.9020, Training Accuracy: 82.0654%\n",
      "Test Loss: 2.7007, Test Accuracy: 47.2385%\n",
      "Epoch 500/500-------------------\n",
      "Training Loss: 1.8977, Training Accuracy: 82.0153%\n",
      "Test Loss: 2.6977, Test Accuracy: 47.3076%\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}-------------------\")\n",
    "\n",
    "    train(model, training_dataloader, loss_fn, optimizer, device)\n",
    "\n",
    "    training_loss, training_acc = test(model, training_dataloader, loss_fn, device)\n",
    "    print(\n",
    "        f\"Training Loss: {training_loss:.4f}, Training Accuracy: {100 * training_acc:>0.4f}%\"\n",
    "    )\n",
    "\n",
    "    test_loss, test_acc = test(model, test_dataloader, loss_fn, device)\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {100 * test_acc:>0.4f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d4040fe446a930194e7f49e706fe5ca82fc3ae21142ec3efeed3554a6698e7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
