{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.concept_bottleneck.dataset import (\n",
    "    CUB200AttributesToClass,\n",
    "    NUM_ATTRIBUTES,\n",
    "    NUM_CLASSES,\n",
    ")\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "training_data = CUB200AttributesToClass(train=True)\n",
    "test_data = CUB200AttributesToClass(train=False)\n",
    "\n",
    "training_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from src.concept_bottleneck.networks import get_mlp\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = get_mlp().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.typing as npt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: DataLoader[tuple[npt.NDArray[np.float32], np.int_]],\n",
    "    loss_fn: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: str,\n",
    "):\n",
    "    model.train()\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: DataLoader[tuple[npt.NDArray[np.float32], np.int_]],\n",
    "    loss_fn: torch.nn.Module,\n",
    "    device: str,\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            test_loss += loss_fn(logits, y).item()\n",
    "            correct += (logits.argmax(dim=1) == y).sum().item()\n",
    "\n",
    "    test_loss /= len(dataloader)\n",
    "    accuracy = correct / len(dataloader.dataset)  # type: ignore\n",
    "\n",
    "    return test_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100-------------------\n",
      "Training Loss: 4.8809, Training Accuracy: 18.6019%\n",
      "Test Loss: 4.9268, Test Accuracy: 15.0673%\n",
      "Saving model to attributes-to-class.pth with accuracy 15.0673%\n",
      "Epoch 2/100-------------------\n",
      "Training Loss: 4.5035, Training Accuracy: 32.1655%\n",
      "Test Loss: 4.5937, Test Accuracy: 23.9731%\n",
      "Saving model to attributes-to-class.pth with accuracy 23.9731%\n",
      "Epoch 3/100-------------------\n",
      "Training Loss: 4.1775, Training Accuracy: 38.8722%\n",
      "Test Loss: 4.3097, Test Accuracy: 29.0645%\n",
      "Saving model to attributes-to-class.pth with accuracy 29.0645%\n",
      "Epoch 4/100-------------------\n",
      "Training Loss: 3.8949, Training Accuracy: 43.1431%\n",
      "Test Loss: 4.0673, Test Accuracy: 32.8098%\n",
      "Saving model to attributes-to-class.pth with accuracy 32.8098%\n",
      "Epoch 5/100-------------------\n",
      "Training Loss: 3.6495, Training Accuracy: 46.8468%\n",
      "Test Loss: 3.8601, Test Accuracy: 35.2434%\n",
      "Saving model to attributes-to-class.pth with accuracy 35.2434%\n",
      "Epoch 6/100-------------------\n",
      "Training Loss: 3.4352, Training Accuracy: 50.4004%\n",
      "Test Loss: 3.6812, Test Accuracy: 37.6769%\n",
      "Saving model to attributes-to-class.pth with accuracy 37.6769%\n",
      "Epoch 7/100-------------------\n",
      "Training Loss: 3.2476, Training Accuracy: 52.7528%\n",
      "Test Loss: 3.5270, Test Accuracy: 38.9886%\n",
      "Saving model to attributes-to-class.pth with accuracy 38.9886%\n",
      "Epoch 8/100-------------------\n",
      "Training Loss: 3.0819, Training Accuracy: 54.7381%\n",
      "Test Loss: 3.3923, Test Accuracy: 40.5937%\n",
      "Saving model to attributes-to-class.pth with accuracy 40.5937%\n",
      "Epoch 9/100-------------------\n",
      "Training Loss: 2.9366, Training Accuracy: 56.3230%\n",
      "Test Loss: 3.2751, Test Accuracy: 41.8019%\n",
      "Saving model to attributes-to-class.pth with accuracy 41.8019%\n",
      "Epoch 10/100-------------------\n",
      "Training Loss: 2.8071, Training Accuracy: 57.3907%\n",
      "Test Loss: 3.1721, Test Accuracy: 42.2161%\n",
      "Saving model to attributes-to-class.pth with accuracy 42.2161%\n",
      "Epoch 11/100-------------------\n",
      "Training Loss: 2.6909, Training Accuracy: 58.6753%\n",
      "Test Loss: 3.0812, Test Accuracy: 43.2344%\n",
      "Saving model to attributes-to-class.pth with accuracy 43.2344%\n",
      "Epoch 12/100-------------------\n",
      "Training Loss: 2.5869, Training Accuracy: 60.0100%\n",
      "Test Loss: 3.0013, Test Accuracy: 43.5796%\n",
      "Saving model to attributes-to-class.pth with accuracy 43.5796%\n",
      "Epoch 13/100-------------------\n",
      "Training Loss: 2.4930, Training Accuracy: 60.8609%\n",
      "Test Loss: 2.9294, Test Accuracy: 43.8385%\n",
      "Saving model to attributes-to-class.pth with accuracy 43.8385%\n",
      "Epoch 14/100-------------------\n",
      "Training Loss: 2.4084, Training Accuracy: 61.6617%\n",
      "Test Loss: 2.8654, Test Accuracy: 44.4425%\n",
      "Saving model to attributes-to-class.pth with accuracy 44.4425%\n",
      "Epoch 15/100-------------------\n",
      "Training Loss: 2.3306, Training Accuracy: 62.6126%\n",
      "Test Loss: 2.8081, Test Accuracy: 44.9776%\n",
      "Saving model to attributes-to-class.pth with accuracy 44.9776%\n",
      "Epoch 16/100-------------------\n",
      "Training Loss: 2.2603, Training Accuracy: 63.3133%\n",
      "Test Loss: 2.7563, Test Accuracy: 45.4263%\n",
      "Saving model to attributes-to-class.pth with accuracy 45.4263%\n",
      "Epoch 17/100-------------------\n",
      "Training Loss: 2.1954, Training Accuracy: 64.1308%\n",
      "Test Loss: 2.7101, Test Accuracy: 45.7542%\n",
      "Saving model to attributes-to-class.pth with accuracy 45.7542%\n",
      "Epoch 18/100-------------------\n",
      "Training Loss: 2.1349, Training Accuracy: 64.9983%\n",
      "Test Loss: 2.6678, Test Accuracy: 45.8578%\n",
      "Saving model to attributes-to-class.pth with accuracy 45.8578%\n",
      "Epoch 19/100-------------------\n",
      "Training Loss: 2.0799, Training Accuracy: 65.7491%\n",
      "Test Loss: 2.6290, Test Accuracy: 46.0822%\n",
      "Saving model to attributes-to-class.pth with accuracy 46.0822%\n",
      "Epoch 20/100-------------------\n",
      "Training Loss: 2.0285, Training Accuracy: 66.2829%\n",
      "Test Loss: 2.5936, Test Accuracy: 46.4619%\n",
      "Saving model to attributes-to-class.pth with accuracy 46.4619%\n",
      "Epoch 21/100-------------------\n",
      "Training Loss: 1.9812, Training Accuracy: 66.3997%\n",
      "Test Loss: 2.5617, Test Accuracy: 46.4619%\n",
      "Epoch 22/100-------------------\n",
      "Training Loss: 1.9363, Training Accuracy: 67.0170%\n",
      "Test Loss: 2.5319, Test Accuracy: 46.6344%\n",
      "Saving model to attributes-to-class.pth with accuracy 46.6344%\n",
      "Epoch 23/100-------------------\n",
      "Training Loss: 1.8947, Training Accuracy: 67.5175%\n",
      "Test Loss: 2.5044, Test Accuracy: 46.6690%\n",
      "Saving model to attributes-to-class.pth with accuracy 46.6690%\n",
      "Epoch 24/100-------------------\n",
      "Training Loss: 1.8555, Training Accuracy: 68.0681%\n",
      "Test Loss: 2.4792, Test Accuracy: 47.1004%\n",
      "Saving model to attributes-to-class.pth with accuracy 47.1004%\n",
      "Epoch 25/100-------------------\n",
      "Training Loss: 1.8180, Training Accuracy: 68.4518%\n",
      "Test Loss: 2.4558, Test Accuracy: 47.1004%\n",
      "Epoch 26/100-------------------\n",
      "Training Loss: 1.7833, Training Accuracy: 68.7020%\n",
      "Test Loss: 2.4342, Test Accuracy: 47.2385%\n",
      "Saving model to attributes-to-class.pth with accuracy 47.2385%\n",
      "Epoch 27/100-------------------\n",
      "Training Loss: 1.7501, Training Accuracy: 69.3193%\n",
      "Test Loss: 2.4138, Test Accuracy: 47.2903%\n",
      "Saving model to attributes-to-class.pth with accuracy 47.2903%\n",
      "Epoch 28/100-------------------\n",
      "Training Loss: 1.7195, Training Accuracy: 69.6363%\n",
      "Test Loss: 2.3956, Test Accuracy: 47.2903%\n",
      "Epoch 29/100-------------------\n",
      "Training Loss: 1.6893, Training Accuracy: 69.9533%\n",
      "Test Loss: 2.3783, Test Accuracy: 47.1695%\n",
      "Epoch 30/100-------------------\n",
      "Training Loss: 1.6608, Training Accuracy: 70.3871%\n",
      "Test Loss: 2.3618, Test Accuracy: 47.4802%\n",
      "Saving model to attributes-to-class.pth with accuracy 47.4802%\n",
      "Epoch 31/100-------------------\n",
      "Training Loss: 1.6345, Training Accuracy: 70.5706%\n",
      "Test Loss: 2.3465, Test Accuracy: 47.7390%\n",
      "Saving model to attributes-to-class.pth with accuracy 47.7390%\n",
      "Epoch 32/100-------------------\n",
      "Training Loss: 1.6083, Training Accuracy: 70.9877%\n",
      "Test Loss: 2.3321, Test Accuracy: 47.7390%\n",
      "Epoch 33/100-------------------\n",
      "Training Loss: 1.5838, Training Accuracy: 71.2880%\n",
      "Test Loss: 2.3188, Test Accuracy: 47.8426%\n",
      "Saving model to attributes-to-class.pth with accuracy 47.8426%\n",
      "Epoch 34/100-------------------\n",
      "Training Loss: 1.5598, Training Accuracy: 71.8719%\n",
      "Test Loss: 2.3059, Test Accuracy: 47.9634%\n",
      "Saving model to attributes-to-class.pth with accuracy 47.9634%\n",
      "Epoch 35/100-------------------\n",
      "Training Loss: 1.5373, Training Accuracy: 72.2389%\n",
      "Test Loss: 2.2944, Test Accuracy: 48.0324%\n",
      "Saving model to attributes-to-class.pth with accuracy 48.0324%\n",
      "Epoch 36/100-------------------\n",
      "Training Loss: 1.5158, Training Accuracy: 72.5392%\n",
      "Test Loss: 2.2835, Test Accuracy: 48.0842%\n",
      "Saving model to attributes-to-class.pth with accuracy 48.0842%\n",
      "Epoch 37/100-------------------\n",
      "Training Loss: 1.4946, Training Accuracy: 72.7561%\n",
      "Test Loss: 2.2727, Test Accuracy: 48.0842%\n",
      "Epoch 38/100-------------------\n",
      "Training Loss: 1.4745, Training Accuracy: 73.0731%\n",
      "Test Loss: 2.2628, Test Accuracy: 48.2223%\n",
      "Saving model to attributes-to-class.pth with accuracy 48.2223%\n",
      "Epoch 39/100-------------------\n",
      "Training Loss: 1.4552, Training Accuracy: 73.4067%\n",
      "Test Loss: 2.2533, Test Accuracy: 48.2568%\n",
      "Saving model to attributes-to-class.pth with accuracy 48.2568%\n",
      "Epoch 40/100-------------------\n",
      "Training Loss: 1.4363, Training Accuracy: 73.8405%\n",
      "Test Loss: 2.2445, Test Accuracy: 48.3776%\n",
      "Saving model to attributes-to-class.pth with accuracy 48.3776%\n",
      "Epoch 41/100-------------------\n",
      "Training Loss: 1.4184, Training Accuracy: 73.9239%\n",
      "Test Loss: 2.2356, Test Accuracy: 48.2396%\n",
      "Epoch 42/100-------------------\n",
      "Training Loss: 1.4020, Training Accuracy: 74.2743%\n",
      "Test Loss: 2.2282, Test Accuracy: 48.5157%\n",
      "Saving model to attributes-to-class.pth with accuracy 48.5157%\n",
      "Epoch 43/100-------------------\n",
      "Training Loss: 1.3847, Training Accuracy: 74.6413%\n",
      "Test Loss: 2.2210, Test Accuracy: 48.3086%\n",
      "Epoch 44/100-------------------\n",
      "Training Loss: 1.3674, Training Accuracy: 74.9583%\n",
      "Test Loss: 2.2139, Test Accuracy: 48.3259%\n",
      "Epoch 45/100-------------------\n",
      "Training Loss: 1.3518, Training Accuracy: 75.2085%\n",
      "Test Loss: 2.2071, Test Accuracy: 48.3949%\n",
      "Epoch 46/100-------------------\n",
      "Training Loss: 1.3366, Training Accuracy: 75.4087%\n",
      "Test Loss: 2.2007, Test Accuracy: 48.3949%\n",
      "Epoch 47/100-------------------\n",
      "Training Loss: 1.3214, Training Accuracy: 75.7257%\n",
      "Test Loss: 2.1944, Test Accuracy: 48.4639%\n",
      "Epoch 48/100-------------------\n",
      "Training Loss: 1.3077, Training Accuracy: 76.0427%\n",
      "Test Loss: 2.1888, Test Accuracy: 48.6710%\n",
      "Saving model to attributes-to-class.pth with accuracy 48.6710%\n",
      "Epoch 49/100-------------------\n",
      "Training Loss: 1.2930, Training Accuracy: 76.2763%\n",
      "Test Loss: 2.1833, Test Accuracy: 48.5675%\n",
      "Epoch 50/100-------------------\n",
      "Training Loss: 1.2796, Training Accuracy: 76.5432%\n",
      "Test Loss: 2.1783, Test Accuracy: 48.5675%\n",
      "Epoch 51/100-------------------\n",
      "Training Loss: 1.2658, Training Accuracy: 76.4431%\n",
      "Test Loss: 2.1730, Test Accuracy: 48.6365%\n",
      "Epoch 52/100-------------------\n",
      "Training Loss: 1.2528, Training Accuracy: 76.7434%\n",
      "Test Loss: 2.1682, Test Accuracy: 48.7056%\n",
      "Saving model to attributes-to-class.pth with accuracy 48.7056%\n",
      "Epoch 53/100-------------------\n",
      "Training Loss: 1.2404, Training Accuracy: 77.0103%\n",
      "Test Loss: 2.1639, Test Accuracy: 48.6365%\n",
      "Epoch 54/100-------------------\n",
      "Training Loss: 1.2279, Training Accuracy: 77.3774%\n",
      "Test Loss: 2.1598, Test Accuracy: 48.6710%\n",
      "Epoch 55/100-------------------\n",
      "Training Loss: 1.2160, Training Accuracy: 77.7110%\n",
      "Test Loss: 2.1557, Test Accuracy: 48.6365%\n",
      "Epoch 56/100-------------------\n",
      "Training Loss: 1.2041, Training Accuracy: 77.9112%\n",
      "Test Loss: 2.1520, Test Accuracy: 48.6365%\n",
      "Epoch 57/100-------------------\n",
      "Training Loss: 1.1930, Training Accuracy: 78.1448%\n",
      "Test Loss: 2.1487, Test Accuracy: 48.6538%\n",
      "Epoch 58/100-------------------\n",
      "Training Loss: 1.1814, Training Accuracy: 78.3283%\n",
      "Test Loss: 2.1452, Test Accuracy: 48.7056%\n",
      "Epoch 59/100-------------------\n",
      "Training Loss: 1.1707, Training Accuracy: 78.4451%\n",
      "Test Loss: 2.1417, Test Accuracy: 48.7056%\n",
      "Epoch 60/100-------------------\n",
      "Training Loss: 1.1604, Training Accuracy: 78.6954%\n",
      "Test Loss: 2.1387, Test Accuracy: 48.8264%\n",
      "Saving model to attributes-to-class.pth with accuracy 48.8264%\n",
      "Epoch 61/100-------------------\n",
      "Training Loss: 1.1496, Training Accuracy: 78.7120%\n",
      "Test Loss: 2.1353, Test Accuracy: 48.7919%\n",
      "Epoch 62/100-------------------\n",
      "Training Loss: 1.1397, Training Accuracy: 79.0958%\n",
      "Test Loss: 2.1327, Test Accuracy: 48.8264%\n",
      "Epoch 63/100-------------------\n",
      "Training Loss: 1.1294, Training Accuracy: 79.1959%\n",
      "Test Loss: 2.1298, Test Accuracy: 48.8609%\n",
      "Saving model to attributes-to-class.pth with accuracy 48.8609%\n",
      "Epoch 64/100-------------------\n",
      "Training Loss: 1.1198, Training Accuracy: 79.3126%\n",
      "Test Loss: 2.1272, Test Accuracy: 48.9299%\n",
      "Saving model to attributes-to-class.pth with accuracy 48.9299%\n",
      "Epoch 65/100-------------------\n",
      "Training Loss: 1.1106, Training Accuracy: 79.5629%\n",
      "Test Loss: 2.1245, Test Accuracy: 48.9299%\n",
      "Epoch 66/100-------------------\n",
      "Training Loss: 1.1009, Training Accuracy: 79.9800%\n",
      "Test Loss: 2.1226, Test Accuracy: 49.0507%\n",
      "Saving model to attributes-to-class.pth with accuracy 49.0507%\n",
      "Epoch 67/100-------------------\n",
      "Training Loss: 1.0915, Training Accuracy: 79.9466%\n",
      "Test Loss: 2.1205, Test Accuracy: 48.8091%\n",
      "Epoch 68/100-------------------\n",
      "Training Loss: 1.0833, Training Accuracy: 80.0968%\n",
      "Test Loss: 2.1183, Test Accuracy: 48.9644%\n",
      "Epoch 69/100-------------------\n",
      "Training Loss: 1.0739, Training Accuracy: 80.2803%\n",
      "Test Loss: 2.1163, Test Accuracy: 48.7573%\n",
      "Epoch 70/100-------------------\n",
      "Training Loss: 1.0650, Training Accuracy: 80.4471%\n",
      "Test Loss: 2.1140, Test Accuracy: 48.9299%\n",
      "Epoch 71/100-------------------\n",
      "Training Loss: 1.0570, Training Accuracy: 80.8141%\n",
      "Test Loss: 2.1125, Test Accuracy: 48.9472%\n",
      "Epoch 72/100-------------------\n",
      "Training Loss: 1.0484, Training Accuracy: 80.8475%\n",
      "Test Loss: 2.1110, Test Accuracy: 48.9299%\n",
      "Epoch 73/100-------------------\n",
      "Training Loss: 1.0407, Training Accuracy: 81.2145%\n",
      "Test Loss: 2.1095, Test Accuracy: 48.9817%\n",
      "Epoch 74/100-------------------\n",
      "Training Loss: 1.0323, Training Accuracy: 81.2980%\n",
      "Test Loss: 2.1083, Test Accuracy: 48.7401%\n",
      "Epoch 75/100-------------------\n",
      "Training Loss: 1.0242, Training Accuracy: 81.5315%\n",
      "Test Loss: 2.1066, Test Accuracy: 48.9472%\n",
      "Epoch 76/100-------------------\n",
      "Training Loss: 1.0167, Training Accuracy: 81.6984%\n",
      "Test Loss: 2.1051, Test Accuracy: 48.9644%\n",
      "Epoch 77/100-------------------\n",
      "Training Loss: 1.0092, Training Accuracy: 81.7818%\n",
      "Test Loss: 2.1037, Test Accuracy: 48.9472%\n",
      "Epoch 78/100-------------------\n",
      "Training Loss: 1.0019, Training Accuracy: 82.0988%\n",
      "Test Loss: 2.1026, Test Accuracy: 48.9817%\n",
      "Epoch 79/100-------------------\n",
      "Training Loss: 0.9943, Training Accuracy: 82.3156%\n",
      "Test Loss: 2.1015, Test Accuracy: 48.8609%\n",
      "Epoch 80/100-------------------\n",
      "Training Loss: 0.9868, Training Accuracy: 82.4324%\n",
      "Test Loss: 2.1006, Test Accuracy: 48.9472%\n",
      "Epoch 81/100-------------------\n",
      "Training Loss: 0.9799, Training Accuracy: 82.5659%\n",
      "Test Loss: 2.0992, Test Accuracy: 48.9127%\n",
      "Epoch 82/100-------------------\n",
      "Training Loss: 0.9729, Training Accuracy: 82.5659%\n",
      "Test Loss: 2.0984, Test Accuracy: 48.8781%\n",
      "Epoch 83/100-------------------\n",
      "Training Loss: 0.9664, Training Accuracy: 82.8829%\n",
      "Test Loss: 2.0977, Test Accuracy: 48.8609%\n",
      "Epoch 84/100-------------------\n",
      "Training Loss: 0.9595, Training Accuracy: 82.8996%\n",
      "Test Loss: 2.0969, Test Accuracy: 49.0335%\n",
      "Epoch 85/100-------------------\n",
      "Training Loss: 0.9530, Training Accuracy: 83.2165%\n",
      "Test Loss: 2.0961, Test Accuracy: 48.9299%\n",
      "Epoch 86/100-------------------\n",
      "Training Loss: 0.9465, Training Accuracy: 83.3000%\n",
      "Test Loss: 2.0954, Test Accuracy: 48.8436%\n",
      "Epoch 87/100-------------------\n",
      "Training Loss: 0.9397, Training Accuracy: 83.4001%\n",
      "Test Loss: 2.0947, Test Accuracy: 48.8954%\n",
      "Epoch 88/100-------------------\n",
      "Training Loss: 0.9345, Training Accuracy: 83.5002%\n",
      "Test Loss: 2.0941, Test Accuracy: 48.8954%\n",
      "Epoch 89/100-------------------\n",
      "Training Loss: 0.9274, Training Accuracy: 83.6170%\n",
      "Test Loss: 2.0937, Test Accuracy: 48.8954%\n",
      "Epoch 90/100-------------------\n",
      "Training Loss: 0.9218, Training Accuracy: 83.7838%\n",
      "Test Loss: 2.0928, Test Accuracy: 48.8609%\n",
      "Epoch 91/100-------------------\n",
      "Training Loss: 0.9149, Training Accuracy: 83.8338%\n",
      "Test Loss: 2.0926, Test Accuracy: 48.9299%\n",
      "Epoch 92/100-------------------\n",
      "Training Loss: 0.9092, Training Accuracy: 84.0007%\n",
      "Test Loss: 2.0923, Test Accuracy: 48.8781%\n",
      "Epoch 93/100-------------------\n",
      "Training Loss: 0.9032, Training Accuracy: 84.1675%\n",
      "Test Loss: 2.0919, Test Accuracy: 48.8264%\n",
      "Epoch 94/100-------------------\n",
      "Training Loss: 0.8978, Training Accuracy: 84.2509%\n",
      "Test Loss: 2.0914, Test Accuracy: 48.8264%\n",
      "Epoch 95/100-------------------\n",
      "Training Loss: 0.8917, Training Accuracy: 84.2342%\n",
      "Test Loss: 2.0910, Test Accuracy: 48.8781%\n",
      "Epoch 96/100-------------------\n",
      "Training Loss: 0.8866, Training Accuracy: 84.4678%\n",
      "Test Loss: 2.0908, Test Accuracy: 48.8781%\n",
      "Epoch 97/100-------------------\n",
      "Training Loss: 0.8807, Training Accuracy: 84.5679%\n",
      "Test Loss: 2.0906, Test Accuracy: 48.9299%\n",
      "Epoch 98/100-------------------\n",
      "Training Loss: 0.8751, Training Accuracy: 84.6513%\n",
      "Test Loss: 2.0901, Test Accuracy: 48.9644%\n",
      "Epoch 99/100-------------------\n",
      "Training Loss: 0.8699, Training Accuracy: 84.7681%\n",
      "Test Loss: 2.0902, Test Accuracy: 48.9127%\n",
      "Epoch 100/100-------------------\n",
      "Training Loss: 0.8646, Training Accuracy: 84.9016%\n",
      "Test Loss: 2.0901, Test Accuracy: 48.9644%\n",
      "Best Test Accuracy: 49.0507%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-0.0922, -0.3742,  0.1346,  ..., -0.2687,  0.2704, -0.2033],\n",
       "                      [ 0.1067, -0.3059,  0.4043,  ..., -0.0886, -0.0688, -0.7138],\n",
       "                      [-0.0604, -0.3150,  0.1318,  ..., -0.2120, -0.5559,  0.1888],\n",
       "                      ...,\n",
       "                      [ 0.0651,  0.9468, -0.1142,  ...,  0.9651, -0.1223, -0.5563],\n",
       "                      [-0.2269, -0.2144, -0.0398,  ...,  0.3109,  0.0655,  0.0720],\n",
       "                      [-0.0551,  0.0073, -0.0054,  ..., -0.1103, -0.3590, -0.1296]],\n",
       "                     device='cuda:0')),\n",
       "             ('0.bias',\n",
       "              tensor([ 0.6068,  0.6178,  0.3081,  0.1719,  0.2887,  0.3213,  0.1441,  0.8954,\n",
       "                       0.4529, -0.0213, -0.1170, -0.0119, -0.2155, -0.0587, -0.1556,  0.2981,\n",
       "                       0.2109,  0.3282, -0.2287, -0.2762, -0.0366,  0.4565,  0.3167,  0.5228,\n",
       "                       0.1946, -0.3027,  0.1153, -0.1625, -0.6111, -0.1824, -0.1918,  0.0805,\n",
       "                      -0.0478, -0.2679, -0.1895, -0.1350,  0.0292,  0.0591,  0.3115,  0.2167,\n",
       "                      -0.2365, -0.1541,  0.2404,  0.3547,  0.0101, -0.1983, -0.1472,  0.0632,\n",
       "                       0.0203,  0.1184,  0.3758,  0.2799,  0.5796,  0.1828, -0.0143,  0.2591,\n",
       "                      -0.1782, -0.0162, -0.1152,  0.0160, -0.0484, -0.0665, -0.2922, -0.0487,\n",
       "                       0.1906, -0.1573,  0.1186,  0.2692,  0.1077,  0.3970,  0.3007,  0.4588,\n",
       "                      -0.2206,  0.4894,  0.1592,  0.1505,  0.1206, -0.0340,  0.0945,  0.1108,\n",
       "                       0.0651,  0.1690,  0.2045,  0.1260, -0.2493,  0.4268,  0.0200, -0.1326,\n",
       "                       0.3110,  0.1031,  0.0693,  0.1037, -0.0776, -0.0226, -0.2740, -0.1003,\n",
       "                      -0.0032,  0.0346,  0.2104,  0.5549,  0.2011,  0.1662, -0.3964, -0.0127,\n",
       "                       0.7870,  0.2163, -0.2762,  0.2166, -0.1326, -0.0241, -0.0893,  0.1981,\n",
       "                       0.1692, -0.2413,  0.1212, -0.1756, -0.2626, -0.2628, -0.2072, -0.3123,\n",
       "                      -0.1892, -0.4230,  0.0369, -0.1452, -0.4183,  0.1094, -0.3766,  0.2079,\n",
       "                      -0.3406, -0.2973,  0.0413,  0.3784, -0.1257,  0.0029,  0.0721, -0.0382,\n",
       "                       0.7715,  0.0284, -0.1981, -0.0822, -0.0206,  0.0290,  0.0158, -0.0811,\n",
       "                       0.1850, -0.2665, -0.0144,  0.1628, -0.0858, -0.2499, -0.0746, -0.4481,\n",
       "                      -0.0136,  0.0093, -0.0127, -0.2198, -0.2630, -0.0557, -0.4851,  0.1278,\n",
       "                       0.0087,  0.3223,  0.1052, -0.3241, -0.0637, -0.2359,  0.0642,  0.0083,\n",
       "                      -0.2316,  0.3036,  0.1445, -0.1155,  0.5429,  0.2835, -0.0942, -0.3078,\n",
       "                      -0.4947, -0.0037, -0.0195, -0.2088, -0.1783, -0.2155, -0.4410, -0.3988,\n",
       "                      -0.1947, -0.1718, -0.0464, -0.1316, -0.0396, -0.0569, -0.2269, -0.4569,\n",
       "                      -0.4292, -0.1803, -0.3292, -0.2473, -0.3308, -0.4510, -0.2639, -0.2532],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.concept_bottleneck.train import TrainFn, TestFn, run_epochs\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "train_fn: TrainFn = lambda model: train(\n",
    "    model, training_dataloader, loss_fn, optimizer, device\n",
    ")\n",
    "test_fn: TestFn = lambda model, dataloader: test(model, dataloader, loss_fn, device)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "run_epochs(\n",
    "    epochs,\n",
    "    model,\n",
    "    train_fn,\n",
    "    test_fn,\n",
    "    training_dataloader,\n",
    "    test_dataloader,\n",
    "    save_name=\"attributes-to-class.pth\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d4040fe446a930194e7f49e706fe5ca82fc3ae21142ec3efeed3554a6698e7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
