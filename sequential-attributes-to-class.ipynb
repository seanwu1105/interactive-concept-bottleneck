{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.concept_bottleneck.dataset import CUB200ImageToClass\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 2\n",
    "\n",
    "training_data = CUB200ImageToClass(train=True)\n",
    "test_data = CUB200ImageToClass(train=False)\n",
    "\n",
    "training_dataloader = DataLoader(training_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from src.concept_bottleneck.networks import get_mlp\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = get_mlp().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from src.concept_bottleneck.inference import SEQUENTIAL_ATTRIBUTES_TO_CLASS_MODEL_NAME\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: DataLoader[tuple[torch.Tensor, np.int_]],\n",
    "    trained_image_to_attributes_model: torch.nn.Module,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: str,\n",
    "):\n",
    "    model.train()\n",
    "    trained_image_to_attributes_model.eval()\n",
    "    size = len(dataloader.dataset)  # type: ignore\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x = trained_image_to_attributes_model(x.to(device))\n",
    "        y = y.to(device)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f\"loss: {loss.item():>7f} [{batch * len(x):>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: DataLoader[tuple[torch.Tensor, np.int_]],\n",
    "    trained_image_to_attributes_model: torch.nn.Module,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    device: str,\n",
    "):\n",
    "    model.eval()\n",
    "    trained_image_to_attributes_model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = trained_image_to_attributes_model(x.to(device))\n",
    "            y = y.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            test_loss += loss_fn(logits, y).item()\n",
    "            correct += (logits.argmax(dim=1) == y).sum().item()\n",
    "\n",
    "    test_loss /= len(dataloader)\n",
    "    accuracy = correct / len(dataloader.dataset)  # type: ignore\n",
    "\n",
    "    return test_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/shuangwu/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200-------------------\n",
      "loss: 8.090341 [    0/ 5994]\n",
      "loss: 443.980286 [ 1600/ 5994]\n",
      "loss: 554.696838 [ 3200/ 5994]\n",
      "loss: 243.043884 [ 4800/ 5994]\n",
      "Training Loss: 325.3225, Training Accuracy: 15.8825%\n",
      "Test Loss: 327.2878, Test Accuracy: 15.1536%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 15.1536%\n",
      "Epoch 2/200-------------------\n",
      "loss: 326.555908 [    0/ 5994]\n",
      "loss: 249.687500 [ 1600/ 5994]\n",
      "loss: 259.589081 [ 3200/ 5994]\n",
      "loss: 267.599213 [ 4800/ 5994]\n",
      "Training Loss: 284.8847, Training Accuracy: 20.2536%\n",
      "Test Loss: 288.2812, Test Accuracy: 19.2440%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 19.2440%\n",
      "Epoch 3/200-------------------\n",
      "loss: 103.394791 [    0/ 5994]\n",
      "loss: 177.530777 [ 1600/ 5994]\n",
      "loss: 368.142120 [ 3200/ 5994]\n",
      "loss: 317.048096 [ 4800/ 5994]\n",
      "Training Loss: 248.4690, Training Accuracy: 22.2389%\n",
      "Test Loss: 251.3528, Test Accuracy: 20.2969%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 20.2969%\n",
      "Epoch 4/200-------------------\n",
      "loss: 171.737869 [    0/ 5994]\n",
      "loss: 329.437134 [ 1600/ 5994]\n",
      "loss: 233.361404 [ 3200/ 5994]\n",
      "loss: 226.555023 [ 4800/ 5994]\n",
      "Training Loss: 265.4137, Training Accuracy: 25.0918%\n",
      "Test Loss: 275.9085, Test Accuracy: 22.6269%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 22.6269%\n",
      "Epoch 5/200-------------------\n",
      "loss: 354.361969 [    0/ 5994]\n",
      "loss: 246.504166 [ 1600/ 5994]\n",
      "loss: 190.704559 [ 3200/ 5994]\n",
      "loss: 235.684937 [ 4800/ 5994]\n",
      "Training Loss: 210.1524, Training Accuracy: 28.6119%\n",
      "Test Loss: 224.0936, Test Accuracy: 24.8706%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 24.8706%\n",
      "Epoch 6/200-------------------\n",
      "loss: 125.948303 [    0/ 5994]\n",
      "loss: 203.972244 [ 1600/ 5994]\n",
      "loss: 197.065521 [ 3200/ 5994]\n",
      "loss: 129.173492 [ 4800/ 5994]\n",
      "Training Loss: 244.4206, Training Accuracy: 26.3597%\n",
      "Test Loss: 257.2136, Test Accuracy: 24.0766%\n",
      "Epoch 7/200-------------------\n",
      "loss: 211.316666 [    0/ 5994]\n",
      "loss: 244.268646 [ 1600/ 5994]\n",
      "loss: 170.433868 [ 3200/ 5994]\n",
      "loss: 134.216324 [ 4800/ 5994]\n",
      "Training Loss: 225.8514, Training Accuracy: 28.6286%\n",
      "Test Loss: 240.4496, Test Accuracy: 25.1294%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 25.1294%\n",
      "Epoch 8/200-------------------\n",
      "loss: 165.407684 [    0/ 5994]\n",
      "loss: 222.530624 [ 1600/ 5994]\n",
      "loss: 196.044693 [ 3200/ 5994]\n",
      "loss: 166.777267 [ 4800/ 5994]\n",
      "Training Loss: 217.2271, Training Accuracy: 32.4491%\n",
      "Test Loss: 236.6645, Test Accuracy: 28.6503%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 28.6503%\n",
      "Epoch 9/200-------------------\n",
      "loss: 246.599426 [    0/ 5994]\n",
      "loss: 89.498291 [ 1600/ 5994]\n",
      "loss: 242.027405 [ 3200/ 5994]\n",
      "loss: 215.846344 [ 4800/ 5994]\n",
      "Training Loss: 206.0417, Training Accuracy: 34.2176%\n",
      "Test Loss: 225.1024, Test Accuracy: 29.0991%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 29.0991%\n",
      "Epoch 10/200-------------------\n",
      "loss: 106.047516 [    0/ 5994]\n",
      "loss: 162.574280 [ 1600/ 5994]\n",
      "loss: 269.278107 [ 3200/ 5994]\n",
      "loss: 235.164810 [ 4800/ 5994]\n",
      "Training Loss: 184.4365, Training Accuracy: 36.4031%\n",
      "Test Loss: 201.6492, Test Accuracy: 31.7570%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 31.7570%\n",
      "Epoch 11/200-------------------\n",
      "loss: 231.257324 [    0/ 5994]\n",
      "loss: 195.451080 [ 1600/ 5994]\n",
      "loss: 154.802612 [ 3200/ 5994]\n",
      "loss: 264.348816 [ 4800/ 5994]\n",
      "Training Loss: 211.4154, Training Accuracy: 36.3697%\n",
      "Test Loss: 231.6690, Test Accuracy: 32.6372%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 32.6372%\n",
      "Epoch 12/200-------------------\n",
      "loss: 178.816360 [    0/ 5994]\n",
      "loss: 66.952003 [ 1600/ 5994]\n",
      "loss: 248.432861 [ 3200/ 5994]\n",
      "loss: 220.069046 [ 4800/ 5994]\n",
      "Training Loss: 198.8998, Training Accuracy: 36.6366%\n",
      "Test Loss: 218.5981, Test Accuracy: 32.4474%\n",
      "Epoch 13/200-------------------\n",
      "loss: 196.636078 [    0/ 5994]\n",
      "loss: 101.990807 [ 1600/ 5994]\n",
      "loss: 261.798279 [ 3200/ 5994]\n",
      "loss: 177.268341 [ 4800/ 5994]\n",
      "Training Loss: 205.2755, Training Accuracy: 35.0350%\n",
      "Test Loss: 226.5034, Test Accuracy: 30.3245%\n",
      "Epoch 14/200-------------------\n",
      "loss: 131.836761 [    0/ 5994]\n",
      "loss: 211.213287 [ 1600/ 5994]\n",
      "loss: 255.543701 [ 3200/ 5994]\n",
      "loss: 77.169685 [ 4800/ 5994]\n",
      "Training Loss: 202.7683, Training Accuracy: 34.2509%\n",
      "Test Loss: 224.8174, Test Accuracy: 30.4625%\n",
      "Epoch 15/200-------------------\n",
      "loss: 147.858612 [    0/ 5994]\n",
      "loss: 229.036362 [ 1600/ 5994]\n",
      "loss: 223.608521 [ 3200/ 5994]\n",
      "loss: 188.188461 [ 4800/ 5994]\n",
      "Training Loss: 187.8949, Training Accuracy: 37.1705%\n",
      "Test Loss: 212.4385, Test Accuracy: 32.1885%\n",
      "Epoch 16/200-------------------\n",
      "loss: 170.503906 [    0/ 5994]\n",
      "loss: 78.878883 [ 1600/ 5994]\n",
      "loss: 87.979782 [ 3200/ 5994]\n",
      "loss: 190.820999 [ 4800/ 5994]\n",
      "Training Loss: 202.7177, Training Accuracy: 37.2039%\n",
      "Test Loss: 227.9660, Test Accuracy: 31.8260%\n",
      "Epoch 17/200-------------------\n",
      "loss: 188.920166 [    0/ 5994]\n",
      "loss: 258.136078 [ 1600/ 5994]\n",
      "loss: 185.713989 [ 3200/ 5994]\n",
      "loss: 192.702087 [ 4800/ 5994]\n",
      "Training Loss: 206.0303, Training Accuracy: 38.5886%\n",
      "Test Loss: 228.6086, Test Accuracy: 33.2585%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 33.2585%\n",
      "Epoch 18/200-------------------\n",
      "loss: 70.354355 [    0/ 5994]\n",
      "loss: 192.622528 [ 1600/ 5994]\n",
      "loss: 161.995743 [ 3200/ 5994]\n",
      "loss: 106.994949 [ 4800/ 5994]\n",
      "Training Loss: 211.0707, Training Accuracy: 38.4384%\n",
      "Test Loss: 239.4396, Test Accuracy: 34.1388%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 34.1388%\n",
      "Epoch 19/200-------------------\n",
      "loss: 203.746368 [    0/ 5994]\n",
      "loss: 301.388275 [ 1600/ 5994]\n",
      "loss: 203.474442 [ 3200/ 5994]\n",
      "loss: 208.833984 [ 4800/ 5994]\n",
      "Training Loss: 191.9196, Training Accuracy: 40.4238%\n",
      "Test Loss: 221.0111, Test Accuracy: 34.7428%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 34.7428%\n",
      "Epoch 20/200-------------------\n",
      "loss: 77.083496 [    0/ 5994]\n",
      "loss: 239.847122 [ 1600/ 5994]\n",
      "loss: 43.851734 [ 3200/ 5994]\n",
      "loss: 183.595123 [ 4800/ 5994]\n",
      "Training Loss: 199.4063, Training Accuracy: 38.9056%\n",
      "Test Loss: 231.3927, Test Accuracy: 33.4139%\n",
      "Epoch 21/200-------------------\n",
      "loss: 191.889954 [    0/ 5994]\n",
      "loss: 224.034973 [ 1600/ 5994]\n",
      "loss: 205.611389 [ 3200/ 5994]\n",
      "loss: 181.408569 [ 4800/ 5994]\n",
      "Training Loss: 214.3463, Training Accuracy: 37.4541%\n",
      "Test Loss: 244.7303, Test Accuracy: 31.7915%\n",
      "Epoch 22/200-------------------\n",
      "loss: 285.159149 [    0/ 5994]\n",
      "loss: 186.243195 [ 1600/ 5994]\n",
      "loss: 213.498856 [ 3200/ 5994]\n",
      "loss: 164.698792 [ 4800/ 5994]\n",
      "Training Loss: 179.8859, Training Accuracy: 43.2099%\n",
      "Test Loss: 206.5167, Test Accuracy: 37.3835%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 37.3835%\n",
      "Epoch 23/200-------------------\n",
      "loss: 80.343300 [    0/ 5994]\n",
      "loss: 154.837860 [ 1600/ 5994]\n",
      "loss: 193.759354 [ 3200/ 5994]\n",
      "loss: 155.434006 [ 4800/ 5994]\n",
      "Training Loss: 168.9300, Training Accuracy: 40.8575%\n",
      "Test Loss: 198.2686, Test Accuracy: 35.0362%\n",
      "Epoch 24/200-------------------\n",
      "loss: 249.177872 [    0/ 5994]\n",
      "loss: 141.066666 [ 1600/ 5994]\n",
      "loss: 165.203781 [ 3200/ 5994]\n",
      "loss: 211.487366 [ 4800/ 5994]\n",
      "Training Loss: 197.2622, Training Accuracy: 40.8242%\n",
      "Test Loss: 228.6573, Test Accuracy: 34.9672%\n",
      "Epoch 25/200-------------------\n",
      "loss: 253.703430 [    0/ 5994]\n",
      "loss: 174.031784 [ 1600/ 5994]\n",
      "loss: 322.063049 [ 3200/ 5994]\n",
      "loss: 151.474152 [ 4800/ 5994]\n",
      "Training Loss: 154.3303, Training Accuracy: 46.9636%\n",
      "Test Loss: 183.1931, Test Accuracy: 40.9562%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 40.9562%\n",
      "Epoch 26/200-------------------\n",
      "loss: 202.553833 [    0/ 5994]\n",
      "loss: 199.039551 [ 1600/ 5994]\n",
      "loss: 285.785889 [ 3200/ 5994]\n",
      "loss: 190.692490 [ 4800/ 5994]\n",
      "Training Loss: 191.1748, Training Accuracy: 44.1108%\n",
      "Test Loss: 226.4654, Test Accuracy: 37.7114%\n",
      "Epoch 27/200-------------------\n",
      "loss: 208.636108 [    0/ 5994]\n",
      "loss: 160.566391 [ 1600/ 5994]\n",
      "loss: 134.977448 [ 3200/ 5994]\n",
      "loss: 206.849457 [ 4800/ 5994]\n",
      "Training Loss: 181.7651, Training Accuracy: 42.9596%\n",
      "Test Loss: 217.2390, Test Accuracy: 36.7104%\n",
      "Epoch 28/200-------------------\n",
      "loss: 173.853424 [    0/ 5994]\n",
      "loss: 294.818848 [ 1600/ 5994]\n",
      "loss: 132.394302 [ 3200/ 5994]\n",
      "loss: 100.713203 [ 4800/ 5994]\n",
      "Training Loss: 173.7295, Training Accuracy: 44.1275%\n",
      "Test Loss: 206.5866, Test Accuracy: 38.2637%\n",
      "Epoch 29/200-------------------\n",
      "loss: 187.357269 [    0/ 5994]\n",
      "loss: 250.580872 [ 1600/ 5994]\n",
      "loss: 224.251389 [ 3200/ 5994]\n",
      "loss: 305.969666 [ 4800/ 5994]\n",
      "Training Loss: 193.8844, Training Accuracy: 42.4591%\n",
      "Test Loss: 230.0184, Test Accuracy: 36.1581%\n",
      "Epoch 30/200-------------------\n",
      "loss: 330.068420 [    0/ 5994]\n",
      "loss: 205.959305 [ 1600/ 5994]\n",
      "loss: 156.703339 [ 3200/ 5994]\n",
      "loss: 273.517670 [ 4800/ 5994]\n",
      "Training Loss: 162.8353, Training Accuracy: 46.9469%\n",
      "Test Loss: 197.7551, Test Accuracy: 41.1288%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 41.1288%\n",
      "Epoch 31/200-------------------\n",
      "loss: 168.144440 [    0/ 5994]\n",
      "loss: 208.218338 [ 1600/ 5994]\n",
      "loss: 126.801819 [ 3200/ 5994]\n",
      "loss: 201.099045 [ 4800/ 5994]\n",
      "Training Loss: 174.8951, Training Accuracy: 46.1962%\n",
      "Test Loss: 211.4853, Test Accuracy: 39.3683%\n",
      "Epoch 32/200-------------------\n",
      "loss: 206.758606 [    0/ 5994]\n",
      "loss: 131.476532 [ 1600/ 5994]\n",
      "loss: 78.307938 [ 3200/ 5994]\n",
      "loss: 229.967926 [ 4800/ 5994]\n",
      "Training Loss: 181.4806, Training Accuracy: 42.4424%\n",
      "Test Loss: 215.3296, Test Accuracy: 37.4525%\n",
      "Epoch 33/200-------------------\n",
      "loss: 216.630768 [    0/ 5994]\n",
      "loss: 198.870895 [ 1600/ 5994]\n",
      "loss: 167.673950 [ 3200/ 5994]\n",
      "loss: 216.771317 [ 4800/ 5994]\n",
      "Training Loss: 162.8337, Training Accuracy: 45.9960%\n",
      "Test Loss: 200.2182, Test Accuracy: 39.9896%\n",
      "Epoch 34/200-------------------\n",
      "loss: 244.129562 [    0/ 5994]\n",
      "loss: 256.151245 [ 1600/ 5994]\n",
      "loss: 269.974915 [ 3200/ 5994]\n",
      "loss: 88.175079 [ 4800/ 5994]\n",
      "Training Loss: 141.3084, Training Accuracy: 49.4328%\n",
      "Test Loss: 175.6278, Test Accuracy: 42.5958%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 42.5958%\n",
      "Epoch 35/200-------------------\n",
      "loss: 103.580269 [    0/ 5994]\n",
      "loss: 190.677887 [ 1600/ 5994]\n",
      "loss: 158.066055 [ 3200/ 5994]\n",
      "loss: 182.538208 [ 4800/ 5994]\n",
      "Training Loss: 161.5068, Training Accuracy: 47.2639%\n",
      "Test Loss: 199.4243, Test Accuracy: 39.6272%\n",
      "Epoch 36/200-------------------\n",
      "loss: 47.765457 [    0/ 5994]\n",
      "loss: 140.528915 [ 1600/ 5994]\n",
      "loss: 207.630493 [ 3200/ 5994]\n",
      "loss: 87.243713 [ 4800/ 5994]\n",
      "Training Loss: 158.7517, Training Accuracy: 46.3297%\n",
      "Test Loss: 197.0471, Test Accuracy: 40.1795%\n",
      "Epoch 37/200-------------------\n",
      "loss: 99.941284 [    0/ 5994]\n",
      "loss: 135.263306 [ 1600/ 5994]\n",
      "loss: 87.918510 [ 3200/ 5994]\n",
      "loss: 126.263443 [ 4800/ 5994]\n",
      "Training Loss: 180.6254, Training Accuracy: 44.1441%\n",
      "Test Loss: 220.9764, Test Accuracy: 38.1256%\n",
      "Epoch 38/200-------------------\n",
      "loss: 117.415611 [    0/ 5994]\n",
      "loss: 339.389465 [ 1600/ 5994]\n",
      "loss: 76.649902 [ 3200/ 5994]\n",
      "loss: 138.195602 [ 4800/ 5994]\n",
      "Training Loss: 170.3821, Training Accuracy: 47.8145%\n",
      "Test Loss: 206.9230, Test Accuracy: 40.8353%\n",
      "Epoch 39/200-------------------\n",
      "loss: 136.750656 [    0/ 5994]\n",
      "loss: 168.569153 [ 1600/ 5994]\n",
      "loss: 218.699768 [ 3200/ 5994]\n",
      "loss: 110.561493 [ 4800/ 5994]\n",
      "Training Loss: 165.3266, Training Accuracy: 49.3160%\n",
      "Test Loss: 202.4088, Test Accuracy: 42.6648%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 42.6648%\n",
      "Epoch 40/200-------------------\n",
      "loss: 212.425720 [    0/ 5994]\n",
      "loss: 235.124573 [ 1600/ 5994]\n",
      "loss: 251.541397 [ 3200/ 5994]\n",
      "loss: 198.807190 [ 4800/ 5994]\n",
      "Training Loss: 155.2750, Training Accuracy: 49.3160%\n",
      "Test Loss: 198.2743, Test Accuracy: 41.8536%\n",
      "Epoch 41/200-------------------\n",
      "loss: 115.714211 [    0/ 5994]\n",
      "loss: 335.609619 [ 1600/ 5994]\n",
      "loss: 143.196350 [ 3200/ 5994]\n",
      "loss: 182.897278 [ 4800/ 5994]\n",
      "Training Loss: 178.1185, Training Accuracy: 48.6320%\n",
      "Test Loss: 216.3355, Test Accuracy: 41.5775%\n",
      "Epoch 42/200-------------------\n",
      "loss: 133.565979 [    0/ 5994]\n",
      "loss: 113.847923 [ 1600/ 5994]\n",
      "loss: 148.203171 [ 3200/ 5994]\n",
      "loss: 147.800797 [ 4800/ 5994]\n",
      "Training Loss: 170.7913, Training Accuracy: 45.9293%\n",
      "Test Loss: 210.9959, Test Accuracy: 39.4201%\n",
      "Epoch 43/200-------------------\n",
      "loss: 133.723572 [    0/ 5994]\n",
      "loss: 156.169388 [ 1600/ 5994]\n",
      "loss: 206.345428 [ 3200/ 5994]\n",
      "loss: 164.735901 [ 4800/ 5994]\n",
      "Training Loss: 165.4084, Training Accuracy: 48.2816%\n",
      "Test Loss: 207.4958, Test Accuracy: 41.9054%\n",
      "Epoch 44/200-------------------\n",
      "loss: 82.801682 [    0/ 5994]\n",
      "loss: 57.550362 [ 1600/ 5994]\n",
      "loss: 230.691772 [ 3200/ 5994]\n",
      "loss: 314.902588 [ 4800/ 5994]\n",
      "Training Loss: 146.2395, Training Accuracy: 50.0501%\n",
      "Test Loss: 185.4167, Test Accuracy: 43.7349%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 43.7349%\n",
      "Epoch 45/200-------------------\n",
      "loss: 148.185928 [    0/ 5994]\n",
      "loss: 178.988403 [ 1600/ 5994]\n",
      "loss: 262.109863 [ 3200/ 5994]\n",
      "loss: 171.372528 [ 4800/ 5994]\n",
      "Training Loss: 159.0535, Training Accuracy: 49.0157%\n",
      "Test Loss: 199.2440, Test Accuracy: 42.3542%\n",
      "Epoch 46/200-------------------\n",
      "loss: 121.341568 [    0/ 5994]\n",
      "loss: 157.251251 [ 1600/ 5994]\n",
      "loss: 124.875816 [ 3200/ 5994]\n",
      "loss: 117.043655 [ 4800/ 5994]\n",
      "Training Loss: 173.4721, Training Accuracy: 48.7154%\n",
      "Test Loss: 213.0147, Test Accuracy: 41.9745%\n",
      "Epoch 47/200-------------------\n",
      "loss: 169.677856 [    0/ 5994]\n",
      "loss: 150.581787 [ 1600/ 5994]\n",
      "loss: 182.958206 [ 3200/ 5994]\n",
      "loss: 214.246613 [ 4800/ 5994]\n",
      "Training Loss: 196.7059, Training Accuracy: 45.8458%\n",
      "Test Loss: 242.7022, Test Accuracy: 38.5744%\n",
      "Epoch 48/200-------------------\n",
      "loss: 136.321457 [    0/ 5994]\n",
      "loss: 98.267471 [ 1600/ 5994]\n",
      "loss: 229.510529 [ 3200/ 5994]\n",
      "loss: 399.937347 [ 4800/ 5994]\n",
      "Training Loss: 157.2273, Training Accuracy: 49.5162%\n",
      "Test Loss: 195.7148, Test Accuracy: 42.2679%\n",
      "Epoch 49/200-------------------\n",
      "loss: 234.586700 [    0/ 5994]\n",
      "loss: 80.865646 [ 1600/ 5994]\n",
      "loss: 220.358398 [ 3200/ 5994]\n",
      "loss: 162.311554 [ 4800/ 5994]\n",
      "Training Loss: 134.3842, Training Accuracy: 49.0324%\n",
      "Test Loss: 177.9795, Test Accuracy: 41.5948%\n",
      "Epoch 50/200-------------------\n",
      "loss: 151.731796 [    0/ 5994]\n",
      "loss: 164.661133 [ 1600/ 5994]\n",
      "loss: 299.953918 [ 3200/ 5994]\n",
      "loss: 152.082123 [ 4800/ 5994]\n",
      "Training Loss: 141.9496, Training Accuracy: 49.5162%\n",
      "Test Loss: 184.2446, Test Accuracy: 43.5623%\n",
      "Epoch 51/200-------------------\n",
      "loss: 102.052948 [    0/ 5994]\n",
      "loss: 155.177963 [ 1600/ 5994]\n",
      "loss: 119.180901 [ 3200/ 5994]\n",
      "loss: 113.315536 [ 4800/ 5994]\n",
      "Training Loss: 157.5961, Training Accuracy: 50.1502%\n",
      "Test Loss: 198.9295, Test Accuracy: 43.7004%\n",
      "Epoch 52/200-------------------\n",
      "loss: 67.377838 [    0/ 5994]\n",
      "loss: 180.427536 [ 1600/ 5994]\n",
      "loss: 271.938141 [ 3200/ 5994]\n",
      "loss: 89.161041 [ 4800/ 5994]\n",
      "Training Loss: 145.2889, Training Accuracy: 52.0521%\n",
      "Test Loss: 188.3113, Test Accuracy: 43.7867%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 43.7867%\n",
      "Epoch 53/200-------------------\n",
      "loss: 179.832153 [    0/ 5994]\n",
      "loss: 165.050369 [ 1600/ 5994]\n",
      "loss: 206.577957 [ 3200/ 5994]\n",
      "loss: 150.346848 [ 4800/ 5994]\n",
      "Training Loss: 168.4076, Training Accuracy: 49.3827%\n",
      "Test Loss: 211.1307, Test Accuracy: 42.5095%\n",
      "Epoch 54/200-------------------\n",
      "loss: 86.375259 [    0/ 5994]\n",
      "loss: 190.580994 [ 1600/ 5994]\n",
      "loss: 110.953217 [ 3200/ 5994]\n",
      "loss: 106.507904 [ 4800/ 5994]\n",
      "Training Loss: 149.8853, Training Accuracy: 50.5172%\n",
      "Test Loss: 197.0127, Test Accuracy: 42.7339%\n",
      "Epoch 55/200-------------------\n",
      "loss: 110.792557 [    0/ 5994]\n",
      "loss: 102.096687 [ 1600/ 5994]\n",
      "loss: 70.195251 [ 3200/ 5994]\n",
      "loss: 172.921951 [ 4800/ 5994]\n",
      "Training Loss: 157.2904, Training Accuracy: 49.7998%\n",
      "Test Loss: 197.0708, Test Accuracy: 42.6648%\n",
      "Epoch 56/200-------------------\n",
      "loss: 246.022781 [    0/ 5994]\n",
      "loss: 112.794220 [ 1600/ 5994]\n",
      "loss: 139.429016 [ 3200/ 5994]\n",
      "loss: 166.278198 [ 4800/ 5994]\n",
      "Training Loss: 150.5763, Training Accuracy: 50.4671%\n",
      "Test Loss: 194.1728, Test Accuracy: 42.3369%\n",
      "Epoch 57/200-------------------\n",
      "loss: 165.711182 [    0/ 5994]\n",
      "loss: 73.399170 [ 1600/ 5994]\n",
      "loss: 107.307419 [ 3200/ 5994]\n",
      "loss: 201.030609 [ 4800/ 5994]\n",
      "Training Loss: 149.6218, Training Accuracy: 49.6997%\n",
      "Test Loss: 195.1091, Test Accuracy: 42.9755%\n",
      "Epoch 58/200-------------------\n",
      "loss: 35.722832 [    0/ 5994]\n",
      "loss: 215.798492 [ 1600/ 5994]\n",
      "loss: 207.314880 [ 3200/ 5994]\n",
      "loss: 208.754547 [ 4800/ 5994]\n",
      "Training Loss: 134.8961, Training Accuracy: 51.7351%\n",
      "Test Loss: 180.9463, Test Accuracy: 44.1146%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 44.1146%\n",
      "Epoch 59/200-------------------\n",
      "loss: 226.401550 [    0/ 5994]\n",
      "loss: 72.059189 [ 1600/ 5994]\n",
      "loss: 133.113861 [ 3200/ 5994]\n",
      "loss: 131.230637 [ 4800/ 5994]\n",
      "Training Loss: 132.9060, Training Accuracy: 51.8352%\n",
      "Test Loss: 179.5646, Test Accuracy: 44.2699%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 44.2699%\n",
      "Epoch 60/200-------------------\n",
      "loss: 122.039543 [    0/ 5994]\n",
      "loss: 135.899658 [ 1600/ 5994]\n",
      "loss: 154.116180 [ 3200/ 5994]\n",
      "loss: 154.731323 [ 4800/ 5994]\n",
      "Training Loss: 148.0417, Training Accuracy: 47.4474%\n",
      "Test Loss: 193.8933, Test Accuracy: 40.6110%\n",
      "Epoch 61/200-------------------\n",
      "loss: 127.263870 [    0/ 5994]\n",
      "loss: 165.866730 [ 1600/ 5994]\n",
      "loss: 115.965141 [ 3200/ 5994]\n",
      "loss: 143.042755 [ 4800/ 5994]\n",
      "Training Loss: 163.7207, Training Accuracy: 51.6350%\n",
      "Test Loss: 210.4996, Test Accuracy: 43.0618%\n",
      "Epoch 62/200-------------------\n",
      "loss: 312.635254 [    0/ 5994]\n",
      "loss: 124.363289 [ 1600/ 5994]\n",
      "loss: 234.495239 [ 3200/ 5994]\n",
      "loss: 108.302788 [ 4800/ 5994]\n",
      "Training Loss: 156.0560, Training Accuracy: 49.3493%\n",
      "Test Loss: 205.5770, Test Accuracy: 41.9917%\n",
      "Epoch 63/200-------------------\n",
      "loss: 73.394302 [    0/ 5994]\n",
      "loss: 295.282806 [ 1600/ 5994]\n",
      "loss: 317.132904 [ 3200/ 5994]\n",
      "loss: 131.273804 [ 4800/ 5994]\n",
      "Training Loss: 160.3121, Training Accuracy: 50.0501%\n",
      "Test Loss: 210.8585, Test Accuracy: 42.1816%\n",
      "Epoch 64/200-------------------\n",
      "loss: 180.568817 [    0/ 5994]\n",
      "loss: 209.187469 [ 1600/ 5994]\n",
      "loss: 142.237213 [ 3200/ 5994]\n",
      "loss: 144.737457 [ 4800/ 5994]\n",
      "Training Loss: 154.3436, Training Accuracy: 49.4328%\n",
      "Test Loss: 199.8650, Test Accuracy: 41.9227%\n",
      "Epoch 65/200-------------------\n",
      "loss: 178.146027 [    0/ 5994]\n",
      "loss: 237.103989 [ 1600/ 5994]\n",
      "loss: 264.523682 [ 3200/ 5994]\n",
      "loss: 113.889610 [ 4800/ 5994]\n",
      "Training Loss: 149.0032, Training Accuracy: 52.8862%\n",
      "Test Loss: 199.1182, Test Accuracy: 44.6842%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 44.6842%\n",
      "Epoch 66/200-------------------\n",
      "loss: 148.123505 [    0/ 5994]\n",
      "loss: 208.180740 [ 1600/ 5994]\n",
      "loss: 131.265015 [ 3200/ 5994]\n",
      "loss: 66.487869 [ 4800/ 5994]\n",
      "Training Loss: 145.7142, Training Accuracy: 51.0677%\n",
      "Test Loss: 198.2053, Test Accuracy: 42.3024%\n",
      "Epoch 67/200-------------------\n",
      "loss: 163.179413 [    0/ 5994]\n",
      "loss: 97.665039 [ 1600/ 5994]\n",
      "loss: 84.424393 [ 3200/ 5994]\n",
      "loss: 135.683563 [ 4800/ 5994]\n",
      "Training Loss: 151.3560, Training Accuracy: 49.7831%\n",
      "Test Loss: 204.2310, Test Accuracy: 41.0252%\n",
      "Epoch 68/200-------------------\n",
      "loss: 178.463364 [    0/ 5994]\n",
      "loss: 115.967804 [ 1600/ 5994]\n",
      "loss: 252.241394 [ 3200/ 5994]\n",
      "loss: 175.514603 [ 4800/ 5994]\n",
      "Training Loss: 177.6192, Training Accuracy: 49.7998%\n",
      "Test Loss: 226.4377, Test Accuracy: 41.7501%\n",
      "Epoch 69/200-------------------\n",
      "loss: 187.424927 [    0/ 5994]\n",
      "loss: 135.092484 [ 1600/ 5994]\n",
      "loss: 185.637665 [ 3200/ 5994]\n",
      "loss: 110.349060 [ 4800/ 5994]\n",
      "Training Loss: 158.8294, Training Accuracy: 51.2679%\n",
      "Test Loss: 209.8538, Test Accuracy: 44.1146%\n",
      "Epoch 70/200-------------------\n",
      "loss: 133.929657 [    0/ 5994]\n",
      "loss: 119.488503 [ 1600/ 5994]\n",
      "loss: 186.653168 [ 3200/ 5994]\n",
      "loss: 192.224945 [ 4800/ 5994]\n",
      "Training Loss: 150.5066, Training Accuracy: 51.2679%\n",
      "Test Loss: 197.4758, Test Accuracy: 44.3390%\n",
      "Epoch 71/200-------------------\n",
      "loss: 26.007931 [    0/ 5994]\n",
      "loss: 290.431183 [ 1600/ 5994]\n",
      "loss: 253.369614 [ 3200/ 5994]\n",
      "loss: 80.437408 [ 4800/ 5994]\n",
      "Training Loss: 123.9722, Training Accuracy: 55.1385%\n",
      "Test Loss: 172.1708, Test Accuracy: 46.0649%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 46.0649%\n",
      "Epoch 72/200-------------------\n",
      "loss: 191.138016 [    0/ 5994]\n",
      "loss: 267.149475 [ 1600/ 5994]\n",
      "loss: 142.688232 [ 3200/ 5994]\n",
      "loss: 166.947815 [ 4800/ 5994]\n",
      "Training Loss: 124.9858, Training Accuracy: 54.6713%\n",
      "Test Loss: 175.1509, Test Accuracy: 44.9776%\n",
      "Epoch 73/200-------------------\n",
      "loss: 123.030617 [    0/ 5994]\n",
      "loss: 163.975601 [ 1600/ 5994]\n",
      "loss: 77.761330 [ 3200/ 5994]\n",
      "loss: 178.377045 [ 4800/ 5994]\n",
      "Training Loss: 167.0639, Training Accuracy: 51.7684%\n",
      "Test Loss: 217.7395, Test Accuracy: 44.1146%\n",
      "Epoch 74/200-------------------\n",
      "loss: 141.818634 [    0/ 5994]\n",
      "loss: 165.209106 [ 1600/ 5994]\n",
      "loss: 275.103333 [ 3200/ 5994]\n",
      "loss: 44.607819 [ 4800/ 5994]\n",
      "Training Loss: 145.3716, Training Accuracy: 52.0354%\n",
      "Test Loss: 197.0662, Test Accuracy: 44.1319%\n",
      "Epoch 75/200-------------------\n",
      "loss: 96.142410 [    0/ 5994]\n",
      "loss: 84.744873 [ 1600/ 5994]\n",
      "loss: 251.670517 [ 3200/ 5994]\n",
      "loss: 187.638138 [ 4800/ 5994]\n",
      "Training Loss: 135.8528, Training Accuracy: 54.5045%\n",
      "Test Loss: 186.0402, Test Accuracy: 45.6334%\n",
      "Epoch 76/200-------------------\n",
      "loss: 215.234268 [    0/ 5994]\n",
      "loss: 112.397987 [ 1600/ 5994]\n",
      "loss: 175.655853 [ 3200/ 5994]\n",
      "loss: 128.547272 [ 4800/ 5994]\n",
      "Training Loss: 141.9581, Training Accuracy: 54.1208%\n",
      "Test Loss: 195.8886, Test Accuracy: 45.0293%\n",
      "Epoch 77/200-------------------\n",
      "loss: 123.859650 [    0/ 5994]\n",
      "loss: 149.593613 [ 1600/ 5994]\n",
      "loss: 101.231209 [ 3200/ 5994]\n",
      "loss: 90.099220 [ 4800/ 5994]\n",
      "Training Loss: 140.4852, Training Accuracy: 53.1532%\n",
      "Test Loss: 194.3287, Test Accuracy: 44.4080%\n",
      "Epoch 78/200-------------------\n",
      "loss: 361.194946 [    0/ 5994]\n",
      "loss: 212.319092 [ 1600/ 5994]\n",
      "loss: 194.833221 [ 3200/ 5994]\n",
      "loss: 156.420105 [ 4800/ 5994]\n",
      "Training Loss: 158.5713, Training Accuracy: 51.9186%\n",
      "Test Loss: 211.5670, Test Accuracy: 44.3217%\n",
      "Epoch 79/200-------------------\n",
      "loss: 235.956955 [    0/ 5994]\n",
      "loss: 123.525978 [ 1600/ 5994]\n",
      "loss: 148.245438 [ 3200/ 5994]\n",
      "loss: 136.222717 [ 4800/ 5994]\n",
      "Training Loss: 148.0223, Training Accuracy: 54.5379%\n",
      "Test Loss: 202.6082, Test Accuracy: 45.5471%\n",
      "Epoch 80/200-------------------\n",
      "loss: 165.856079 [    0/ 5994]\n",
      "loss: 157.677795 [ 1600/ 5994]\n",
      "loss: 241.451355 [ 3200/ 5994]\n",
      "loss: 175.677658 [ 4800/ 5994]\n",
      "Training Loss: 156.9082, Training Accuracy: 52.5025%\n",
      "Test Loss: 209.3751, Test Accuracy: 43.3207%\n",
      "Epoch 81/200-------------------\n",
      "loss: 368.144745 [    0/ 5994]\n",
      "loss: 397.933960 [ 1600/ 5994]\n",
      "loss: 152.806686 [ 3200/ 5994]\n",
      "loss: 76.068321 [ 4800/ 5994]\n",
      "Training Loss: 125.4371, Training Accuracy: 56.5232%\n",
      "Test Loss: 178.4825, Test Accuracy: 47.2558%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 47.2558%\n",
      "Epoch 82/200-------------------\n",
      "loss: 156.135666 [    0/ 5994]\n",
      "loss: 238.424576 [ 1600/ 5994]\n",
      "loss: 174.219574 [ 3200/ 5994]\n",
      "loss: 84.148521 [ 4800/ 5994]\n",
      "Training Loss: 139.0242, Training Accuracy: 53.0864%\n",
      "Test Loss: 189.8095, Test Accuracy: 44.4253%\n",
      "Epoch 83/200-------------------\n",
      "loss: 77.296959 [    0/ 5994]\n",
      "loss: 143.077972 [ 1600/ 5994]\n",
      "loss: 142.301773 [ 3200/ 5994]\n",
      "loss: 167.650116 [ 4800/ 5994]\n",
      "Training Loss: 162.7543, Training Accuracy: 52.6860%\n",
      "Test Loss: 217.9843, Test Accuracy: 44.9258%\n",
      "Epoch 84/200-------------------\n",
      "loss: 237.631332 [    0/ 5994]\n",
      "loss: 200.883408 [ 1600/ 5994]\n",
      "loss: 98.193520 [ 3200/ 5994]\n",
      "loss: 90.744263 [ 4800/ 5994]\n",
      "Training Loss: 123.9351, Training Accuracy: 55.8892%\n",
      "Test Loss: 178.2636, Test Accuracy: 45.5126%\n",
      "Epoch 85/200-------------------\n",
      "loss: 125.608894 [    0/ 5994]\n",
      "loss: 128.247955 [ 1600/ 5994]\n",
      "loss: 209.000031 [ 3200/ 5994]\n",
      "loss: 173.824982 [ 4800/ 5994]\n",
      "Training Loss: 127.6636, Training Accuracy: 56.8902%\n",
      "Test Loss: 180.5227, Test Accuracy: 47.6010%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 47.6010%\n",
      "Epoch 86/200-------------------\n",
      "loss: 78.271179 [    0/ 5994]\n",
      "loss: 229.448471 [ 1600/ 5994]\n",
      "loss: 125.511002 [ 3200/ 5994]\n",
      "loss: 175.496002 [ 4800/ 5994]\n",
      "Training Loss: 145.8782, Training Accuracy: 54.0040%\n",
      "Test Loss: 202.7479, Test Accuracy: 44.9085%\n",
      "Epoch 87/200-------------------\n",
      "loss: 225.782669 [    0/ 5994]\n",
      "loss: 136.319122 [ 1600/ 5994]\n",
      "loss: 184.592651 [ 3200/ 5994]\n",
      "loss: 227.583099 [ 4800/ 5994]\n",
      "Training Loss: 142.5340, Training Accuracy: 52.9029%\n",
      "Test Loss: 195.3628, Test Accuracy: 44.6151%\n",
      "Epoch 88/200-------------------\n",
      "loss: 164.413437 [    0/ 5994]\n",
      "loss: 106.819038 [ 1600/ 5994]\n",
      "loss: 84.144173 [ 3200/ 5994]\n",
      "loss: 144.213043 [ 4800/ 5994]\n",
      "Training Loss: 163.1204, Training Accuracy: 49.8165%\n",
      "Test Loss: 215.4486, Test Accuracy: 41.5775%\n",
      "Epoch 89/200-------------------\n",
      "loss: 94.313599 [    0/ 5994]\n",
      "loss: 92.200226 [ 1600/ 5994]\n",
      "loss: 215.184067 [ 3200/ 5994]\n",
      "loss: 39.639580 [ 4800/ 5994]\n",
      "Training Loss: 117.0679, Training Accuracy: 58.7754%\n",
      "Test Loss: 172.6691, Test Accuracy: 49.1198%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 49.1198%\n",
      "Epoch 90/200-------------------\n",
      "loss: 139.768005 [    0/ 5994]\n",
      "loss: 164.403030 [ 1600/ 5994]\n",
      "loss: 219.121887 [ 3200/ 5994]\n",
      "loss: 240.857346 [ 4800/ 5994]\n",
      "Training Loss: 141.3362, Training Accuracy: 55.7891%\n",
      "Test Loss: 194.6120, Test Accuracy: 46.2720%\n",
      "Epoch 91/200-------------------\n",
      "loss: 78.568550 [    0/ 5994]\n",
      "loss: 138.381180 [ 1600/ 5994]\n",
      "loss: 26.502312 [ 3200/ 5994]\n",
      "loss: 176.043793 [ 4800/ 5994]\n",
      "Training Loss: 149.4729, Training Accuracy: 53.4701%\n",
      "Test Loss: 204.7342, Test Accuracy: 45.0984%\n",
      "Epoch 92/200-------------------\n",
      "loss: 135.789780 [    0/ 5994]\n",
      "loss: 340.243530 [ 1600/ 5994]\n",
      "loss: 122.333160 [ 3200/ 5994]\n",
      "loss: 179.380280 [ 4800/ 5994]\n",
      "Training Loss: 125.1021, Training Accuracy: 56.5232%\n",
      "Test Loss: 180.5705, Test Accuracy: 46.4619%\n",
      "Epoch 93/200-------------------\n",
      "loss: 145.544067 [    0/ 5994]\n",
      "loss: 76.233185 [ 1600/ 5994]\n",
      "loss: 129.676453 [ 3200/ 5994]\n",
      "loss: 279.501831 [ 4800/ 5994]\n",
      "Training Loss: 113.0605, Training Accuracy: 57.4575%\n",
      "Test Loss: 166.3338, Test Accuracy: 48.3949%\n",
      "Epoch 94/200-------------------\n",
      "loss: 140.656311 [    0/ 5994]\n",
      "loss: 77.257866 [ 1600/ 5994]\n",
      "loss: 75.530701 [ 3200/ 5994]\n",
      "loss: 192.099167 [ 4800/ 5994]\n",
      "Training Loss: 153.3490, Training Accuracy: 51.9520%\n",
      "Test Loss: 213.9652, Test Accuracy: 42.3714%\n",
      "Epoch 95/200-------------------\n",
      "loss: 123.335396 [    0/ 5994]\n",
      "loss: 134.425537 [ 1600/ 5994]\n",
      "loss: 109.854538 [ 3200/ 5994]\n",
      "loss: 80.746971 [ 4800/ 5994]\n",
      "Training Loss: 128.7426, Training Accuracy: 54.4711%\n",
      "Test Loss: 188.3342, Test Accuracy: 45.3227%\n",
      "Epoch 96/200-------------------\n",
      "loss: 198.114532 [    0/ 5994]\n",
      "loss: 95.013458 [ 1600/ 5994]\n",
      "loss: 64.759689 [ 3200/ 5994]\n",
      "loss: 121.156219 [ 4800/ 5994]\n",
      "Training Loss: 142.7665, Training Accuracy: 53.9873%\n",
      "Test Loss: 201.6113, Test Accuracy: 44.4770%\n",
      "Epoch 97/200-------------------\n",
      "loss: 275.644623 [    0/ 5994]\n",
      "loss: 229.437241 [ 1600/ 5994]\n",
      "loss: 98.595360 [ 3200/ 5994]\n",
      "loss: 248.873108 [ 4800/ 5994]\n",
      "Training Loss: 141.4478, Training Accuracy: 52.5526%\n",
      "Test Loss: 199.3127, Test Accuracy: 44.1319%\n",
      "Epoch 98/200-------------------\n",
      "loss: 163.541794 [    0/ 5994]\n",
      "loss: 158.130951 [ 1600/ 5994]\n",
      "loss: 63.760513 [ 3200/ 5994]\n",
      "loss: 83.040764 [ 4800/ 5994]\n",
      "Training Loss: 143.9779, Training Accuracy: 54.3210%\n",
      "Test Loss: 204.0262, Test Accuracy: 45.0121%\n",
      "Epoch 99/200-------------------\n",
      "loss: 203.332123 [    0/ 5994]\n",
      "loss: 111.372864 [ 1600/ 5994]\n",
      "loss: 114.707069 [ 3200/ 5994]\n",
      "loss: 87.978828 [ 4800/ 5994]\n",
      "Training Loss: 164.7183, Training Accuracy: 52.4191%\n",
      "Test Loss: 221.2713, Test Accuracy: 43.3552%\n",
      "Epoch 100/200-------------------\n",
      "loss: 310.421326 [    0/ 5994]\n",
      "loss: 196.868362 [ 1600/ 5994]\n",
      "loss: 217.224670 [ 3200/ 5994]\n",
      "loss: 166.289612 [ 4800/ 5994]\n",
      "Training Loss: 142.3192, Training Accuracy: 55.5055%\n",
      "Test Loss: 203.1700, Test Accuracy: 45.3400%\n",
      "Epoch 101/200-------------------\n",
      "loss: 156.101242 [    0/ 5994]\n",
      "loss: 174.126892 [ 1600/ 5994]\n",
      "loss: 216.708710 [ 3200/ 5994]\n",
      "loss: 151.146240 [ 4800/ 5994]\n",
      "Training Loss: 135.7820, Training Accuracy: 55.6723%\n",
      "Test Loss: 193.1660, Test Accuracy: 47.1177%\n",
      "Epoch 102/200-------------------\n",
      "loss: 178.641068 [    0/ 5994]\n",
      "loss: 178.130249 [ 1600/ 5994]\n",
      "loss: 105.322311 [ 3200/ 5994]\n",
      "loss: 105.133591 [ 4800/ 5994]\n",
      "Training Loss: 128.9857, Training Accuracy: 55.9893%\n",
      "Test Loss: 189.0446, Test Accuracy: 46.5482%\n",
      "Epoch 103/200-------------------\n",
      "loss: 84.630020 [    0/ 5994]\n",
      "loss: 109.562027 [ 1600/ 5994]\n",
      "loss: 120.900826 [ 3200/ 5994]\n",
      "loss: 208.290161 [ 4800/ 5994]\n",
      "Training Loss: 146.0515, Training Accuracy: 55.4388%\n",
      "Test Loss: 206.1900, Test Accuracy: 45.5989%\n",
      "Epoch 104/200-------------------\n",
      "loss: 117.396523 [    0/ 5994]\n",
      "loss: 149.572815 [ 1600/ 5994]\n",
      "loss: 126.343681 [ 3200/ 5994]\n",
      "loss: 207.774628 [ 4800/ 5994]\n",
      "Training Loss: 113.3917, Training Accuracy: 56.7734%\n",
      "Test Loss: 173.1612, Test Accuracy: 47.2385%\n",
      "Epoch 105/200-------------------\n",
      "loss: 162.838394 [    0/ 5994]\n",
      "loss: 139.936859 [ 1600/ 5994]\n",
      "loss: 205.950134 [ 3200/ 5994]\n",
      "loss: 249.793121 [ 4800/ 5994]\n",
      "Training Loss: 144.2888, Training Accuracy: 53.1198%\n",
      "Test Loss: 207.1204, Test Accuracy: 43.2689%\n",
      "Epoch 106/200-------------------\n",
      "loss: 141.050217 [    0/ 5994]\n",
      "loss: 173.120560 [ 1600/ 5994]\n",
      "loss: 218.750565 [ 3200/ 5994]\n",
      "loss: 228.905457 [ 4800/ 5994]\n",
      "Training Loss: 145.4510, Training Accuracy: 54.4545%\n",
      "Test Loss: 206.0348, Test Accuracy: 45.6852%\n",
      "Epoch 107/200-------------------\n",
      "loss: 187.761032 [    0/ 5994]\n",
      "loss: 97.330460 [ 1600/ 5994]\n",
      "loss: 131.056229 [ 3200/ 5994]\n",
      "loss: 142.443329 [ 4800/ 5994]\n",
      "Training Loss: 150.0339, Training Accuracy: 54.8715%\n",
      "Test Loss: 208.7562, Test Accuracy: 44.7877%\n",
      "Epoch 108/200-------------------\n",
      "loss: 130.408890 [    0/ 5994]\n",
      "loss: 112.043236 [ 1600/ 5994]\n",
      "loss: 72.335762 [ 3200/ 5994]\n",
      "loss: 97.670212 [ 4800/ 5994]\n",
      "Training Loss: 153.6962, Training Accuracy: 55.3554%\n",
      "Test Loss: 217.6540, Test Accuracy: 44.8050%\n",
      "Epoch 109/200-------------------\n",
      "loss: 69.920197 [    0/ 5994]\n",
      "loss: 158.875076 [ 1600/ 5994]\n",
      "loss: 110.184280 [ 3200/ 5994]\n",
      "loss: 93.672256 [ 4800/ 5994]\n",
      "Training Loss: 136.9796, Training Accuracy: 54.6547%\n",
      "Test Loss: 197.7107, Test Accuracy: 45.3745%\n",
      "Epoch 110/200-------------------\n",
      "loss: 95.204567 [    0/ 5994]\n",
      "loss: 203.778290 [ 1600/ 5994]\n",
      "loss: 196.418213 [ 3200/ 5994]\n",
      "loss: 20.774260 [ 4800/ 5994]\n",
      "Training Loss: 137.2423, Training Accuracy: 56.5899%\n",
      "Test Loss: 197.5547, Test Accuracy: 47.9289%\n",
      "Epoch 111/200-------------------\n",
      "loss: 102.967476 [    0/ 5994]\n",
      "loss: 82.790436 [ 1600/ 5994]\n",
      "loss: 30.345583 [ 3200/ 5994]\n",
      "loss: 134.194702 [ 4800/ 5994]\n",
      "Training Loss: 140.5053, Training Accuracy: 56.9736%\n",
      "Test Loss: 203.4197, Test Accuracy: 46.5654%\n",
      "Epoch 112/200-------------------\n",
      "loss: 196.567993 [    0/ 5994]\n",
      "loss: 98.042236 [ 1600/ 5994]\n",
      "loss: 102.154892 [ 3200/ 5994]\n",
      "loss: 199.490097 [ 4800/ 5994]\n",
      "Training Loss: 144.6947, Training Accuracy: 57.2072%\n",
      "Test Loss: 206.6796, Test Accuracy: 47.7908%\n",
      "Epoch 113/200-------------------\n",
      "loss: 34.060509 [    0/ 5994]\n",
      "loss: 77.944374 [ 1600/ 5994]\n",
      "loss: 89.589508 [ 3200/ 5994]\n",
      "loss: 95.302681 [ 4800/ 5994]\n",
      "Training Loss: 132.6860, Training Accuracy: 56.5399%\n",
      "Test Loss: 195.1326, Test Accuracy: 46.3756%\n",
      "Epoch 114/200-------------------\n",
      "loss: 89.577217 [    0/ 5994]\n",
      "loss: 235.231796 [ 1600/ 5994]\n",
      "loss: 158.087875 [ 3200/ 5994]\n",
      "loss: 68.079666 [ 4800/ 5994]\n",
      "Training Loss: 129.3978, Training Accuracy: 55.6723%\n",
      "Test Loss: 189.5283, Test Accuracy: 45.3573%\n",
      "Epoch 115/200-------------------\n",
      "loss: 160.665405 [    0/ 5994]\n",
      "loss: 63.249565 [ 1600/ 5994]\n",
      "loss: 82.650131 [ 3200/ 5994]\n",
      "loss: 52.888832 [ 4800/ 5994]\n",
      "Training Loss: 135.7899, Training Accuracy: 54.9883%\n",
      "Test Loss: 200.3938, Test Accuracy: 45.5644%\n",
      "Epoch 116/200-------------------\n",
      "loss: 84.974907 [    0/ 5994]\n",
      "loss: 332.899231 [ 1600/ 5994]\n",
      "loss: 122.126526 [ 3200/ 5994]\n",
      "loss: 197.650726 [ 4800/ 5994]\n",
      "Training Loss: 125.9633, Training Accuracy: 56.8902%\n",
      "Test Loss: 191.0829, Test Accuracy: 46.6862%\n",
      "Epoch 117/200-------------------\n",
      "loss: 186.064102 [    0/ 5994]\n",
      "loss: 80.706718 [ 1600/ 5994]\n",
      "loss: 101.406425 [ 3200/ 5994]\n",
      "loss: 146.016602 [ 4800/ 5994]\n",
      "Training Loss: 127.3438, Training Accuracy: 59.1425%\n",
      "Test Loss: 190.3434, Test Accuracy: 47.7736%\n",
      "Epoch 118/200-------------------\n",
      "loss: 166.998138 [    0/ 5994]\n",
      "loss: 85.203079 [ 1600/ 5994]\n",
      "loss: 225.496002 [ 3200/ 5994]\n",
      "loss: 89.805122 [ 4800/ 5994]\n",
      "Training Loss: 129.2668, Training Accuracy: 55.4388%\n",
      "Test Loss: 192.4856, Test Accuracy: 45.9786%\n",
      "Epoch 119/200-------------------\n",
      "loss: 90.515884 [    0/ 5994]\n",
      "loss: 94.170837 [ 1600/ 5994]\n",
      "loss: 98.640816 [ 3200/ 5994]\n",
      "loss: 90.482292 [ 4800/ 5994]\n",
      "Training Loss: 130.5932, Training Accuracy: 55.6223%\n",
      "Test Loss: 192.5084, Test Accuracy: 45.8060%\n",
      "Epoch 120/200-------------------\n",
      "loss: 201.471481 [    0/ 5994]\n",
      "loss: 46.328251 [ 1600/ 5994]\n",
      "loss: 63.279312 [ 3200/ 5994]\n",
      "loss: 233.626007 [ 4800/ 5994]\n",
      "Training Loss: 133.3199, Training Accuracy: 57.3240%\n",
      "Test Loss: 193.1911, Test Accuracy: 46.5309%\n",
      "Epoch 121/200-------------------\n",
      "loss: 182.858856 [    0/ 5994]\n",
      "loss: 86.301880 [ 1600/ 5994]\n",
      "loss: 97.056114 [ 3200/ 5994]\n",
      "loss: 199.047607 [ 4800/ 5994]\n",
      "Training Loss: 131.2333, Training Accuracy: 58.2082%\n",
      "Test Loss: 191.0982, Test Accuracy: 48.7228%\n",
      "Epoch 122/200-------------------\n",
      "loss: 344.766296 [    0/ 5994]\n",
      "loss: 107.414490 [ 1600/ 5994]\n",
      "loss: 149.526031 [ 3200/ 5994]\n",
      "loss: 292.794861 [ 4800/ 5994]\n",
      "Training Loss: 138.6946, Training Accuracy: 56.7067%\n",
      "Test Loss: 201.7207, Test Accuracy: 47.2040%\n",
      "Epoch 123/200-------------------\n",
      "loss: 148.256134 [    0/ 5994]\n",
      "loss: 215.027390 [ 1600/ 5994]\n",
      "loss: 73.430077 [ 3200/ 5994]\n",
      "loss: 103.572342 [ 4800/ 5994]\n",
      "Training Loss: 140.4430, Training Accuracy: 54.8048%\n",
      "Test Loss: 205.5816, Test Accuracy: 44.7705%\n",
      "Epoch 124/200-------------------\n",
      "loss: 269.858246 [    0/ 5994]\n",
      "loss: 136.979599 [ 1600/ 5994]\n",
      "loss: 37.550362 [ 3200/ 5994]\n",
      "loss: 57.140194 [ 4800/ 5994]\n",
      "Training Loss: 131.6420, Training Accuracy: 57.4575%\n",
      "Test Loss: 198.8586, Test Accuracy: 47.0314%\n",
      "Epoch 125/200-------------------\n",
      "loss: 33.677170 [    0/ 5994]\n",
      "loss: 37.535789 [ 1600/ 5994]\n",
      "loss: 80.871918 [ 3200/ 5994]\n",
      "loss: 48.210289 [ 4800/ 5994]\n",
      "Training Loss: 141.3612, Training Accuracy: 55.4054%\n",
      "Test Loss: 204.2301, Test Accuracy: 46.2547%\n",
      "Epoch 126/200-------------------\n",
      "loss: 1.221748 [    0/ 5994]\n",
      "loss: 107.364197 [ 1600/ 5994]\n",
      "loss: 157.421371 [ 3200/ 5994]\n",
      "loss: 155.769470 [ 4800/ 5994]\n",
      "Training Loss: 150.4242, Training Accuracy: 54.7881%\n",
      "Test Loss: 218.9236, Test Accuracy: 45.4436%\n",
      "Epoch 127/200-------------------\n",
      "loss: 191.143707 [    0/ 5994]\n",
      "loss: 77.187469 [ 1600/ 5994]\n",
      "loss: 184.102158 [ 3200/ 5994]\n",
      "loss: 143.075134 [ 4800/ 5994]\n",
      "Training Loss: 137.3284, Training Accuracy: 54.7714%\n",
      "Test Loss: 200.7272, Test Accuracy: 45.0293%\n",
      "Epoch 128/200-------------------\n",
      "loss: 133.126465 [    0/ 5994]\n",
      "loss: 97.268448 [ 1600/ 5994]\n",
      "loss: 68.638374 [ 3200/ 5994]\n",
      "loss: 28.235229 [ 4800/ 5994]\n",
      "Training Loss: 129.0520, Training Accuracy: 56.9903%\n",
      "Test Loss: 194.2030, Test Accuracy: 46.9106%\n",
      "Epoch 129/200-------------------\n",
      "loss: 194.701859 [    0/ 5994]\n",
      "loss: 135.470001 [ 1600/ 5994]\n",
      "loss: 50.253731 [ 3200/ 5994]\n",
      "loss: 62.253716 [ 4800/ 5994]\n",
      "Training Loss: 121.6337, Training Accuracy: 57.7911%\n",
      "Test Loss: 188.9644, Test Accuracy: 46.9106%\n",
      "Epoch 130/200-------------------\n",
      "loss: 139.502563 [    0/ 5994]\n",
      "loss: 168.156967 [ 1600/ 5994]\n",
      "loss: 113.680420 [ 3200/ 5994]\n",
      "loss: 161.318756 [ 4800/ 5994]\n",
      "Training Loss: 132.4528, Training Accuracy: 57.6410%\n",
      "Test Loss: 195.1981, Test Accuracy: 47.2730%\n",
      "Epoch 131/200-------------------\n",
      "loss: 172.843353 [    0/ 5994]\n",
      "loss: 93.946564 [ 1600/ 5994]\n",
      "loss: 91.702148 [ 3200/ 5994]\n",
      "loss: 121.455490 [ 4800/ 5994]\n",
      "Training Loss: 129.1237, Training Accuracy: 55.4221%\n",
      "Test Loss: 194.3243, Test Accuracy: 46.3410%\n",
      "Epoch 132/200-------------------\n",
      "loss: 47.440918 [    0/ 5994]\n",
      "loss: 129.451721 [ 1600/ 5994]\n",
      "loss: 142.157410 [ 3200/ 5994]\n",
      "loss: 254.645416 [ 4800/ 5994]\n",
      "Training Loss: 157.8655, Training Accuracy: 55.7558%\n",
      "Test Loss: 223.8325, Test Accuracy: 45.1674%\n",
      "Epoch 133/200-------------------\n",
      "loss: 258.805969 [    0/ 5994]\n",
      "loss: 105.563560 [ 1600/ 5994]\n",
      "loss: 103.430908 [ 3200/ 5994]\n",
      "loss: 142.807526 [ 4800/ 5994]\n",
      "Training Loss: 135.2735, Training Accuracy: 57.5742%\n",
      "Test Loss: 202.2510, Test Accuracy: 46.7725%\n",
      "Epoch 134/200-------------------\n",
      "loss: 195.722473 [    0/ 5994]\n",
      "loss: 75.436722 [ 1600/ 5994]\n",
      "loss: 90.776680 [ 3200/ 5994]\n",
      "loss: 120.166801 [ 4800/ 5994]\n",
      "Training Loss: 134.8237, Training Accuracy: 58.3250%\n",
      "Test Loss: 202.8774, Test Accuracy: 47.5664%\n",
      "Epoch 135/200-------------------\n",
      "loss: 76.831360 [    0/ 5994]\n",
      "loss: 125.892410 [ 1600/ 5994]\n",
      "loss: 85.881447 [ 3200/ 5994]\n",
      "loss: 93.174057 [ 4800/ 5994]\n",
      "Training Loss: 143.0640, Training Accuracy: 55.3220%\n",
      "Test Loss: 210.1130, Test Accuracy: 45.4781%\n",
      "Epoch 136/200-------------------\n",
      "loss: 89.686653 [    0/ 5994]\n",
      "loss: 206.770935 [ 1600/ 5994]\n",
      "loss: 154.279190 [ 3200/ 5994]\n",
      "loss: 160.288025 [ 4800/ 5994]\n",
      "Training Loss: 136.4820, Training Accuracy: 58.2749%\n",
      "Test Loss: 202.3543, Test Accuracy: 47.1350%\n",
      "Epoch 137/200-------------------\n",
      "loss: 191.633209 [    0/ 5994]\n",
      "loss: 205.207672 [ 1600/ 5994]\n",
      "loss: 162.368835 [ 3200/ 5994]\n",
      "loss: 85.934708 [ 4800/ 5994]\n",
      "Training Loss: 158.4766, Training Accuracy: 55.2386%\n",
      "Test Loss: 221.7658, Test Accuracy: 45.3745%\n",
      "Epoch 138/200-------------------\n",
      "loss: 167.125595 [    0/ 5994]\n",
      "loss: 58.173439 [ 1600/ 5994]\n",
      "loss: 149.098587 [ 3200/ 5994]\n",
      "loss: 98.621574 [ 4800/ 5994]\n",
      "Training Loss: 128.9143, Training Accuracy: 57.2239%\n",
      "Test Loss: 191.8015, Test Accuracy: 47.0659%\n",
      "Epoch 139/200-------------------\n",
      "loss: 193.380402 [    0/ 5994]\n",
      "loss: 28.244524 [ 1600/ 5994]\n",
      "loss: 56.081570 [ 3200/ 5994]\n",
      "loss: 75.553101 [ 4800/ 5994]\n",
      "Training Loss: 133.7765, Training Accuracy: 56.0394%\n",
      "Test Loss: 204.0879, Test Accuracy: 45.7715%\n",
      "Epoch 140/200-------------------\n",
      "loss: 149.907394 [    0/ 5994]\n",
      "loss: 78.742020 [ 1600/ 5994]\n",
      "loss: 139.855362 [ 3200/ 5994]\n",
      "loss: 200.577942 [ 4800/ 5994]\n",
      "Training Loss: 147.6117, Training Accuracy: 52.4691%\n",
      "Test Loss: 221.9800, Test Accuracy: 42.6648%\n",
      "Epoch 141/200-------------------\n",
      "loss: 149.403870 [    0/ 5994]\n",
      "loss: 86.272110 [ 1600/ 5994]\n",
      "loss: 198.549225 [ 3200/ 5994]\n",
      "loss: 117.609535 [ 4800/ 5994]\n",
      "Training Loss: 104.1324, Training Accuracy: 60.5272%\n",
      "Test Loss: 172.3473, Test Accuracy: 49.6721%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 49.6721%\n",
      "Epoch 142/200-------------------\n",
      "loss: 153.991562 [    0/ 5994]\n",
      "loss: 85.427795 [ 1600/ 5994]\n",
      "loss: 160.240570 [ 3200/ 5994]\n",
      "loss: 98.874741 [ 4800/ 5994]\n",
      "Training Loss: 110.3742, Training Accuracy: 60.0434%\n",
      "Test Loss: 173.4478, Test Accuracy: 49.0335%\n",
      "Epoch 143/200-------------------\n",
      "loss: 175.912796 [    0/ 5994]\n",
      "loss: 99.232986 [ 1600/ 5994]\n",
      "loss: 76.441849 [ 3200/ 5994]\n",
      "loss: 134.889587 [ 4800/ 5994]\n",
      "Training Loss: 118.4110, Training Accuracy: 57.4741%\n",
      "Test Loss: 184.0672, Test Accuracy: 46.8243%\n",
      "Epoch 144/200-------------------\n",
      "loss: 59.172306 [    0/ 5994]\n",
      "loss: 212.719635 [ 1600/ 5994]\n",
      "loss: 59.174896 [ 3200/ 5994]\n",
      "loss: 73.127632 [ 4800/ 5994]\n",
      "Training Loss: 126.5882, Training Accuracy: 58.1582%\n",
      "Test Loss: 194.4013, Test Accuracy: 47.0142%\n",
      "Epoch 145/200-------------------\n",
      "loss: 186.366837 [    0/ 5994]\n",
      "loss: 131.142181 [ 1600/ 5994]\n",
      "loss: 116.134750 [ 3200/ 5994]\n",
      "loss: 140.315567 [ 4800/ 5994]\n",
      "Training Loss: 128.4535, Training Accuracy: 60.3437%\n",
      "Test Loss: 198.7409, Test Accuracy: 48.8091%\n",
      "Epoch 146/200-------------------\n",
      "loss: 69.130821 [    0/ 5994]\n",
      "loss: 123.627914 [ 1600/ 5994]\n",
      "loss: 69.852631 [ 3200/ 5994]\n",
      "loss: 318.203796 [ 4800/ 5994]\n",
      "Training Loss: 140.1633, Training Accuracy: 55.7724%\n",
      "Test Loss: 208.8108, Test Accuracy: 45.8750%\n",
      "Epoch 147/200-------------------\n",
      "loss: 101.279099 [    0/ 5994]\n",
      "loss: 79.250809 [ 1600/ 5994]\n",
      "loss: 68.458061 [ 3200/ 5994]\n",
      "loss: 53.546101 [ 4800/ 5994]\n",
      "Training Loss: 108.8812, Training Accuracy: 59.8098%\n",
      "Test Loss: 174.7728, Test Accuracy: 49.2406%\n",
      "Epoch 148/200-------------------\n",
      "loss: 62.017685 [    0/ 5994]\n",
      "loss: 114.724937 [ 1600/ 5994]\n",
      "loss: 95.812325 [ 3200/ 5994]\n",
      "loss: 221.520020 [ 4800/ 5994]\n",
      "Training Loss: 124.1988, Training Accuracy: 57.5742%\n",
      "Test Loss: 191.3293, Test Accuracy: 47.9116%\n",
      "Epoch 149/200-------------------\n",
      "loss: 73.212723 [    0/ 5994]\n",
      "loss: 110.648399 [ 1600/ 5994]\n",
      "loss: 41.753212 [ 3200/ 5994]\n",
      "loss: 100.409798 [ 4800/ 5994]\n",
      "Training Loss: 137.2287, Training Accuracy: 55.7558%\n",
      "Test Loss: 208.0988, Test Accuracy: 45.4436%\n",
      "Epoch 150/200-------------------\n",
      "loss: 128.308075 [    0/ 5994]\n",
      "loss: 135.982239 [ 1600/ 5994]\n",
      "loss: 96.462173 [ 3200/ 5994]\n",
      "loss: 239.487671 [ 4800/ 5994]\n",
      "Training Loss: 126.1610, Training Accuracy: 59.9600%\n",
      "Test Loss: 196.5205, Test Accuracy: 49.4650%\n",
      "Epoch 151/200-------------------\n",
      "loss: 254.557312 [    0/ 5994]\n",
      "loss: 139.154404 [ 1600/ 5994]\n",
      "loss: 122.462418 [ 3200/ 5994]\n",
      "loss: 147.216537 [ 4800/ 5994]\n",
      "Training Loss: 118.4791, Training Accuracy: 57.6743%\n",
      "Test Loss: 188.2469, Test Accuracy: 47.0659%\n",
      "Epoch 152/200-------------------\n",
      "loss: 25.262482 [    0/ 5994]\n",
      "loss: 67.346291 [ 1600/ 5994]\n",
      "loss: 147.744339 [ 3200/ 5994]\n",
      "loss: 86.821564 [ 4800/ 5994]\n",
      "Training Loss: 134.2736, Training Accuracy: 57.5576%\n",
      "Test Loss: 208.0977, Test Accuracy: 47.0832%\n",
      "Epoch 153/200-------------------\n",
      "loss: 62.943504 [    0/ 5994]\n",
      "loss: 63.351231 [ 1600/ 5994]\n",
      "loss: 120.835373 [ 3200/ 5994]\n",
      "loss: 148.361099 [ 4800/ 5994]\n",
      "Training Loss: 136.2512, Training Accuracy: 58.1081%\n",
      "Test Loss: 206.0046, Test Accuracy: 47.4111%\n",
      "Epoch 154/200-------------------\n",
      "loss: 171.089020 [    0/ 5994]\n",
      "loss: 169.457489 [ 1600/ 5994]\n",
      "loss: 57.264549 [ 3200/ 5994]\n",
      "loss: 80.450623 [ 4800/ 5994]\n",
      "Training Loss: 122.6535, Training Accuracy: 59.9933%\n",
      "Test Loss: 190.8015, Test Accuracy: 49.6376%\n",
      "Epoch 155/200-------------------\n",
      "loss: 2.844582 [    0/ 5994]\n",
      "loss: 195.873657 [ 1600/ 5994]\n",
      "loss: 175.035736 [ 3200/ 5994]\n",
      "loss: 166.375366 [ 4800/ 5994]\n",
      "Training Loss: 141.7635, Training Accuracy: 57.8745%\n",
      "Test Loss: 214.8187, Test Accuracy: 47.0314%\n",
      "Epoch 156/200-------------------\n",
      "loss: 209.421173 [    0/ 5994]\n",
      "loss: 94.225670 [ 1600/ 5994]\n",
      "loss: 137.093063 [ 3200/ 5994]\n",
      "loss: 80.540077 [ 4800/ 5994]\n",
      "Training Loss: 113.9012, Training Accuracy: 60.3270%\n",
      "Test Loss: 184.8371, Test Accuracy: 49.7239%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 49.7239%\n",
      "Epoch 157/200-------------------\n",
      "loss: 115.540138 [    0/ 5994]\n",
      "loss: 169.748444 [ 1600/ 5994]\n",
      "loss: 242.533585 [ 3200/ 5994]\n",
      "loss: 195.063599 [ 4800/ 5994]\n",
      "Training Loss: 130.9965, Training Accuracy: 57.1905%\n",
      "Test Loss: 200.2224, Test Accuracy: 47.0659%\n",
      "Epoch 158/200-------------------\n",
      "loss: 97.565971 [    0/ 5994]\n",
      "loss: 76.398827 [ 1600/ 5994]\n",
      "loss: 221.393784 [ 3200/ 5994]\n",
      "loss: 88.339020 [ 4800/ 5994]\n",
      "Training Loss: 104.8830, Training Accuracy: 61.1778%\n",
      "Test Loss: 176.5928, Test Accuracy: 50.0690%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 50.0690%\n",
      "Epoch 159/200-------------------\n",
      "loss: 75.870529 [    0/ 5994]\n",
      "loss: 164.816010 [ 1600/ 5994]\n",
      "loss: 88.612648 [ 3200/ 5994]\n",
      "loss: 71.316147 [ 4800/ 5994]\n",
      "Training Loss: 115.7583, Training Accuracy: 59.7931%\n",
      "Test Loss: 184.9420, Test Accuracy: 48.8781%\n",
      "Epoch 160/200-------------------\n",
      "loss: 117.643661 [    0/ 5994]\n",
      "loss: 187.209686 [ 1600/ 5994]\n",
      "loss: 160.180695 [ 3200/ 5994]\n",
      "loss: 153.796875 [ 4800/ 5994]\n",
      "Training Loss: 125.9151, Training Accuracy: 57.3740%\n",
      "Test Loss: 195.0250, Test Accuracy: 46.6172%\n",
      "Epoch 161/200-------------------\n",
      "loss: 176.286652 [    0/ 5994]\n",
      "loss: 144.080963 [ 1600/ 5994]\n",
      "loss: 68.711327 [ 3200/ 5994]\n",
      "loss: 161.192932 [ 4800/ 5994]\n",
      "Training Loss: 111.4936, Training Accuracy: 58.7588%\n",
      "Test Loss: 180.3911, Test Accuracy: 48.5502%\n",
      "Epoch 162/200-------------------\n",
      "loss: 83.014290 [    0/ 5994]\n",
      "loss: 49.376366 [ 1600/ 5994]\n",
      "loss: 354.145996 [ 3200/ 5994]\n",
      "loss: 163.976288 [ 4800/ 5994]\n",
      "Training Loss: 112.6611, Training Accuracy: 59.8432%\n",
      "Test Loss: 184.1360, Test Accuracy: 49.4304%\n",
      "Epoch 163/200-------------------\n",
      "loss: 91.449844 [    0/ 5994]\n",
      "loss: 59.801323 [ 1600/ 5994]\n",
      "loss: 193.787979 [ 3200/ 5994]\n",
      "loss: 161.820923 [ 4800/ 5994]\n",
      "Training Loss: 116.6013, Training Accuracy: 58.2749%\n",
      "Test Loss: 189.4758, Test Accuracy: 47.9979%\n",
      "Epoch 164/200-------------------\n",
      "loss: 105.813553 [    0/ 5994]\n",
      "loss: 58.679260 [ 1600/ 5994]\n",
      "loss: 92.255676 [ 3200/ 5994]\n",
      "loss: 162.953705 [ 4800/ 5994]\n",
      "Training Loss: 124.8448, Training Accuracy: 56.8402%\n",
      "Test Loss: 198.1565, Test Accuracy: 47.4802%\n",
      "Epoch 165/200-------------------\n",
      "loss: 146.982864 [    0/ 5994]\n",
      "loss: 139.247803 [ 1600/ 5994]\n",
      "loss: 201.307220 [ 3200/ 5994]\n",
      "loss: 50.277870 [ 4800/ 5994]\n",
      "Training Loss: 131.6093, Training Accuracy: 57.4741%\n",
      "Test Loss: 200.8808, Test Accuracy: 46.7725%\n",
      "Epoch 166/200-------------------\n",
      "loss: 211.662369 [    0/ 5994]\n",
      "loss: 135.821548 [ 1600/ 5994]\n",
      "loss: 178.472992 [ 3200/ 5994]\n",
      "loss: 217.088593 [ 4800/ 5994]\n",
      "Training Loss: 125.9683, Training Accuracy: 58.0747%\n",
      "Test Loss: 202.1912, Test Accuracy: 47.1177%\n",
      "Epoch 167/200-------------------\n",
      "loss: 137.084564 [    0/ 5994]\n",
      "loss: 37.357918 [ 1600/ 5994]\n",
      "loss: 86.875908 [ 3200/ 5994]\n",
      "loss: 138.131775 [ 4800/ 5994]\n",
      "Training Loss: 123.9832, Training Accuracy: 59.0257%\n",
      "Test Loss: 197.6419, Test Accuracy: 48.2741%\n",
      "Epoch 168/200-------------------\n",
      "loss: 204.826828 [    0/ 5994]\n",
      "loss: 154.628571 [ 1600/ 5994]\n",
      "loss: 56.098072 [ 3200/ 5994]\n",
      "loss: 151.891876 [ 4800/ 5994]\n",
      "Training Loss: 132.2272, Training Accuracy: 58.8922%\n",
      "Test Loss: 204.8190, Test Accuracy: 47.6010%\n",
      "Epoch 169/200-------------------\n",
      "loss: 55.517174 [    0/ 5994]\n",
      "loss: 112.470757 [ 1600/ 5994]\n",
      "loss: 97.197021 [ 3200/ 5994]\n",
      "loss: 36.236950 [ 4800/ 5994]\n",
      "Training Loss: 139.4214, Training Accuracy: 57.7411%\n",
      "Test Loss: 211.7351, Test Accuracy: 47.5664%\n",
      "Epoch 170/200-------------------\n",
      "loss: 191.458618 [    0/ 5994]\n",
      "loss: 84.579422 [ 1600/ 5994]\n",
      "loss: 79.153923 [ 3200/ 5994]\n",
      "loss: 246.881516 [ 4800/ 5994]\n",
      "Training Loss: 146.1313, Training Accuracy: 55.9560%\n",
      "Test Loss: 216.3227, Test Accuracy: 45.3918%\n",
      "Epoch 171/200-------------------\n",
      "loss: 135.295074 [    0/ 5994]\n",
      "loss: 79.894691 [ 1600/ 5994]\n",
      "loss: 166.252167 [ 3200/ 5994]\n",
      "loss: 43.909348 [ 4800/ 5994]\n",
      "Training Loss: 121.9280, Training Accuracy: 59.9099%\n",
      "Test Loss: 192.8078, Test Accuracy: 48.2913%\n",
      "Epoch 172/200-------------------\n",
      "loss: 82.665916 [    0/ 5994]\n",
      "loss: 25.219666 [ 1600/ 5994]\n",
      "loss: 191.317627 [ 3200/ 5994]\n",
      "loss: 83.645195 [ 4800/ 5994]\n",
      "Training Loss: 101.4213, Training Accuracy: 62.7628%\n",
      "Test Loss: 173.4541, Test Accuracy: 50.6559%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 50.6559%\n",
      "Epoch 173/200-------------------\n",
      "loss: 59.189278 [    0/ 5994]\n",
      "loss: 105.227402 [ 1600/ 5994]\n",
      "loss: 361.021973 [ 3200/ 5994]\n",
      "loss: 122.785835 [ 4800/ 5994]\n",
      "Training Loss: 111.9618, Training Accuracy: 61.4781%\n",
      "Test Loss: 183.5660, Test Accuracy: 49.7929%\n",
      "Epoch 174/200-------------------\n",
      "loss: 161.325958 [    0/ 5994]\n",
      "loss: 97.693771 [ 1600/ 5994]\n",
      "loss: 34.081863 [ 3200/ 5994]\n",
      "loss: 58.047546 [ 4800/ 5994]\n",
      "Training Loss: 123.3779, Training Accuracy: 60.2769%\n",
      "Test Loss: 193.1268, Test Accuracy: 49.6548%\n",
      "Epoch 175/200-------------------\n",
      "loss: 127.158478 [    0/ 5994]\n",
      "loss: 42.761299 [ 1600/ 5994]\n",
      "loss: 245.485489 [ 3200/ 5994]\n",
      "loss: 197.538681 [ 4800/ 5994]\n",
      "Training Loss: 120.9918, Training Accuracy: 59.1091%\n",
      "Test Loss: 197.1585, Test Accuracy: 47.6010%\n",
      "Epoch 176/200-------------------\n",
      "loss: 198.628418 [    0/ 5994]\n",
      "loss: 140.026993 [ 1600/ 5994]\n",
      "loss: 223.854858 [ 3200/ 5994]\n",
      "loss: 52.181789 [ 4800/ 5994]\n",
      "Training Loss: 128.9030, Training Accuracy: 59.6096%\n",
      "Test Loss: 202.2807, Test Accuracy: 47.6355%\n",
      "Epoch 177/200-------------------\n",
      "loss: 179.941711 [    0/ 5994]\n",
      "loss: 161.619644 [ 1600/ 5994]\n",
      "loss: 84.668449 [ 3200/ 5994]\n",
      "loss: 99.400513 [ 4800/ 5994]\n",
      "Training Loss: 140.1353, Training Accuracy: 58.1748%\n",
      "Test Loss: 216.7458, Test Accuracy: 47.4111%\n",
      "Epoch 178/200-------------------\n",
      "loss: 186.437012 [    0/ 5994]\n",
      "loss: 121.943031 [ 1600/ 5994]\n",
      "loss: 224.254745 [ 3200/ 5994]\n",
      "loss: 103.522034 [ 4800/ 5994]\n",
      "Training Loss: 106.0957, Training Accuracy: 62.2456%\n",
      "Test Loss: 183.3084, Test Accuracy: 49.8101%\n",
      "Epoch 179/200-------------------\n",
      "loss: 55.415390 [    0/ 5994]\n",
      "loss: 58.389267 [ 1600/ 5994]\n",
      "loss: 68.986359 [ 3200/ 5994]\n",
      "loss: 106.593430 [ 4800/ 5994]\n",
      "Training Loss: 134.5356, Training Accuracy: 59.1425%\n",
      "Test Loss: 207.1440, Test Accuracy: 47.6010%\n",
      "Epoch 180/200-------------------\n",
      "loss: 133.292816 [    0/ 5994]\n",
      "loss: 104.790878 [ 1600/ 5994]\n",
      "loss: 215.275894 [ 3200/ 5994]\n",
      "loss: 137.577820 [ 4800/ 5994]\n",
      "Training Loss: 121.2633, Training Accuracy: 59.9600%\n",
      "Test Loss: 195.3955, Test Accuracy: 48.3776%\n",
      "Epoch 181/200-------------------\n",
      "loss: 161.586029 [    0/ 5994]\n",
      "loss: 35.371216 [ 1600/ 5994]\n",
      "loss: 75.646721 [ 3200/ 5994]\n",
      "loss: 91.326355 [ 4800/ 5994]\n",
      "Training Loss: 99.6860, Training Accuracy: 63.4801%\n",
      "Test Loss: 169.7524, Test Accuracy: 51.1046%\n",
      "Saving model to sequential-attributes-to-class.pth with accuracy 51.1046%\n",
      "Epoch 182/200-------------------\n",
      "loss: 162.818909 [    0/ 5994]\n",
      "loss: 164.743011 [ 1600/ 5994]\n",
      "loss: 55.240322 [ 3200/ 5994]\n",
      "loss: 145.174622 [ 4800/ 5994]\n",
      "Training Loss: 114.8591, Training Accuracy: 60.0100%\n",
      "Test Loss: 188.1490, Test Accuracy: 48.3949%\n",
      "Epoch 183/200-------------------\n",
      "loss: 389.394775 [    0/ 5994]\n",
      "loss: 175.126358 [ 1600/ 5994]\n",
      "loss: 101.726814 [ 3200/ 5994]\n",
      "loss: 90.404358 [ 4800/ 5994]\n",
      "Training Loss: 116.1171, Training Accuracy: 59.9933%\n",
      "Test Loss: 194.1563, Test Accuracy: 48.0670%\n",
      "Epoch 184/200-------------------\n",
      "loss: 119.244308 [    0/ 5994]\n",
      "loss: 47.850899 [ 1600/ 5994]\n",
      "loss: 24.594032 [ 3200/ 5994]\n",
      "loss: 217.321335 [ 4800/ 5994]\n",
      "Training Loss: 121.5091, Training Accuracy: 62.3457%\n",
      "Test Loss: 193.8865, Test Accuracy: 50.1726%\n",
      "Epoch 185/200-------------------\n",
      "loss: 75.006973 [    0/ 5994]\n",
      "loss: 86.805107 [ 1600/ 5994]\n",
      "loss: 99.507866 [ 3200/ 5994]\n",
      "loss: 168.932739 [ 4800/ 5994]\n",
      "Training Loss: 128.9865, Training Accuracy: 58.4585%\n",
      "Test Loss: 202.0598, Test Accuracy: 47.9116%\n",
      "Epoch 186/200-------------------\n",
      "loss: 125.863792 [    0/ 5994]\n",
      "loss: 111.970741 [ 1600/ 5994]\n",
      "loss: 103.686485 [ 3200/ 5994]\n",
      "loss: 175.213440 [ 4800/ 5994]\n",
      "Training Loss: 128.7968, Training Accuracy: 60.5272%\n",
      "Test Loss: 202.4722, Test Accuracy: 49.0507%\n",
      "Epoch 187/200-------------------\n",
      "loss: 140.037018 [    0/ 5994]\n",
      "loss: 122.268456 [ 1600/ 5994]\n",
      "loss: 94.241501 [ 3200/ 5994]\n",
      "loss: 90.663475 [ 4800/ 5994]\n",
      "Training Loss: 103.2106, Training Accuracy: 62.7461%\n",
      "Test Loss: 177.0442, Test Accuracy: 50.6213%\n",
      "Epoch 188/200-------------------\n",
      "loss: 40.152950 [    0/ 5994]\n",
      "loss: 119.736473 [ 1600/ 5994]\n",
      "loss: 275.078003 [ 3200/ 5994]\n",
      "loss: 105.395515 [ 4800/ 5994]\n",
      "Training Loss: 101.5366, Training Accuracy: 62.6960%\n",
      "Test Loss: 175.1136, Test Accuracy: 50.5005%\n",
      "Epoch 189/200-------------------\n",
      "loss: 112.877235 [    0/ 5994]\n",
      "loss: 116.115547 [ 1600/ 5994]\n",
      "loss: 84.250633 [ 3200/ 5994]\n",
      "loss: 112.499596 [ 4800/ 5994]\n",
      "Training Loss: 103.7846, Training Accuracy: 61.2779%\n",
      "Test Loss: 177.9925, Test Accuracy: 50.0863%\n",
      "Epoch 190/200-------------------\n",
      "loss: 176.001999 [    0/ 5994]\n",
      "loss: 83.331749 [ 1600/ 5994]\n",
      "loss: 225.958405 [ 3200/ 5994]\n",
      "loss: 37.532036 [ 4800/ 5994]\n",
      "Training Loss: 134.4170, Training Accuracy: 57.7744%\n",
      "Test Loss: 213.8461, Test Accuracy: 48.0497%\n",
      "Epoch 191/200-------------------\n",
      "loss: 237.671936 [    0/ 5994]\n",
      "loss: 69.477379 [ 1600/ 5994]\n",
      "loss: 144.680359 [ 3200/ 5994]\n",
      "loss: 77.532509 [ 4800/ 5994]\n",
      "Training Loss: 113.9345, Training Accuracy: 60.9610%\n",
      "Test Loss: 188.8120, Test Accuracy: 49.2924%\n",
      "Epoch 192/200-------------------\n",
      "loss: 166.932419 [    0/ 5994]\n",
      "loss: 58.290855 [ 1600/ 5994]\n",
      "loss: 117.638962 [ 3200/ 5994]\n",
      "loss: 90.997139 [ 4800/ 5994]\n",
      "Training Loss: 125.8999, Training Accuracy: 57.3907%\n",
      "Test Loss: 205.6988, Test Accuracy: 46.4791%\n",
      "Epoch 193/200-------------------\n",
      "loss: 186.641525 [    0/ 5994]\n",
      "loss: 219.968704 [ 1600/ 5994]\n",
      "loss: 86.699493 [ 3200/ 5994]\n",
      "loss: 101.800392 [ 4800/ 5994]\n",
      "Training Loss: 118.7734, Training Accuracy: 61.2946%\n",
      "Test Loss: 198.5610, Test Accuracy: 48.8264%\n",
      "Epoch 194/200-------------------\n",
      "loss: 42.338943 [    0/ 5994]\n",
      "loss: 110.054832 [ 1600/ 5994]\n",
      "loss: 87.267708 [ 3200/ 5994]\n",
      "loss: 163.028290 [ 4800/ 5994]\n",
      "Training Loss: 146.7652, Training Accuracy: 57.2573%\n",
      "Test Loss: 224.8945, Test Accuracy: 46.8070%\n",
      "Epoch 195/200-------------------\n",
      "loss: 24.082340 [    0/ 5994]\n",
      "loss: 89.087509 [ 1600/ 5994]\n",
      "loss: 235.687805 [ 3200/ 5994]\n",
      "loss: 46.641556 [ 4800/ 5994]\n",
      "Training Loss: 123.8080, Training Accuracy: 62.2289%\n",
      "Test Loss: 202.2681, Test Accuracy: 49.2233%\n",
      "Epoch 196/200-------------------\n",
      "loss: 106.739418 [    0/ 5994]\n",
      "loss: 248.926880 [ 1600/ 5994]\n",
      "loss: 82.274460 [ 3200/ 5994]\n",
      "loss: 150.054626 [ 4800/ 5994]\n",
      "Training Loss: 127.1042, Training Accuracy: 60.5272%\n",
      "Test Loss: 206.9947, Test Accuracy: 49.2406%\n",
      "Epoch 197/200-------------------\n",
      "loss: 187.565765 [    0/ 5994]\n",
      "loss: 94.742714 [ 1600/ 5994]\n",
      "loss: 174.519730 [ 3200/ 5994]\n",
      "loss: 110.029785 [ 4800/ 5994]\n",
      "Training Loss: 110.8741, Training Accuracy: 60.5606%\n",
      "Test Loss: 189.2128, Test Accuracy: 48.1705%\n",
      "Epoch 198/200-------------------\n",
      "loss: 115.996529 [    0/ 5994]\n",
      "loss: 41.897652 [ 1600/ 5994]\n",
      "loss: 144.204330 [ 3200/ 5994]\n",
      "loss: 90.423523 [ 4800/ 5994]\n",
      "Training Loss: 108.0495, Training Accuracy: 62.4791%\n",
      "Test Loss: 182.5668, Test Accuracy: 49.2406%\n",
      "Epoch 199/200-------------------\n",
      "loss: 133.093964 [    0/ 5994]\n",
      "loss: 133.173218 [ 1600/ 5994]\n",
      "loss: 186.955658 [ 3200/ 5994]\n",
      "loss: 93.143333 [ 4800/ 5994]\n",
      "Training Loss: 127.5142, Training Accuracy: 60.3770%\n",
      "Test Loss: 205.1987, Test Accuracy: 47.2558%\n",
      "Epoch 200/200-------------------\n",
      "loss: 98.458015 [    0/ 5994]\n",
      "loss: 68.488495 [ 1600/ 5994]\n",
      "loss: 57.189068 [ 3200/ 5994]\n",
      "loss: 45.270416 [ 4800/ 5994]\n",
      "Training Loss: 119.1562, Training Accuracy: 59.9433%\n",
      "Test Loss: 199.1353, Test Accuracy: 48.7401%\n",
      "Best Test Accuracy: 51.1046%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-5.1838e+00, -3.4911e+01,  1.1484e+01,  ..., -1.7288e+01,\n",
       "                       -1.9966e+00, -2.2177e+01],\n",
       "                      [ 1.0490e+01, -4.3466e+01,  9.3212e+00,  ...,  1.3436e+01,\n",
       "                       -1.3708e+01, -2.7054e+01],\n",
       "                      [-4.0387e+00, -2.3054e+01, -2.0484e+00,  ..., -1.5062e+01,\n",
       "                       -1.2643e+01, -1.8658e+01],\n",
       "                      ...,\n",
       "                      [ 2.6812e+01,  4.7301e+01,  2.5565e+00,  ...,  3.7157e+01,\n",
       "                        8.3943e+00, -6.0619e+00],\n",
       "                      [ 1.1969e+01, -1.1978e+01,  1.2614e+01,  ...,  3.8636e+01,\n",
       "                        9.8863e+00, -9.4816e+00],\n",
       "                      [ 6.7023e+00,  2.5132e+01, -7.8330e-01,  ..., -4.1641e-02,\n",
       "                       -2.1109e+01,  7.7411e+00]], device='cuda:0')),\n",
       "             ('0.bias',\n",
       "              tensor([-1.5246e+00, -8.7593e+00, -1.2093e-01, -2.6328e+00,  2.7481e+00,\n",
       "                       4.6032e+00, -4.8262e-01, -5.9524e+00, -4.1249e+00,  4.1564e+00,\n",
       "                       7.9763e+00,  3.4611e-01,  6.8019e-01, -1.6886e+00,  8.5797e-01,\n",
       "                      -3.8124e+00,  4.5612e+00,  1.3564e+00,  1.7650e+00, -1.0727e+00,\n",
       "                       8.7660e-01, -2.8851e+00, -4.8395e+00, -6.4658e-01, -6.2337e+00,\n",
       "                      -1.8023e+00,  1.5098e+00,  2.1997e+00, -8.9472e+00,  1.8910e+00,\n",
       "                      -7.5115e+00,  5.2691e+00,  1.6400e+00, -4.1171e+00,  8.5151e-01,\n",
       "                       1.0740e+00, -5.1135e+00,  2.5464e+00,  1.7667e+01, -8.4179e+00,\n",
       "                       5.8481e+00, -1.3629e+00, -8.2767e+00,  5.5318e+00, -1.5298e+01,\n",
       "                      -2.1981e+00, -1.9053e+00,  2.3673e+00,  1.1322e+01,  3.5925e+00,\n",
       "                       2.1321e-01, -1.3294e+01, -2.9243e+00, -6.6016e+00,  1.5341e-01,\n",
       "                      -3.1723e+00, -1.0207e+00, -7.5583e+00, -5.0739e+00,  1.0382e+01,\n",
       "                       5.1843e+00,  8.8497e+00, -1.7941e+00,  1.6265e+01, -1.9892e+00,\n",
       "                       4.2826e-01,  8.3885e+00, -4.4450e+00,  5.2681e+00, -5.2497e+00,\n",
       "                       4.2665e+00,  9.3733e+00, -7.7098e-01, -5.4838e+00, -1.8456e+00,\n",
       "                      -1.1251e+01, -5.5749e+00, -1.4852e+01, -2.7741e+00,  5.4640e+00,\n",
       "                      -2.1557e+00, -7.6644e+00,  7.6851e-01, -6.4536e+00, -8.6996e-01,\n",
       "                      -8.6351e+00, -1.0353e+00, -6.5148e-01,  5.6675e+00,  1.5123e+00,\n",
       "                       4.4948e+00,  8.5202e+00, -4.4337e+00,  7.1033e+00,  3.8644e+00,\n",
       "                       3.3669e+00, -6.4750e+00, -6.5323e+00,  8.5878e+00,  4.1637e+00,\n",
       "                      -7.8365e+00, -8.7173e+00, -6.0812e+00, -8.3356e-01, -1.9960e+00,\n",
       "                       4.8887e+00,  3.7989e+00,  1.1592e+01,  3.0618e+00,  5.2388e+00,\n",
       "                       7.4937e+00,  7.3579e-01, -5.8897e+00, -2.9371e-01,  2.0619e+00,\n",
       "                      -7.8102e+00, -2.1973e+00,  1.3440e+00, -2.2177e+00, -5.7637e-01,\n",
       "                       4.0545e+00, -3.8455e+00,  5.5003e+00,  5.0773e-01,  1.1831e+01,\n",
       "                       1.0472e+00,  1.5629e+00,  8.6905e+00, -6.7021e+00,  6.5708e+00,\n",
       "                       2.0972e-01,  9.4276e+00,  4.2754e+00, -3.6538e+00,  2.0848e-01,\n",
       "                       1.1591e+01, -9.6778e+00, -2.4866e-01, -4.5810e+00,  1.6194e+00,\n",
       "                       4.0213e+00,  1.0850e+01, -2.9881e+00,  6.9995e-01,  5.5314e+00,\n",
       "                      -8.7176e+00,  1.0915e-02,  7.4813e+00,  9.1359e+00, -2.9046e+00,\n",
       "                       3.8124e+00,  3.1589e+00, -1.6650e+01,  6.9873e+00, -8.4881e-01,\n",
       "                       8.4952e+00, -7.4122e+00,  5.1649e+00,  2.0101e+00, -6.0232e+00,\n",
       "                       1.1835e+00,  2.8443e+00,  4.2135e+00,  1.9546e+00,  4.9808e+00,\n",
       "                      -5.5652e+00,  7.4983e+00, -1.2559e+00, -2.6682e+00, -1.1242e+00,\n",
       "                      -1.1454e+01,  8.3638e+00,  1.1074e+01,  3.1506e+00, -2.8953e+00,\n",
       "                       6.2427e+00, -4.9702e+00, -3.1256e+00, -6.8567e+00,  1.4318e-01,\n",
       "                       2.1916e+00, -3.4913e+00, -5.1277e+00, -3.5374e+00, -1.5887e-01,\n",
       "                      -2.9697e+00, -4.0721e+00,  1.7193e+00,  1.4499e+00,  3.3575e+00,\n",
       "                      -1.9521e+00, -3.1838e+00, -4.6237e-01, -3.9607e+00, -1.0888e+00,\n",
       "                      -3.9950e+00,  6.7771e+00, -7.4324e-01, -6.9811e+00, -7.0852e+00],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.concept_bottleneck.train import TrainFn, TestFn, run_epochs\n",
    "from src.concept_bottleneck.inference import load_image_to_attributes_model\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "trained_image_to_attributes_model = load_image_to_attributes_model(device)\n",
    "\n",
    "train_fn: TrainFn = lambda model: train(\n",
    "    model,\n",
    "    training_dataloader,\n",
    "    trained_image_to_attributes_model,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    ")\n",
    "test_fn: TestFn = lambda model, dataloader: test(\n",
    "    model, dataloader, trained_image_to_attributes_model, loss_fn, device\n",
    ")\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "run_epochs(\n",
    "    epochs,\n",
    "    model,\n",
    "    train_fn,\n",
    "    test_fn,\n",
    "    training_dataloader,\n",
    "    test_dataloader,\n",
    "    save_name=SEQUENTIAL_ATTRIBUTES_TO_CLASS_MODEL_NAME,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d4040fe446a930194e7f49e706fe5ca82fc3ae21142ec3efeed3554a6698e7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
